<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Pandas基础与实战</title>
      <link href="/2022/08/23/pandas-ji-chu-yu-shi-zhan/"/>
      <url>/2022/08/23/pandas-ji-chu-yu-shi-zhan/</url>
      
        <content type="html"><![CDATA[<h1 id="pandas-基础"><a href="#pandas-基础" class="headerlink" title="pandas 基础"></a>pandas 基础</h1><h2 id="pandas应用"><a href="#pandas应用" class="headerlink" title="pandas应用"></a>pandas应用</h2><p>pandas主要的数据结构是Series（一维数据）和DataFrame（二维数据）。</p><ul><li><strong>Series</strong>是一种类似一维数组的对象，它由一组数据（各种Numpy数据类型）以及一组与之相关的数据标签（即索引）组成。</li><li><strong>DataFrame</strong>是表格型的数据结构，含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔型值）。DataFrame 既有行索引也有列索引，它可以被看做由 Series 组成的字典（共同用一个索引）。</li></ul><p>Pandas官网：<a href="https://pandas.pydata.org/">https://pandas.pydata.org/</a></p><p>Pandas源代码：<a href="https://github.com/pandas-dev/pandas">https://github.com/pandas-dev/pandas</a></p><p>对于python 3，只需编写以下代码即可忽略所有警告。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> warnings <span class="token keyword">import</span> filterwarningsfilterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>还是没有消除警告</p><h2 id="Pandas安装"><a href="#Pandas安装" class="headerlink" title="Pandas安装"></a>Pandas安装</h2><p>pip安装</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">pip install pandas<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看是否安装成功</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">print</span><span class="token punctuation">(</span>pd<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span>  <span class="token comment"># 查看pandas版本</span><span class="token comment"># 一个简单的demo</span>data <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'Time'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'year'</span><span class="token punctuation">,</span> <span class="token string">'month'</span><span class="token punctuation">,</span> <span class="token string">'day'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">'Now'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">2022</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">]</span><span class="token punctuation">}</span>df_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df_data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行结果<br><img src="https://img-blog.csdnimg.cn/d3e3efa1f1b24c04827f09be349dbe5b.png" alt="执行结果"></p><h2 id="Pandas数据结构"><a href="#Pandas数据结构" class="headerlink" title="Pandas数据结构"></a>Pandas数据结构</h2><h3 id="Series"><a href="#Series" class="headerlink" title="Series"></a>Series</h3><p>Parameters:</p><ul><li>data : array-like, Iterable, dict, or scalar value</li></ul><p>​        包含存储在系列中的数据。如果 data 是一个 dict，则保持参数顺序。</p><ul><li>index : array-like or Index (1d)</li></ul><p>​      <strong>数据索引标签，如果不指定，默认从 0 开始</strong>。值必须是可散列的，并且与“数据”具有相同的长度。允许使用非唯一索引值。如果未提供，将默认为 RangeIndex (0, 1, 2, …, n)。如果 data 是 dict-like 并且 index 是 None，那么 data 中的键被用作索引。如果索引不是 None，则使用索引值重新索引生成的 Series。</p><ul><li>dtype : str, numpy.dtype, or ExtensionDtype, optional</li></ul><p>​        输出系列的数据类型。如果未指定，这将从 <code>data</code> 推断。</p><ul><li><p>name：设置名称。</p></li><li><p>copy : bool, default False</p></li></ul><p>​        拷贝数据，默认为 False。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'a'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">}</span>ser_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>data<span class="token operator">=</span>data<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>ser_data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果：<br><img src="https://img-blog.csdnimg.cn/82de83a0d9fe49a3b74383467540eda8.png"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'a'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">}</span>ser_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>data<span class="token operator">=</span>data<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token string">'y'</span><span class="token punctuation">,</span> <span class="token string">'z'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>ser_data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果：<br><img src="https://img-blog.csdnimg.cn/f33df17af5364c4fbf4271b20598036f.png"><br>⚠️<strong>请注意</strong>，索引首先使用字典中的键构建。在此之后，Series 使用给定的 Index 值重新索引，因此我们得到所有 NaN 作为结果。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pda <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>myvar <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>myvar<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果：<br><img src="https://img-blog.csdnimg.cn/679aa2be0c064e88ac97c0efebb79e55.jpeg"><br>如果没有指定索引，索引值就从 0 开始</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>ser_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>data<span class="token operator">=</span>data<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>ser_data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>指定索引，输出结果：<br><img src="https://img-blog.csdnimg.cn/3b5ba39db7ff492287522984e3ccb188.png"></p><h3 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h3><p>既有行索引也有列索引。<br><img src="https://img-blog.csdnimg.cn/9ef8f52efb4d49238b6f9b563291d7f0.png"><br><img src="https://img-blog.csdnimg.cn/22457d4338334fb68da9a37322d0bd55.png"><br>图片来自<a href="https://www.runoob.com/">菜鸟教程</a><br>Parameters:</p><ul><li><p>data: ndarray (structured or homogeneous), Iterable, dict, or DataFrame</p><p>一组数据(ndarray、series, map, lists, dict 等类型)。Dict 可以包含系列、数组、常量、数据类或类似列表的对象。如果数据是一个字典，列顺序遵循插入顺序。</p></li><li><p>index : Index or array-like</p></li></ul><p>​        索引值，或者可以称为行标签。如果输入数据没有索引信息部分并且没有提供索引，则默认为 RangeIndex。</p><ul><li><p>columns : Index or array-like</p><p>列标签。如果没有提供列标签，将默认为 RangeIndex (0, 1, 2, …, n)。</p></li><li><p>dtype : dtype, default None</p><p>要强制的数据类型。只允许使用一个 dtype。如果没有，推断。</p></li><li><p>copy : bool, default False</p><p>拷贝数据，默认为 False。</p></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'col1'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'col2'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">}</span>  <span class="token comment"># 使用 ndarrays 创建</span><span class="token comment"># data = [{'col1': 'a', 'col2': 1}, {'col1': 'b', 'col2': 2}]  # 使用字典创建</span><span class="token comment"># data = [['a', 1], ['b', 2]]  # 使用列表创建</span>df_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token operator">=</span>data<span class="token punctuation">)</span><span class="token comment"># df_data = pd.DataFrame(data=data, columns=['col1', 'col2'])</span><span class="token keyword">print</span><span class="token punctuation">(</span>df_data<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df_data<span class="token punctuation">.</span>dtypes<span class="token punctuation">)</span>  <span class="token comment"># 查看数据类型</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果：<br><img src="https://img-blog.csdnimg.cn/7fd33943223d4be59b69af03f075657f.png"><br>从dataclass构造 DataFrame</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> dataclasses <span class="token keyword">import</span> make_dataclassPoint <span class="token operator">=</span> make_dataclass<span class="token punctuation">(</span><span class="token string">"Point"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"x"</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"y"</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>class_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span>Point<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Point<span class="token punctuation">(</span><span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Point<span class="token punctuation">(</span><span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>class_data<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>class_data<span class="token punctuation">.</span>dtypes<span class="token punctuation">)</span>  <span class="token comment"># 查看数据类型</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果：<br><img src="https://img-blog.csdnimg.cn/15e393ff928f45b4aa94d37feb2d1e88.png"><br>没有对应的部分数据为 <strong>NaN</strong>。</p><p>Pandas 可以使用 <code>loc</code> 属性返回指定行的数据，如果没有设置索引，第一行索引为 <strong>0</strong>，第二行索引为 <strong>1</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">"calories"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">420</span><span class="token punctuation">,</span> <span class="token number">380</span><span class="token punctuation">,</span> <span class="token number">390</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">"duration"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">}</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span>  <span class="token comment"># 数据载入到 DataFrame 对象</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'第一行:\n{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 返回第一行</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'第二行:\n{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 返回第二行</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 返回第一行和第二行</span><span class="token comment"># df = pd.DataFrame(data, index = ["day1", "day2", "day3"])</span><span class="token comment"># print(df.loc["day2"])  # 指定索引</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果：<br><img src="https://img-blog.csdnimg.cn/35aa12df80f84038a44c040b6ad15571.png"></p><h2 id="CSV文件"><a href="#CSV文件" class="headerlink" title="CSV文件"></a>CSV文件</h2><p>CSV（Comma-Separated Values，逗号分隔值，有时也称为字符分隔值，因为分隔字符也可以不是逗号），其文件以纯文本形式存储表格数据（数字和文本）。</p><p>Pandas 可以很方便的处理 CSV 文件，本文以<strong>鸢尾花数据集</strong><code>iris.csv</code> 为例，扫码获取数据。<br><img src="https://img-blog.csdnimg.cn/e191bd36211c4033afe938e3c252df86.png"><br><strong>to_string()</strong> 用于返回 DataFrame 类型的数据，如果不使用该函数，则输出结果为数据的前面 5 行和末尾 5 行，中间部分以 <strong>…</strong> 代替。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdcsv_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./iris.csv'</span><span class="token punctuation">)</span><span class="token comment"># print(csv_data)  # 显示前五行和后五行数据，中间...表示</span><span class="token keyword">print</span><span class="token punctuation">(</span>csv_data<span class="token punctuation">.</span>to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 显示全部数据</span><span class="token keyword">print</span><span class="token punctuation">(</span>csv_data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 显示前3行</span><span class="token keyword">print</span><span class="token punctuation">(</span>csv_data<span class="token punctuation">.</span>tail<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 显示后3行</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>print(csv_data)输出：<br><img src="https://img-blog.csdnimg.cn/a60473f0c665408eaac2a81d245f87f1.png"><br>print(csv_data.to_string())输出：<br><img src="https://img-blog.csdnimg.cn/ab43aa01853b4f44a1710b7bd1f348c1.png"><br>显示前3行输出结果：<br><img src="https://img-blog.csdnimg.cn/053c9337a5b541cea9e67779f6519041.png"></p><p>显示后3行输出结果：</p><p><img src="https://img-blog.csdnimg.cn/5540e303c4ab4b9bb75d1bc142f80228.png"></p><p>使用 <strong>to_csv()</strong> 方法将 DataFrame 存储为 csv 文件</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">"calories"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">420</span><span class="token punctuation">,</span> <span class="token number">380</span><span class="token punctuation">,</span> <span class="token number">390</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">"duration"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">}</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span>  <span class="token comment"># 数据载入到 DataFrame 对象</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'原始数据:{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 保存 dataframe</span>df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"set.csv"</span><span class="token punctuation">)</span><span class="token comment"># 读取生成的csv文件</span>read_new_set <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'set.csv'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>read_new_set<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>read_new_set<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 显示文件基本信息</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果<br><img src="https://img-blog.csdnimg.cn/c5167351e12f40669001bed1b5691ff1.png"></p><h2 id="JSON文件"><a href="#JSON文件" class="headerlink" title="JSON文件"></a>JSON文件</h2><p>JSON 对象与 Python 字典具有相同的格式</p><p>从 URL 中读取 JSON 数据</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token comment"># 直接读JSON文件</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_json<span class="token punctuation">(</span><span class="token string">'sites.json'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 直接处理 JSON 字符串</span>data <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token punctuation">{</span>        <span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token string">"A001"</span><span class="token punctuation">,</span>        <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"菜鸟教程"</span><span class="token punctuation">,</span>        <span class="token string">"url"</span><span class="token punctuation">:</span> <span class="token string">"www.runoob.com"</span><span class="token punctuation">,</span>        <span class="token string">"likes"</span><span class="token punctuation">:</span> <span class="token number">61</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token punctuation">{</span>        <span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token string">"A002"</span><span class="token punctuation">,</span>        <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"Google"</span><span class="token punctuation">,</span>        <span class="token string">"url"</span><span class="token punctuation">:</span> <span class="token string">"www.google.com"</span><span class="token punctuation">,</span>        <span class="token string">"likes"</span><span class="token punctuation">:</span> <span class="token number">124</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token punctuation">{</span>        <span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token string">"A003"</span><span class="token punctuation">,</span>        <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"淘宝"</span><span class="token punctuation">,</span>        <span class="token string">"url"</span><span class="token punctuation">:</span> <span class="token string">"www.taobao.com"</span><span class="token punctuation">,</span>        <span class="token string">"likes"</span><span class="token punctuation">:</span> <span class="token number">45</span>    <span class="token punctuation">}</span><span class="token punctuation">]</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token comment"># 从 URL 中读取 JSON 数据</span>URL <span class="token operator">=</span> <span class="token string">'https://static.runoob.com/download/sites.json'</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_json<span class="token punctuation">(</span>URL<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果显示：<br><img src="https://img-blog.csdnimg.cn/90202dd87fff459e80e1f5b76acd5405.png"><br>内嵌的 JSON 数据，inner.json如下：</p><pre class="line-numbers language-Json" data-language="Json"><code class="language-Json">{  "school_name": "ABC primary school",  "class": "Year 1",  "students": [    {      "id": "A001",      "name": "Tom",      "math": 60,      "physics": 66,      "chemistry": 61    },    {      "id": "A002",      "name": "James",      "math": 89,      "physics": 76,      "chemistry": 51    }  ]}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>查看json文件</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdinner_json <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_json<span class="token punctuation">(</span><span class="token string">'./inner.json'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>inner_json<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>使用 <strong>json_normalize()</strong> 方法将内嵌的数据完整的解析出来</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> json<span class="token comment"># inner_json = pd.read_json('./inner.json') </span><span class="token comment"># 使用 Python JSON 模块载入数据</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./inner.json'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    inner_json <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 展平数据</span><span class="token comment">#  meta 参数来显示这些元数据 meta=['school_name', 'class']</span>student_inner <span class="token operator">=</span> pd<span class="token punctuation">.</span>json_normalize<span class="token punctuation">(</span>data<span class="token operator">=</span>inner_json<span class="token punctuation">,</span> record_path<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'students'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>student_inner<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>数据嵌套了列表和字典，文件inner_list_dic.json如下：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>  <span class="token property">"school_name"</span><span class="token operator">:</span> <span class="token string">"local primary school"</span><span class="token punctuation">,</span>  <span class="token property">"class"</span><span class="token operator">:</span> <span class="token string">"Year 1"</span><span class="token punctuation">,</span>  <span class="token property">"info"</span><span class="token operator">:</span> <span class="token punctuation">{</span>    <span class="token property">"president"</span><span class="token operator">:</span> <span class="token string">"John Kasich"</span><span class="token punctuation">,</span>    <span class="token property">"address"</span><span class="token operator">:</span> <span class="token string">"ABC road, London, UK"</span><span class="token punctuation">,</span>    <span class="token property">"contacts"</span><span class="token operator">:</span> <span class="token punctuation">{</span>      <span class="token property">"email"</span><span class="token operator">:</span> <span class="token string">"admin@e.com"</span><span class="token punctuation">,</span>      <span class="token property">"tel"</span><span class="token operator">:</span> <span class="token string">"123456789"</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">,</span>  <span class="token property">"students"</span><span class="token operator">:</span> <span class="token punctuation">[</span>    <span class="token punctuation">{</span>      <span class="token property">"id"</span><span class="token operator">:</span> <span class="token string">"A001"</span><span class="token punctuation">,</span>      <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"Tom"</span><span class="token punctuation">,</span>      <span class="token property">"math"</span><span class="token operator">:</span> <span class="token number">60</span><span class="token punctuation">,</span>      <span class="token property">"physics"</span><span class="token operator">:</span> <span class="token number">66</span><span class="token punctuation">,</span>      <span class="token property">"chemistry"</span><span class="token operator">:</span> <span class="token number">61</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token punctuation">{</span>      <span class="token property">"id"</span><span class="token operator">:</span> <span class="token string">"A002"</span><span class="token punctuation">,</span>      <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"James"</span><span class="token punctuation">,</span>      <span class="token property">"math"</span><span class="token operator">:</span> <span class="token number">89</span><span class="token punctuation">,</span>      <span class="token property">"physics"</span><span class="token operator">:</span> <span class="token number">76</span><span class="token punctuation">,</span>      <span class="token property">"chemistry"</span><span class="token operator">:</span> <span class="token number">51</span>    <span class="token punctuation">}</span>  <span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>inner_list_dic.json文件转换为 DataFrame</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> json<span class="token comment"># inner_json = pd.read_json('./inner_list_dic.json')</span><span class="token comment"># 使用 Python JSON 模块载入数据</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./inner_list_dic.json'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    inner_json <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 展平数据</span><span class="token comment">#  meta 参数来显示这些元数据 meta=['school_name', 'class']</span>student_inner <span class="token operator">=</span> pd<span class="token punctuation">.</span>json_normalize<span class="token punctuation">(</span>data<span class="token operator">=</span>inner_json<span class="token punctuation">,</span> record_path<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'students'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> meta<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'class'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'info'</span><span class="token punctuation">,</span> <span class="token string">'contacts'</span><span class="token punctuation">,</span> <span class="token string">'email'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>student_inner<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果：<br><img src="https://img-blog.csdnimg.cn/96371f470c384eac9f1be7f4cf44e8b2.png"><br>只读取内嵌中的某字段，inner_one.json</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>  <span class="token property">"school_name"</span><span class="token operator">:</span> <span class="token string">"local primary school"</span><span class="token punctuation">,</span>  <span class="token property">"class"</span><span class="token operator">:</span> <span class="token string">"Year 1"</span><span class="token punctuation">,</span>  <span class="token property">"students"</span><span class="token operator">:</span> <span class="token punctuation">[</span>    <span class="token punctuation">{</span>      <span class="token property">"id"</span><span class="token operator">:</span> <span class="token string">"A001"</span><span class="token punctuation">,</span>      <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"Tom"</span><span class="token punctuation">,</span>      <span class="token property">"grade"</span><span class="token operator">:</span> <span class="token punctuation">{</span>        <span class="token property">"math"</span><span class="token operator">:</span> <span class="token number">60</span><span class="token punctuation">,</span>        <span class="token property">"physics"</span><span class="token operator">:</span> <span class="token number">66</span><span class="token punctuation">,</span>        <span class="token property">"chemistry"</span><span class="token operator">:</span> <span class="token number">61</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token punctuation">{</span>      <span class="token property">"id"</span><span class="token operator">:</span> <span class="token string">"A002"</span><span class="token punctuation">,</span>      <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"James"</span><span class="token punctuation">,</span>      <span class="token property">"grade"</span><span class="token operator">:</span> <span class="token punctuation">{</span>        <span class="token property">"math"</span><span class="token operator">:</span> <span class="token number">89</span><span class="token punctuation">,</span>        <span class="token property">"physics"</span><span class="token operator">:</span> <span class="token number">76</span><span class="token punctuation">,</span>        <span class="token property">"chemistry"</span><span class="token operator">:</span> <span class="token number">51</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>  <span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>需要使用到 <strong>glom</strong> 模块来处理数据套嵌，<strong>glom</strong> 模块允许我们使用<code>.</code>来访问内嵌对象的属性</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> glom <span class="token keyword">import</span> glomglom_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_json<span class="token punctuation">(</span><span class="token string">'./inner_one.json'</span><span class="token punctuation">)</span>data <span class="token operator">=</span> glom_data<span class="token punctuation">[</span><span class="token string">'students'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> row<span class="token punctuation">:</span> glom<span class="token punctuation">(</span>row<span class="token punctuation">,</span> <span class="token string">'grade.physics'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出：<br><img src="https://img-blog.csdnimg.cn/e8da799e67c849c6a92a38f25cc08d5f.png" alt="请添加图片描述"></p><h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><p> <strong>dropna()</strong> 方法删除包含空字段的行。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddf <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data.csv'</span><span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'NUM_BEDROOMS'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 显示改列</span><span class="token keyword">print</span> <span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'NUM_BEDROOMS'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#通过 isnull() 判断各个单元格是否为空，True表示为空</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Pandas 把 n/a 和 NA 当作空数据</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdmissing_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"n/a"</span><span class="token punctuation">,</span> <span class="token string">"na"</span><span class="token punctuation">,</span> <span class="token string">"--"</span><span class="token punctuation">]</span>  <span class="token comment"># 指定空数据类型</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data.csv'</span><span class="token punctuation">,</span> na_values <span class="token operator">=</span> missing_values<span class="token punctuation">)</span>new_df <span class="token operator">=</span> df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 删除包含空数据的行</span>new_df <span class="token operator">=</span> df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 修改源数据 DataFrame, 可以使用 inplace = True 参数</span><span class="token keyword">print</span><span class="token punctuation">(</span>new_df<span class="token punctuation">.</span>to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>移除指定列有空值的行</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddf <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data.csv'</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'col2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> <strong>fillna()</strong> 方法来替换一些空字段</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddf <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data.csv'</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">,</span> inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 用 123 替换空字段</span><span class="token comment"># 指定某一个列来替换数据 </span>df<span class="token punctuation">[</span><span class="token string">'PID'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">,</span> inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 用 12345 替换 PID 为空数据</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>替换空单元格的常用方法是计算列的均值、中位数值或众数。</p><p>Pandas使用 <strong>mean()<strong>、</strong>median()</strong> 和 <strong>mode()</strong> 方法计算列的均值（所有值加起来的平均值）、中位数值（排序后排在中间的数）和众数（出现频率最高的数）。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddf <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data.csv'</span><span class="token punctuation">)</span><span class="token comment"># 用 mean() 方法计算列的均值并替换空单元格</span>x_mean <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"ST_NUM"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"ST_NUM"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>x_mean<span class="token punctuation">,</span> inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 用 median() 方法计算列的中位数并替换空单元格</span>x_median <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"ST_NUM"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>median<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"ST_NUM"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>x_median<span class="token punctuation">,</span> inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 用 mode() 方法计算列的众数并替换空单元格</span>x_mode <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"ST_NUM"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"ST_NUM"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>x_mode<span class="token punctuation">,</span> inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Pandas-清洗格式错误数据"><a href="#Pandas-清洗格式错误数据" class="headerlink" title="Pandas 清洗格式错误数据"></a>Pandas 清洗格式错误数据</h3><p>格式化日期</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token comment"># 第三个日期格式错误</span>data <span class="token operator">=</span> <span class="token punctuation">{</span>  <span class="token string">"Date"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'2020/12/01'</span><span class="token punctuation">,</span> <span class="token string">'2020/12/02'</span> <span class="token punctuation">,</span> <span class="token string">'20201226'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token string">"duration"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">}</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">,</span> index <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"day1"</span><span class="token punctuation">,</span> <span class="token string">"day2"</span><span class="token punctuation">,</span> <span class="token string">"day3"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">'Date'</span><span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Date'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出</p><blockquote><pre class="line-numbers language-none"><code class="language-none">           Date  durationday1 2020-12-01        50day2 2020-12-02        40day3 2020-12-26        45<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></blockquote><p>替换错误年龄的数据</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdperson <span class="token operator">=</span> <span class="token punctuation">{</span>  <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Google'</span><span class="token punctuation">,</span> <span class="token string">'Runoob'</span> <span class="token punctuation">,</span> <span class="token string">'Taobao'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token string">"age"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">12345</span><span class="token punctuation">]</span>    <span class="token comment"># 12345 年龄数据是错误的</span><span class="token punctuation">}</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>person<span class="token punctuation">)</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">30</span> <span class="token comment"># 修改数据</span><span class="token comment"># 设置条件语句</span><span class="token comment"># for x in df.index:</span><span class="token comment">#   if df.loc[x, "age"] &gt; 120:</span><span class="token comment">#     df.loc[x, "age"] = 120  # 大于120的修改为120</span><span class="token comment">#     # df.drop(x, inplace=True)  # 将错误数据的行删除</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出：</p><blockquote><p>name  age</p><p>0  Google   50<br>1  Runoob   40<br>2  Taobao   30</p></blockquote><h3 id="清洗重复数据"><a href="#清洗重复数据" class="headerlink" title="清洗重复数据"></a>清洗重复数据</h3><p>可以使用 <strong>duplicated()</strong> 和 <strong>drop_duplicates()</strong> 方法</p><p>如果对应的数据是重复的，<strong>duplicated()</strong> 会返回 True，否则返回 False。</p><p>删除重复数据，可以直接使用<strong>drop_duplicates()</strong> 方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdperson <span class="token operator">=</span> <span class="token punctuation">{</span>  <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Google'</span><span class="token punctuation">,</span> <span class="token string">'Runoob'</span><span class="token punctuation">,</span> <span class="token string">'Runoob'</span><span class="token punctuation">,</span> <span class="token string">'Taobao'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token string">"age"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">]</span>  <span class="token punctuation">}</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>person<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>duplicated<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>drop_duplicates<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 删除重复数据</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果：</p><blockquote><p>0    False<br>1    False<br>2     True<br>3    False<br>|  |  |<br>|–|–|<br>|  |  |<br>dtype: bool</p></blockquote><p>删除重复数据</p><blockquote><p>   name  age<br>0  Google   50<br>1  Runoob   40<br>3  Taobao   23</p></blockquote><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>解压文件</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 解压缩zip文件</span><span class="token keyword">import</span> zipfilef <span class="token operator">=</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span><span class="token string">"../input/A榜/toUserA.zip"</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token comment"># 原压缩文件在服务器的位置</span><span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> f<span class="token punctuation">.</span>namelist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  f<span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">,</span><span class="token string">"../output/"</span><span class="token punctuation">)</span> <span class="token comment">#解压到的位置</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 判断是否有效的zipfile</span><span class="token keyword">import</span> zipfilezipfilename <span class="token operator">=</span> <span class="token string">'../input/A榜/toUserA.zip'</span><span class="token keyword">print</span><span class="token punctuation">(</span>zipfile<span class="token punctuation">.</span>is_zipfile<span class="token punctuation">(</span>zipfilename<span class="token punctuation">)</span><span class="token punctuation">)</span>zfile <span class="token operator">=</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span>zipfilename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token comment"># print(zfile)</span><span class="token comment"># 读取所有文件</span><span class="token keyword">with</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span>zipfilename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> zfile<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>zfile<span class="token punctuation">.</span>infolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 抽取文件</span><span class="token keyword">with</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span>zipfilename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> zfile<span class="token punctuation">:</span>    zfile<span class="token punctuation">.</span>extractall<span class="token punctuation">(</span><span class="token string">'../input/A榜/'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>读取基本信息和可视化</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdtrain_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'../output/toUserA/train.csv'</span><span class="token punctuation">)</span>train_data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span>train_data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 去重显示userid</span>train_data<span class="token punctuation">.</span>userid<span class="token punctuation">.</span>drop_duplicates<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># from IPython.display import display, HTML</span><span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> displaytrain_data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>                      <span class="token comment"># 查看训练集基本信息</span>display<span class="token punctuation">(</span>train_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>              <span class="token comment"># 查看训练集数据的维度</span><span class="token comment"># 使用pandas_profiling模块工具一键生成探索性数据分析报告</span><span class="token keyword">import</span> pandas_profiling <span class="token keyword">as</span> ppfppf<span class="token punctuation">.</span>ProfileReport<span class="token punctuation">(</span>train_data<span class="token punctuation">)</span>               <span class="token comment"># 一键进行探索性可视化分析</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2"><a href="#2" class="headerlink" title="2"></a>2</h3><p>文献导出并筛选</p><p>下载搜索到的文献csv表格 ，并修改名字为sample<br><img src="https://img-blog.csdnimg.cn/d5bdc7c5cb434d67a5e129f427b77c91.png" alt="请添加图片描述"><br>代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddf <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'sample.csv'</span><span class="token punctuation">)</span><span class="token comment"># 筛选出含有title中含有'标注'</span>biaozhu<span class="token operator">=</span>df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">str</span><span class="token punctuation">.</span>contains<span class="token punctuation">(</span><span class="token string">'标注'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>biaozhu<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 统计个数</span>biaozhu<span class="token punctuation">.</span>to_excel<span class="token punctuation">(</span><span class="token string">"sample589.xlsx"</span><span class="token punctuation">)</span>  <span class="token comment"># 保存为excel</span><span class="token comment"># 筛选出含有title中含有'图像标注'</span>tuxiang<span class="token operator">=</span>df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">str</span><span class="token punctuation">.</span>contains<span class="token punctuation">(</span><span class="token string">'图像标注'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>tuxiang<span class="token punctuation">.</span>to_excel<span class="token punctuation">(</span><span class="token string">"sample89.xlsx"</span><span class="token punctuation">)</span>  <span class="token comment"># 保存为excel</span><span class="token comment"># 合并两个表格，并保存</span>result <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>biaozhu<span class="token punctuation">,</span> tuxiang<span class="token punctuation">]</span><span class="token punctuation">,</span> sort<span class="token operator">=</span>Fasle<span class="token punctuation">)</span>writer <span class="token operator">=</span> pd<span class="token punctuation">.</span>ExcelWriter<span class="token punctuation">(</span><span class="token string">'result.xlsx'</span><span class="token punctuation">)</span>result<span class="token punctuation">.</span>to_excel<span class="token punctuation">(</span>writer<span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>writer<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3"><a href="#3" class="headerlink" title="3"></a>3</h3><p><a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques">kaggle房价预测项目</a></p><p>导入所需的库</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#基础</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> time<span class="token comment">#绘图</span><span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inline<span class="token comment">#模型</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> Lasso<span class="token punctuation">,</span> LassoCV<span class="token punctuation">,</span> ElasticNet<span class="token punctuation">,</span> ElasticNetCV<span class="token punctuation">,</span> Ridge<span class="token punctuation">,</span> RidgeCV<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestRegressor<span class="token punctuation">,</span> GradientBoostingRegressor<span class="token punctuation">,</span> StackingRegressor<span class="token keyword">from</span> mlxtend<span class="token punctuation">.</span>regressor <span class="token keyword">import</span> StackingCVRegressor<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVR<span class="token keyword">import</span> lightgbm <span class="token keyword">as</span> lgb<span class="token keyword">import</span> xgboost <span class="token keyword">as</span> xgb<span class="token comment">#模型相关</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> make_pipeline<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> RobustScaler<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> KFold<span class="token punctuation">,</span> cross_val_score<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error<span class="token comment">#忽略警告</span><span class="token keyword">import</span> warnings<span class="token keyword">def</span> <span class="token function">ignore_warn</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span>warnings<span class="token punctuation">.</span>warn <span class="token operator">=</span> ignore_warn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>读取数据集，对正偏斜的目标值取对数处理</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">train <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'train_data.csv'</span><span class="token punctuation">)</span>test <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'test_data.csv'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The shape of training data:'</span><span class="token punctuation">,</span> train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The shape of testing data:'</span><span class="token punctuation">,</span> test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment"># 画图看数据分布</span><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> skew<span class="token punctuation">,</span> kurtosis<span class="token punctuation">,</span> normy <span class="token operator">=</span> train<span class="token punctuation">[</span><span class="token string">'SalePrice'</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Skewness of target:'</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>skew<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'kurtosis of target:'</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>kurtosis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>distplot<span class="token punctuation">(</span>y<span class="token punctuation">,</span> fit<span class="token operator">=</span>norm<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment"># 未处理的目标值明显右偏，不满足正态分布</span>y <span class="token operator">=</span> np<span class="token punctuation">.</span>log1p<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Skewness of target:'</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>skew<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'kurtosis of target:'</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>kurtosis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>distplot<span class="token punctuation">(</span>y<span class="token punctuation">,</span> fit<span class="token operator">=</span>norm<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment"># 处理后的目标值接近正态分布</span>train <span class="token operator">=</span> train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'SalePrice'</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#检查训练集与测试集的维度是否一致</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The shape of training data:'</span><span class="token punctuation">,</span> train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The length of y:'</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The shape of testing data:'</span><span class="token punctuation">,</span> test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>定义交叉验证策略及评估方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#采用十折交叉验证</span>n_folds <span class="token operator">=</span> <span class="token number">10</span><span class="token keyword">def</span> <span class="token function">rmse_cv</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span>  kf <span class="token operator">=</span> KFold<span class="token punctuation">(</span>n_folds<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>  rmse <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token operator">-</span>cross_val_score<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train<span class="token punctuation">.</span>values<span class="token punctuation">,</span> y<span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'neg_mean_squared_error'</span><span class="token punctuation">,</span> cv<span class="token operator">=</span>kf<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">return</span><span class="token punctuation">(</span>rmse<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>单个模型参数设置<br>采用六个模型：</p><ul><li>Lasso</li><li>ElasticNet</li><li>Ridge</li><li>Gradient Boosting</li><li>LightGBM</li><li>XGBoost</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#Lasso</span>lasso_alpha <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.00005</span><span class="token punctuation">,</span> <span class="token number">0.0001</span><span class="token punctuation">,</span> <span class="token number">0.0002</span><span class="token punctuation">,</span> <span class="token number">0.0005</span><span class="token punctuation">,</span> <span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">0.002</span><span class="token punctuation">,</span> <span class="token number">0.005</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span>lasso <span class="token operator">=</span> make_pipeline<span class="token punctuation">(</span>RobustScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> LassoCV<span class="token punctuation">(</span>alphas<span class="token operator">=</span>lasso_alpha<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#ElasticNet</span>enet_beta <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">]</span>enet_alpha <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.00005</span><span class="token punctuation">,</span> <span class="token number">0.0001</span><span class="token punctuation">,</span> <span class="token number">0.0002</span><span class="token punctuation">,</span> <span class="token number">0.0005</span><span class="token punctuation">,</span> <span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">0.002</span><span class="token punctuation">,</span> <span class="token number">0.005</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">]</span>ENet <span class="token operator">=</span> make_pipeline<span class="token punctuation">(</span>RobustScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ElasticNetCV<span class="token punctuation">(</span>l1_ratio<span class="token operator">=</span>enet_beta<span class="token punctuation">,</span> alphas<span class="token operator">=</span>enet_alpha<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#Ridge</span>rid_alpha <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.00005</span><span class="token punctuation">,</span> <span class="token number">0.0001</span><span class="token punctuation">,</span> <span class="token number">0.0002</span><span class="token punctuation">,</span> <span class="token number">0.0005</span><span class="token punctuation">,</span> <span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">0.002</span><span class="token punctuation">,</span> <span class="token number">0.005</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span>rid <span class="token operator">=</span> make_pipeline<span class="token punctuation">(</span>RobustScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> RidgeCV<span class="token punctuation">(</span>alphas<span class="token operator">=</span>rid_alpha<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#Gradient Boosting</span>gbr_params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'loss'</span><span class="token punctuation">:</span> <span class="token string">'huber'</span><span class="token punctuation">,</span>      <span class="token string">'criterion'</span><span class="token punctuation">:</span> <span class="token string">'mse'</span><span class="token punctuation">,</span>       <span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>      <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">600</span><span class="token punctuation">,</span>       <span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span>      <span class="token string">'subsample'</span><span class="token punctuation">:</span> <span class="token number">0.6</span><span class="token punctuation">,</span>      <span class="token string">'min_samples_split'</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span>      <span class="token string">'min_samples_leaf'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span>      <span class="token string">'max_features'</span><span class="token punctuation">:</span> <span class="token number">0.6</span><span class="token punctuation">,</span>      <span class="token string">'random_state'</span><span class="token punctuation">:</span> <span class="token number">32</span><span class="token punctuation">,</span>      <span class="token string">'alpha'</span><span class="token punctuation">:</span> <span class="token number">0.5</span><span class="token punctuation">}</span>gbr <span class="token operator">=</span> GradientBoostingRegressor<span class="token punctuation">(</span><span class="token operator">**</span>gbr_params<span class="token punctuation">)</span><span class="token comment">#LightGBM</span>lgbr_params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token number">0.01</span><span class="token punctuation">,</span>      <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">1850</span><span class="token punctuation">,</span>       <span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span>      <span class="token string">'num_leaves'</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span>      <span class="token string">'subsample'</span><span class="token punctuation">:</span> <span class="token number">0.6</span><span class="token punctuation">,</span>      <span class="token string">'colsample_bytree'</span><span class="token punctuation">:</span> <span class="token number">0.6</span><span class="token punctuation">,</span>      <span class="token string">'min_child_weight'</span><span class="token punctuation">:</span> <span class="token number">0.001</span><span class="token punctuation">,</span>      <span class="token string">'min_child_samples'</span><span class="token punctuation">:</span> <span class="token number">21</span><span class="token punctuation">,</span>      <span class="token string">'random_state'</span><span class="token punctuation">:</span> <span class="token number">42</span><span class="token punctuation">,</span>      <span class="token string">'reg_alpha'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>      <span class="token string">'reg_lambda'</span><span class="token punctuation">:</span> <span class="token number">0.05</span><span class="token punctuation">}</span>lgbr <span class="token operator">=</span> lgb<span class="token punctuation">.</span>LGBMRegressor<span class="token punctuation">(</span><span class="token operator">**</span>lgbr_params<span class="token punctuation">)</span><span class="token comment">#XGBoost</span>xgbr_params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token number">0.01</span><span class="token punctuation">,</span>      <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">3000</span><span class="token punctuation">,</span>       <span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span>      <span class="token string">'subsample'</span><span class="token punctuation">:</span> <span class="token number">0.6</span><span class="token punctuation">,</span>      <span class="token string">'colsample_bytree'</span><span class="token punctuation">:</span> <span class="token number">0.7</span><span class="token punctuation">,</span>      <span class="token string">'min_child_weight'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span>      <span class="token string">'seed'</span><span class="token punctuation">:</span> <span class="token number">52</span><span class="token punctuation">,</span>      <span class="token string">'gamma'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>      <span class="token string">'reg_alpha'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>      <span class="token string">'reg_lambda'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>xgbr <span class="token operator">=</span> xgb<span class="token punctuation">.</span>XGBRegressor<span class="token punctuation">(</span><span class="token operator">**</span>xgbr_params<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>单个模型评估</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">models_name <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Lasso'</span><span class="token punctuation">,</span> <span class="token string">'ElasticNet'</span><span class="token punctuation">,</span> <span class="token string">'Ridge'</span><span class="token punctuation">,</span> <span class="token string">'Gradient Boosting'</span><span class="token punctuation">,</span> <span class="token string">'LightGBM'</span><span class="token punctuation">,</span> <span class="token string">'XGBoost'</span><span class="token punctuation">]</span>models <span class="token operator">=</span> <span class="token punctuation">[</span>lasso<span class="token punctuation">,</span> ENet<span class="token punctuation">,</span> rid<span class="token punctuation">,</span> gbr<span class="token punctuation">,</span> lgbr<span class="token punctuation">,</span> xgbr<span class="token punctuation">]</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> model <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>models<span class="token punctuation">)</span><span class="token punctuation">:</span>  score <span class="token operator">=</span> rmse_cv<span class="token punctuation">(</span>model<span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{} score: {}({})'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>models_name<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> score<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> score<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>设置Stacking模型参数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">stack_model <span class="token operator">=</span> StackingCVRegressor<span class="token punctuation">(</span>regressors<span class="token operator">=</span><span class="token punctuation">(</span>lasso<span class="token punctuation">,</span> ENet<span class="token punctuation">,</span> rid<span class="token punctuation">,</span> gbr<span class="token punctuation">,</span> lgbr<span class="token punctuation">,</span> xgbr<span class="token punctuation">)</span><span class="token punctuation">,</span> meta_regressor<span class="token operator">=</span>lasso<span class="token punctuation">,</span> use_features_in_secondary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在整个训练集上训练各模型</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#Lasso</span>lasso_trained <span class="token operator">=</span> lasso<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#ElasticNet</span>ENet_trained <span class="token operator">=</span> ENet<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#Ridge</span>rid_trained <span class="token operator">=</span> rid<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#Gradient Boosting</span>gbr_trained <span class="token operator">=</span> gbr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#LightGBM</span>lgbr_trained <span class="token operator">=</span> lgbr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#XGBoost</span>xgbr_trained <span class="token operator">=</span> xgbr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#Stacking</span>stack_model_trained <span class="token operator">=</span> stack_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>评估各个模型在完整训练集上的表现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">rmse</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_preds<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">return</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>mean_squared_error<span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_preds<span class="token punctuation">)</span><span class="token punctuation">)</span>models<span class="token punctuation">.</span>append<span class="token punctuation">(</span>stack_model<span class="token punctuation">)</span>models_name<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'Stacking_model'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> model <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>models<span class="token punctuation">)</span><span class="token punctuation">:</span>  y_preds <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">)</span>  model_score <span class="token operator">=</span> rmse<span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_preds<span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'RMSE of {}: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>models_name<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> model_score<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>提交各个模型的预测结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">sample_submission <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'sample_submission.csv'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> model <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>models<span class="token punctuation">)</span><span class="token punctuation">:</span>  preds <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test<span class="token punctuation">)</span><span class="token punctuation">)</span>  submission <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'Id'</span><span class="token punctuation">:</span> sample_submission<span class="token punctuation">[</span><span class="token string">'Id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'SalePrice'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>expm1<span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>  submission<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'House_Price_submission_'</span><span class="token operator">+</span>models_name<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">'_optimation.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{} finished.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>models_name<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>均值融合</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">preds_in_train <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>models<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> model <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>models<span class="token punctuation">)</span><span class="token punctuation">:</span>  preds_in_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">)</span>average_preds_in_train <span class="token operator">=</span> preds_in_train<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>average_score <span class="token operator">=</span> rmse<span class="token punctuation">(</span>y<span class="token punctuation">,</span> average_preds_in_train<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'RMSE of average model on training data:'</span><span class="token punctuation">,</span> average_score<span class="token punctuation">)</span><span class="token comment">#提交均值融合预测结果</span>preds_in_test <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>test<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>models<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> model <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>models<span class="token punctuation">)</span><span class="token punctuation">:</span>  preds_in_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test<span class="token punctuation">)</span><span class="token punctuation">)</span>average_preds_in_test <span class="token operator">=</span> preds_in_test<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>average_submission <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'Id'</span><span class="token punctuation">:</span> sample_submission<span class="token punctuation">[</span><span class="token string">'Id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'SalePrice'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>expm1<span class="token punctuation">(</span>average_preds_in_test<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>average_submission<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'House_Price_submission_average_model_optimation.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>权值融合</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model_weights <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.15</span><span class="token punctuation">,</span> <span class="token number">0.12</span><span class="token punctuation">,</span> <span class="token number">0.08</span><span class="token punctuation">,</span> <span class="token number">0.08</span><span class="token punctuation">,</span> <span class="token number">0.12</span><span class="token punctuation">,</span> <span class="token number">0.15</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span>weight_preds_in_train <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>preds_in_train<span class="token punctuation">,</span> model_weights<span class="token punctuation">)</span>weight_score <span class="token operator">=</span> rmse<span class="token punctuation">(</span>y<span class="token punctuation">,</span> weight_preds_in_train<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'RMSE of weight model on training data:'</span><span class="token punctuation">,</span> weight_score<span class="token punctuation">)</span><span class="token comment">#提交权值融合预测结果</span>weight_preds_in_test <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>preds_in_test<span class="token punctuation">,</span> model_weights<span class="token punctuation">)</span>weight_submission <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'Id'</span><span class="token punctuation">:</span> sample_submission<span class="token punctuation">[</span><span class="token string">'Id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'SalePrice'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>expm1<span class="token punctuation">(</span>weight_preds_in_test<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>weight_submission<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'House_Price_submission_weight_model_optimation.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存预测结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#保存训练集上的预测结果</span>train_prediction <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>preds_in_train<span class="token punctuation">,</span> columns<span class="token operator">=</span>models_name<span class="token punctuation">)</span>train_prediction<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'train_prediction_of_7_models.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment">#保存测试集上的预测结果</span>test_prediction <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>preds_in_test<span class="token punctuation">,</span> columns<span class="token operator">=</span>models_name<span class="token punctuation">)</span>test_prediction<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'test_prediction_of_7_models.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://www.kaggle.com/datasets/blastchar/telco-customer-churn">Kaggle：Telco-Customer churn（电信公司用户流失预测）</a><br>这个比赛内容有点多，下次再分享！</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://www.runoob.com/pandas/pandas-tutorial.html">菜鸟教程</a>、<a href="https://github.com/Harold-Ran/Kaggle-House-Price-Forecast">kaggle房价预测</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>时隔三月再识ViT</title>
      <link href="/2021/12/02/shi-ge-san-yue-zai-shi-vit/"/>
      <url>/2021/12/02/shi-ge-san-yue-zai-shi-vit/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/db5d72d3b4014d41b1c4ca3700f0d9eb.webp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_11,color_FFFFFF,t_70,g_se,x_16"></p><p>嘿，太累了，就休息一会吧。</p><h1 id="闲谈"><a href="#闲谈" class="headerlink" title="闲谈"></a>闲谈</h1><p>转眼间2021年就剩下一个月了，回顾十一月，没有太多的收获，拖延症及其严重，总是在学习和不想学习之间徘徊。SGD的精髓就是梯度够大，可以一直跑，慢慢总是能收敛。我总不能找到某个方向一直去努力，总是来回波动。“简单，粗暴但效果很好”的东西，我很喜欢。非常符合我喜欢的话“规则简单易懂，粗暴却完美！“关注大的方向，而不局限于细节。</p><h1 id="ViT"><a href="#ViT" class="headerlink" title="ViT"></a>ViT</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>回顾三个月前<a href="https://wuliwuxin.github.io/2021/08/15/vit/">初识ViT</a></p><p>Paper：<a href="https://arxiv.org/abs/2010.11929">https://arxiv.org/abs/2010.11929</a></p><p>Code：<a href="https://github.com/google-research/vision_transformer">https://github.com/google-research/vision_transformer</a></p><p><img src="https://img-blog.csdnimg.cn/0c81801ac0d6409aa8752dbe4f70b754.webp"></p><p>到现在为止这篇文章引用量为1629</p><p>论文题目：An Image is Worth 16x16 Words:Transformers for Image Recognition at Scale</p><p>为什么题目要叫16✖️16 word呢？</p><p><img src="https://img-blog.csdnimg.cn/552e384d3c054d11a0597bfa3da87cc0.webp"></p><p>N=224✖️224<br>W=224/16<br>H=14<br>N=14✖️14=196</p><p>这就相当于把224✖️224的图片切分成196个16✖️16的patch，此时196个patch就相当于NLP的word组成一个整体。</p><p>Transformer做大规模的图像识别。</p><p>CNN常说的两种Inductive bias（归纳偏置）</p><ul><li>Locality（局部性）。即卷积神经网络是以滑动窗口进行滑动卷积的，所以假设图片相邻区域有相邻特征。这个假设非常合理。</li><li>Translation equivariance（平移等价性）。即无论先做卷积还是先做平移，最后的结果是一样的。</li></ul><p>而Transformer 没有先验信息，都是自己学得到。</p><p>Vit是在公开数据集ImageNet-21k和Google自家的数据集JFT-300M上做预训练。结果发现大规模的预训练毕归纳偏置好。</p><h2 id="论文详解"><a href="#论文详解" class="headerlink" title="论文详解"></a>论文详解</h2><p>在大规模数据集上做预训练，然后迁移到中小型数据集使用，效果非常好。<br><img src="https://img-blog.csdnimg.cn/b7b1bbf75d3746d1828e7c3fc589f45c.webp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/7a7877e59c494db2829e616e318c0ed9.webp"></p><p>以ViT-B/16为例，将输入图片（224✖️224）按照16✖️16大小的patch进行划分，划分后会得到（224^2/16^2）=14^2=196个patch，接着通过线性映射将每个patch映射到一维向量中，以ViT-B/16为例，每个patch数据shape为[16,16,3]通过映射得到一个长度为768的向量。</p><p>对于标准的Transformer模块要求输入的是token（向量）序列，即二维矩阵[num_token,token_dim]。对于图像数据而言，其数据格式为[H,W,C]是三维矩阵。明显不是Transformer模块想要的。所以需要先通过一个Embedding层对数据做变换。</p><p>在输入Transformer encoder之前需要加入class token以及position embedding。此时[196,768]–&gt; [197,768]。这里的class token参考了<strong>BERT网络</strong>（已经阅读了，还未更新文章，我是真的太懒了）。</p><p><img src="https://img-blog.csdnimg.cn/5982ed563af34b42b165bc97a22cf6cb.webp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_12,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/a7ff6166157d4984984602430f5af1ed.webp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_10,color_FFFFFF,t_70,g_se,x_16"></p><p>ViT模型框架由三个模型块组成：</p><ul><li>Linear Projection of Flattened Patches（Embedding层）</li><li>Transformer encoder</li><li>MLP Head（最终用于分类的层结构）</li></ul><h3 id="MLP-Head"><a href="#MLP-Head" class="headerlink" title="MLP Head"></a>MLP Head</h3><p><img src="https://img-blog.csdnimg.cn/00e055a2869e4b71baaf8db5c4e85115.webp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>注意⚠️，在Transformer Encoder前有个Dropout层，后有一个Layer。<br>训练ImageNet-21K时是由Linear+TanH激活函数+Linear，但是迁移到ImageNet-1K上或者你自己的数据集上，只有一个Linear。</p><p>为什么不能在N个输出上<strong>GAP（Globally Average Pooling）</strong>得到最后的特征，为什么要加 class token去输出呢？</p><p>通过实验，得出这两种方法都可以，你可以做GAP得到一个全局特征做分类，也可用class token。作者是为了说明标准的Transformer也一样可以做视觉。</p><p><img src="https://img-blog.csdnimg.cn/0ab9191862e642cca67337fc98a27a72.webp"></p><p>公式（1）是加入class token后的结果；公式（2）是多头自注意力得出的结果；公式（3）是整体的结果；公式（4）就是class token所对应的输出当作整体图像的一个特征，做最后的分类。</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ul><li>Layers是Transformer Encoder中重复堆叠Encoder Block的次数；</li><li>Hidden Size是通过Embedding层后每个token的dim（向量的长度）;</li><li>MLP Size 是Transformer Encoder中MLP Block第一个全连接的节点个数（是Hidden Size的四倍）；</li><li>Heads代表Transformer中Multi-Head Attention的Head数。</li></ul><p>更小的Patch size计算更贵，因为序列长度增加了。</p><p><img src="https://img-blog.csdnimg.cn/65effe4069ec43f38fb1b7c71e0ec09a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>在Google JFT数据集或在ImageNet-21K进行预训练，发现结果差别不大。作者从另一个角度，即在TPUv3上的训练天数来进行对比。</p><p><img src="https://img-blog.csdnimg.cn/dc8b8f0de61b44b0ad27d8301a620534.webp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_12,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/e9ca182fa60049cd9d1902236b23fe82.webp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_11,color_FFFFFF,t_70,g_se,x_16"></p><p>随着数据集的大小不断增加，Vit的表现越来越来好。得出：小数据集用CNN较好，当数据集大小到达ImageNet-21k时，用Vit更好。</p><p><strong>用vision transformer作小样本学习是非常有前途的方向</strong>。</p><p><img src="https://img-blog.csdnimg.cn/79e2b7ed060143398438a93c1dbdfb32.webp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>左边是在五个数据集上的平均效果，发现模型现在也未到达饱和。右边是在ImageNet数据集上的表现。Hybrid是传统CNN和Transformer混合模型。</p><p><img src="https://img-blog.csdnimg.cn/781306f8bb2c4a5781b8a8f5b455ed16.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16"></p><p>头28个主成分。</p><p><img src="https://img-blog.csdnimg.cn/71084005cca64ce9a8bf14fe0c6f3177.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_12,color_FFFFFF,t_70,g_se,x_16"></p><p>余弦相似度。这里的patches大小是32✖️32的224/32=7，所以是7✖️7大小。</p><p><img src="https://img-blog.csdnimg.cn/821d3652a27549a6a92159ce1caabed2.webp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_12,color_FFFFFF,t_70,g_se,x_16"></p><p>这里有16个Head，也就是每层对应有16个点，一共有24层。</p><p><img src="https://img-blog.csdnimg.cn/f6bcd86fcf544b56bd974535ceca33cf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>如果训练次数比较少，混合模型的精确度略高一点；在迭代更多的epoch后，ViT精度会超过ViT混合模型。</p><p><img src="https://img-blog.csdnimg.cn/31b06a78ebc54caebcb1b0734d07a230.webp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>注意⚠️，在最后效果一样的地方，学习率不同，所以需要好好调参，<strong>做一个优秀的练丹师</strong>。</p><p><img src="https://img-blog.csdnimg.cn/ed509b85430f4969b7dba981ea219f47.png"></p><p>不使用位置编码比使用位置编码效果差很多，但是使用相对位置编码和绝对位置编码效果差不多，所以既可用相对位置编码，也可用绝对位置编码。因为图像块小，所以排列组合小块区别不大。</p><p>用1D和2D效果区别也不大。在源码中使用的是1D。</p><p>这篇文章还进行了大规模自监督训练。</p><h2 id="ViT的应用"><a href="#ViT的应用" class="headerlink" title="ViT的应用"></a>ViT的应用</h2><ul><li>目标检测：<a href="https://arxiv.org/abs/2012.09958">ViT-FRCNN</a>  </li><li>图像分割：<a href="https://arxiv.org/abs/2012.15840">SETR</a>  </li><li>多尺度融合：<a href="https://arxiv.org/abs/2103.14030">Swin Transformer</a>  </li></ul><p><img src="https://img-blog.csdnimg.cn/e95c16dcd2ed41f58cf255dc3c312a49.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transformer </tag>
            
            <tag> 分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初识SINet和SINetV2</title>
      <link href="/2021/11/20/chu-shi-sinet-he-sinetv2/"/>
      <url>/2021/11/20/chu-shi-sinet-he-sinetv2/</url>
      
        <content type="html"><![CDATA[<h1 id="初识SINet和SINetV2"><a href="#初识SINet和SINetV2" class="headerlink" title="初识SINet和SINetV2"></a>初识SINet和SINetV2</h1><p><img src="https://img-blog.csdnimg.cn/67e7bcfdfb624934a7d29ad8e486b868.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_19,color_FFFFFF,t_70,g_se,x_16"></p><p>我们都是穷尽自己仅有的一点天赋，来表达我们内心深处的感受。–乔布斯</p><h2 id="闲谈"><a href="#闲谈" class="headerlink" title="闲谈"></a>闲谈</h2><p><strong>对问题/知识理解的深度和广度，哪个更重要？</strong></p><p>如果一定要选一个，我会选深度。但是我常常做不到对某一东西的深刻专研，总是会被新的东西吸引，而后又忘记了原本的计划。对问题/知识的大概了解，也让我做什么都没有底气，有时又有一点不屑。嗯，我已经知道这个了。其实我只是了解了一点点东西，从此往复，我还是那个小菜鸟。我想让自己改变。钻研一件事并从头到尾的从计划到交付的一段经历，可以让你之后的旅程，尤其是你陷入一些困境的时候，给你去完成那些困住你的事情，走出泥沼的信心。了解很多事情的表面，是很难给你这样的底气的。然后，从深度到广度，可能比从广度到深度要相对容易。</p><p>不是说广度不重要，保持开放的视野，可以迅速的连接不同的资源也很有用。但能给予自己不断向前的信心的，更多的还是要靠你对这件事情的理解和对事情的掌控力。</p><p><strong>我总是很在意别人怎样了，而自己呢？</strong></p><p>这里借助人民日报夜读里的一句话，给自己一缕阳光，也给有同样困惑的小可爱们一点动力。<strong>每个人都有属于自己的‘时区’，有些人走在你前面，也有人跟在你后面，其实没有成败之分，在属于自己的‘时区’里，只要今天的你总是优于过去的你，何尝不是成功？</strong></p><h2 id="SINet"><a href="#SINet" class="headerlink" title="SINet"></a>SINet</h2><p><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Fan_Camouflaged_Object_Detection_CVPR_2020_paper.pdf">Camouflaged Object Detection</a></p><p><a href="https://github.com/DengPingFan/SINet/">代码</a></p><p>他们在推出其COD10K数据集同时提出了一种简单但是有效的解决COD的网络SINet。COD10K同时具有大类和子类的分类，包含了大量全高清1080p图片，与此同时，检测目标的全局和局部对比度更加广，意味着对模型的泛化性要求更高，更难检测，是一不错的COD数据集。他们也将COD10K与已有的COD任务数据集做了对比，以此来佐证COD10K的优势。</p><p>SINET网络整体的架构还是属于<strong>encoder-decoder</strong>的，其特点，结尾输出的loss有两个。第一个loss是用来衡量原图中有没有伪装物的，第二个loss是用来衡量模型预测的伪装物的位置准不准的，也是一个不错的想法。</p><p>伪装检测系统 (CDS) 具有多种可能的应用。</p><ul><li>医学图像分割。如果医学图像分割方法配备了针对特定对象（例如息肉）训练的CDS，则它可以用于自动分割息肉。在自然界中寻找和保护稀有物种，甚至在灾区进行搜救。</li><li>搜索引擎。搜索引擎无法检测到隐藏的蝴蝶，因此只能提供具有相似背景的图像。当搜索引擎配备了CDS（这里，我们只是简单地更改关键字）时，引擎可以识别出伪装对象，然后反馈几张蝴蝶图像。</li></ul><p><img src="https://img-blog.csdnimg.cn/db0e0fdf922f49378f3cde028caa56b7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>COD与当前数据集有所不同：</p><ul><li>它包含10K图像，涵盖78个被伪装的对象类别，例如水生，飞行，两栖动物和陆生等。</li><li>所有被伪装的图像均按类别，范围和等级进行注释。框，对象级别和实例级别的标签，从而促进了许多视觉任务，例如本地化，对象提议，语义边缘检测，任务转移学习等。</li><li>每个伪装的图像都被赋予了挑战性，可以在现实世界和消光等级标签中找到属性（每张图像大约需要60分钟）。</li></ul><p>结构可分为<strong>Search Module</strong>和<strong>Identification Module</strong>两部分，即先对图片中的伪装目标对象进行搜索（Search），然后对所有搜集到的的目标对象进行身份确（Identification）。</p><p>SINet可分为两个部分：</p><p><strong>感受野组件（Receptive Field）和部分解码器组件（PDC）</strong>。</p><p>在人类视觉中，存在一组有各种大小的感受野，有助于突出靠近视网膜中央凹的区域，该区域对微小的空间位移十分敏感。借鉴于此，该论文设计了RF模块在搜索阶段获得更多更具区分性的特征。首先，我们通过ResNet-50从输入图像中获取5个特征。</p><p>SINet利用密集连接的来保存来自不同层的更多信息，然后使用RF组件来扩大感受野。</p><p><strong>由于注意力机制可以有效地消除无关特征的干扰。</strong></p><p>本文又引入了<strong>搜索注意（Search Attention，SA）</strong>模块来增强X2的中层特征并获得增强的伪装图。</p><h2 id="SINetV2–改进版"><a href="#SINetV2–改进版" class="headerlink" title="SINetV2–改进版"></a>SINetV2–改进版</h2><p><a href="https://ieeexplore.ieee.org/document/9444794">Concealed Object Detection</a><br><a href="https://github.com/GewelsJI/SINet-V2">代码</a></p><p>这篇文章是SINet的改进版，网络结构变化改进了很多，效果提升还不错。</p><p><img src="https://img-blog.csdnimg.cn/abf5470ed9ce49a39e256663c337d0d9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>SINet模型包括搜索的前两个阶段，即<strong>搜索（负责搜索隐藏对象）和识别（用于以级联方式精确检测隐藏对象）</strong>。</p><p>**与上个版本相比，通过两个精心设计的子模块在COD领域实现了新的SOTA，包括邻居连接解码器(NCD)和组反转注意(GRA)**。</p><p><strong>三个主要模块</strong>：</p><ul><li>纹理增强模块(TEM)，用于捕获具有放大上下文线索的细粒度纹理；</li><li>邻居连接解码器（NCD），能够提供位置信息；</li><li>级联组反转注意(GRA)块，它们协同工作以改进来自更深层的粗略预测。</li></ul><p><strong>纹理增强模块(TEM)</strong><br>在人类视觉系统中，一组不同大小的人群感受野有助于突出靠近视网膜中央凹的区域，该区域对小空间位移敏感。这促使我们在搜索阶段（通常在小/局部空间中）使用TEM来合并更具辨别力的特征表示。</p><p>第一个卷积层利用1×1卷积操作（Conv1×1）将通道大小减少到32。接下来是另外两个层：一个(2i-1)×(2i-1)卷积层和一个3×3卷积层，当i &gt;1时具有特定的膨胀率(2i-1)。</p><p>然后，将前四个分支{bi,i=1,2,3,4}连接起来，并通过3×3卷积操作将通道大小减小到C。网络的默认设置C =32。最后，加入恒等shortcut分支，然后将整个模块馈送到ReLU函数以获得输出特征f’k。此外，一些工作（例如，Inception-V3）已经表明，大小为(2i-1)×(2i-1)的标准卷积运算可以分解为两个步骤的序列，其中(2i-1)×1和1×(2i-1)，在不降低表示能力的情况下加快推理效率。</p><p><strong>邻居连接解码器(NCD)</strong><br>仅聚合前三个最高级别的特征{fk∈RW /2k×H/2k×C,k=3,4,5})以获得更有效的学习能力，而不是考虑所有特征金字塔。具体来说，在获得前三个TEMs的候选特征后，在搜索阶段，我们需要定位隐藏物体。</p><p>使用邻居连接解码器(NCD)，解决聚合多个特征金字塔时仍然存在两个关键问题；即，如何保持层内的语义一致性以及如何跨层桥接上下文。</p><p><strong>Group-Reversal Attention(GRA)</strong><br><img src="https://img-blog.csdnimg.cn/05abbe1966ae4e92aa26709e978fd324.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>组合多个GRA块（例如，Gki,i∈{1,2,3},k∈{3,4,5}）以通过不同的特征金字塔逐步细化粗略预测。总体而言，每个GRA块都有三个残差学习过程。详细请看论文。</p><p><img src="https://img-blog.csdnimg.cn/b84dc53988334236a91995c273760ea2.png"></p><p><img src="https://img-blog.csdnimg.cn/130f5bcfdbb04d3cb4564f6e4d14a3f6.png"></p><p><img src="https://img-blog.csdnimg.cn/ec49651b907d4678b90a0ee3cd422745.webp"></p><h3 id="实验效果"><a href="#实验效果" class="headerlink" title="实验效果"></a>实验效果</h3><p>直接上图，就不多说了</p><p><img src="https://img-blog.csdnimg.cn/5df94c029eae4eaf8f63ecc5ead31814.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/46eecf059af34abfbe83b9c0dc3e9af7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>应用：医学（息肉分割和肺部感染分割）、制造业（表面缺陷检测）、农业（有害生物检测和水果成熟度检测）、艺术（休闲艺术和从隐蔽的物体到显眼的物体）、日常生活（透明物品/物体检测、搜索引擎）</p><p>潜在的研究方向：</p><p><strong>1、弱/半监督学习</strong><br>现有的基于深度的方法以完全监督的方式从带有对象级标签的图像中提取特征。但是，像素级标注通常由LabelMe或Adobe Photoshop工具手动标记，具有密集的专业交互，要耗费大量的精力。因此，必须利用弱/半(部分)标注数据进行训练，以避免巨大的标注成本。</p><p><strong>2、自监督学习</strong></p><p>3、其他模态的伪装目标检测<br>现有的伪装数据仅基于静态图像或动态视频。然而，其他形式的伪装对象检测可能与诸如黑夜害虫监测、机器人和艺术家设计等领域密切相关。与RGB-D SOD、RGB-T SOD和VSOD中的类似，这些模式可以是音频、热或深度数据，在特定场景下提出了新的挑战。</p><p><strong>4、伪装目标分类</strong><br>通用目标分类是计算机视觉中的一项基本任务。因此，隐蔽对象分类在未来也可能获得关注。利用COD10K提供的类和子类标签，可以构建大规模、细粒度的分类任务。</p><p><strong>5、伪装目标跟踪</strong></p><p><strong>6、伪装对象排序</strong><br>目前，伪装目标检测算法都是建立在二值化的基础上，生成伪装目标的掩模，而不分析伪装程度。然而，了解伪装的程度有助于更好地探索模型背后的机制，提供对它们的更深层次的洞察力。</p><p><strong>7、伪装对象实例分割</strong></p><p><strong>8、多任务通用网络</strong><br>不同的视觉任务之间有很强的联系。因此，它们的监管可以在一个通用系统中重用，而不会增加复杂性。考虑设计一个通用网络来同时定位、分割和排序隐藏对象是很自然的。</p><p><strong>9、神经网络搜索</strong><br>无论是传统算法还是基于深度学习的隐蔽目标检测模型，都需要具有强大先验知识或熟练专业知识的人类专家。有时，由算法工程师设计的手工制作的功能和体系结构可能不是最优的。因此，神经结构搜索技术，如流行的自动机器学习，提供了一个潜在的方向。</p><p><strong>10、将突出对象转换为隐藏对象</strong><br>将显著对象转换为隐藏对象以增加训练数据，以及在SOD和COD任务之间引入生成性对抗机制以提高网络的特征提取能力。</p><p><strong>这让我想到了ResNext是ResNet的改进版，但感觉用得ResNext没有ResNet多呢？</strong></p><p>这是因为RestNet太经典了，大家都都知道它，人们都以它为标准(属于它类型的)，一般来说如果任何人弄一个网络算法出来不以那些经典算法比较是难被认可的。即使后来的人改进ResNet且针对其不足有了很大的突破也无济于事。所以对于初学者，要将那些经典算法弄通能跑出来，今后开发的算法也要做这些比较。</p><p><strong>所以要多读文章，从一好文章找它的经典读然后再读它近期的改进文章，但要多重现好文章的算法实验。</strong></p><p><img src="https://img-blog.csdnimg.cn/24b24651b1344afaba86e3a9cac5b1c3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 其他 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>skeet</title>
      <link href="/2021/11/12/sknet/"/>
      <url>/2021/11/12/sknet/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/57163856094a46b282f8b0647b4fd9ec.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_14,color_FFFFFF,t_70,g_se,x_16"><br>一顿火锅，足以忘却暂时的不愉快。</p><h2 id="闲谈"><a href="#闲谈" class="headerlink" title="闲谈"></a>闲谈</h2><p>现在感觉每天都有新的东西需要学习，今天学习这个，明天学习那个。我觉得这样非常不好，学习什么都是在表面游走，不会有一个好的成果。具体怎么解决这个问题，我还不是很清楚，有建议的小伙伴欢迎联系我交流啊🤔。</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>SENet:<br>Paper: <a href="https://arxiv.org/abs/1709.01507">https://arxiv.org/abs/1709.01507</a><br>Code: <a href="https://github.com/hujie-frank/SENet">https://github.com/hujie-frank/SENet</a></p><p>SKNet:<br>Paper: <a href="https://arxiv.org/abs/1903.06586?context=cs">https://arxiv.org/abs/1903.06586?context=cs</a><br>Code:  <a href="https://github.com/implus/SKNet">https://github.com/implus/SKNet</a></p><p>SENet系列文章</p><ul><li>SENet</li><li>cSENet（本质相同，升降维度的超参数 r 取值为2或16），sSENet（空间角度引入注意力机制），csSENet（通道和空间两个角度同时引入注意力机制）</li><li>SKNet</li></ul><p>sSENet空间角度引入注意力机制，这个SSE模块在今年十月份的论文”<a href="https://arxiv.org/pdf/2110.07641">Non-deep Networks</a>“用到，用12层的网络在ImageNet上到达了80%（提出一个非深度网络设计的SSE模块构建了一种新型的模块RepVGG-SSE），在CIFAR10到达了96%，CIFAR100到达了81%。<br><img src="https://img-blog.csdnimg.cn/dff0e4267b1647878d7cda716c7c1053.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="SENet"><a href="#SENet" class="headerlink" title="SENet"></a>SENet</h2><p><a href="https://blog.csdn.net/wuli_xin/article/details/120397210">SENet（Squeeze-and-Excitation Networks）</a>是2017ImageNet分类比赛冠军模型。</p><p><img src="https://img-blog.csdnimg.cn/d5466e04d8e14b55bc06ee3c78831021.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>SENet的思想就是使用全局信息来增强有用的信息，同时抑制无用的信息，也就是对不同的通道进行不同的加权方法，这样有用的特征被放大，没用的就会被抑制。下面这个图就是Squeeze and Excitation Modual的主要框架。上一层输出的feature map X，它的维度是H’，W’，C’分别代表了长，宽和通道数，然后经过一个传统的卷积，会得到U，它的维度是H，W，C。下面就要进行一个SE结构。在正常的过程中加入一个旁路分枝，然后进行Squeeze操作，对U进行全局池化，压缩成一个标量。然后再进行Excitation操作，这个输出和最开始的U进行乘法，最后就得到了一个被重新加权后的feature map。</p><p><img src="https://img-blog.csdnimg.cn/bee70f647ca948bda425833f0394d8d5.png"></p><p>SENet与Inception和ResNet进行整合</p><p><img src="https://img-blog.csdnimg.cn/a87a9e75dad74eac9ca9799f112da6ea.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_10,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/8460a43711814194be45a827fe907383.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_11,color_FFFFFF,t_70,g_se,x_16"></p><p>SE block与其他架构进行整合，第一张是与Inception整合，第二张是与ResNet整合。一个是正常的Inception Modual，另一个是加入了SE block。第二个有了H✖️W✖️C的feature map，然后进行Squeeze，全局平均池化（论文里有实验），把H✖️W✖️C变为1✖️1✖️C，然后通过FC（全连接）降维，用r分之1来降低计算量，通过实验r=16效果最好。再经过ReLU，再经过FC升维，最后通过sigmoid，每个通道得到一个0到1的一个概率，就可以和原来的feature map进行一个乘法，最后输出加权后的feature map。这个ResNet与SE block 整合。和Inception整合的没有太大的区别，就是多了残差连接，SE的操作用在残差上。</p><h2 id="SKNet"><a href="#SKNet" class="headerlink" title="SKNet"></a>SKNet</h2><p>Selective Kernel Network”简称SKNet，它和SENet都是一个团队提出来的。</p><p>SKNet的思想就是利用非线性的方法整合信息，以实现动态调整感受野的大小，就是根据实际内容，找出一个最适合的感受野去适应图片。它的核心方法是Split-Fuse-Select这三个步骤。</p><p><strong>Split-Fuse-Select</strong></p><ul><li>Split: 分出多个支流，每个支流都有不同大小的filter/kernel，以此来实现不同大小的感受野;</li><li>Fuse: 整合支流的信息，然后获得selection weights;</li><li>Select: 通过selection weights来聚合feature map</li></ul><p><img src="https://img-blog.csdnimg.cn/db7cdf04d3204059b930f1d0808f3fdf.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/7f554cd001cd4685b1270155d2bac591.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p><strong>这是论文给出的架构，非常直接明了。</strong></p><p>首先是X分出来两个支流，分别是U1，U2，然后对U1，U2进行整合得到U，然后对U进行全局平均池化得到S，在对S进行FC运算得到Z,然后在分出来两个小的分支a和b，然后再对这两个小的分支之间进行softmax，然后计算一下，就是上面的计算，得到一黄一绿的矩阵，然后再用一个加法运算的合并。</p><p><strong>如何通过图片大小去调节感受野的大小呢？</strong></p><p>首先是Split的这个过程，分出来的两个支流，它们的感受野是不同的，如果图片比较大的话，就会选择感受野较大的支流，小的话，就会选择感受野小的支流，还有就是Select操作的整合，一部分来自上面，一部分来自下面，他们的比例是动态选择的。</p><p><img src="https://img-blog.csdnimg.cn/c6d83ff49897451da5cfcbc1f271202c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>这里是SKNet的完整架构。M代表的是分支数，G为group数量。这是三个网络结构图。可以看到SENet是在(1×1卷积+3×3卷积+1×1卷积)完整卷积操作后直接加入全连接层。而SKNet则是替代了ResNext中3*3卷积部分。从参数量来看，由于模块嵌入位置不同，SKNet的参数量与SENet大致相同。计算量也略有所上升。</p><p><img src="https://img-blog.csdnimg.cn/173fe5124bdd4c068bc9dc29d3dcf364.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>上表是与其他网络的横向对比，可以看出SKNet与其他常见模型，包括SENet。可以看到SKNet取得了最好的结果。</p><p><img src="https://img-blog.csdnimg.cn/5807f2e288d047ae942d52254022a7b0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>分析了D和G对模型的影响，可以看出最好的情况时3乘3，D=2，G=32和5乘5，D=1，G=64这两种情况。</p><p><img src="https://img-blog.csdnimg.cn/1519069d336c45e5affab1d12178122e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>然后是不同组合对模型的影响，论文得出提升分支数(M)，错误率总体减少，使用SK比不使用SK更好，在使用SK后，提升分支数对于模型精度的提升变得微小。</p><p><img src="https://img-blog.csdnimg.cn/2721040badd0491b9b41ed1fde13121a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>然后还分析了attention weights，就是从Z分出来的两个小支流，论文得出当物体的大小增加时，attention weights在5✖️5路径总体也增加，也就意味着感受野增加。</p><p><img src="https://img-blog.csdnimg.cn/33c453422d3549738dc22cd90b97f4a3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>上图是attention weights平均值的差值。</p><p>论文得出在早期的layer里，物体变大，更大的attention 增加。在后期的layer里，这个规律就不存在了，也就意味着后期的layer的SK可以替换成其他的单元。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>SENet提出了Sequeeze and Excitation block，而SKNet提出了Selective Kernel Convolution.</li><li>SENet和SKNet都是可直接嵌入网络的轻量级模块，比如ResNet、Inception、ShuffleNet，实现精度的提升。</li></ul><p><img src="https://img-blog.csdnimg.cn/7625ae9fd0944ec1a9cefde118ad21c9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021年10月总结</title>
      <link href="/2021/11/08/2021-nian-10-yue-zong-jie/"/>
      <url>/2021/11/08/2021-nian-10-yue-zong-jie/</url>
      
        <content type="html"><![CDATA[<blockquote><p>总有一个阳光的人，带给你温暖。<br>如果没有，请学会自己照亮自己。</p></blockquote><p>距离上次更新已经过去了一个多月了，感谢各位的关注。昨天也立冬了，广东的天气也逐渐凉爽了。简单说来，十月我主要干了两件事：华<strong>为杯数学建模和软考高项</strong>。这一期，也是想简单的记录一下自己的经历和闲谈。</p><h2 id="两件事"><a href="#两件事" class="headerlink" title="两件事"></a>两件事</h2><p>小吴准备先从时间上说一下十月具体的时间分配啊🤔。</p><p>十月的开始是美好的，国庆长假😄。小吴先去逛了学校附近的景点和朋友一起去吃了大餐，追了甜甜的剧–《程序员那么可爱》和《暗格里的秘密》，大家不要像我一样，整天躺在床上刷剧啊😢。当然看这种剧，拜托大家不要带脑子，就是看看男女主的情节发展，特别是第一部啊，小吴就是觉得程序员的浪漫很特别，嘻嘻😁。</p><p>举个例子🌰：</p><p>男女主求婚的对话：<br>“你愿意在你的方法里，加上我这么一个参数，从此共享内存，进入婚姻的死循环吗？”<br>“本系统支持这个请求！”<br>🥰</p><p>咳咳，说远了，该说说正题了。国庆前三天过于放纵，后天四天就要开始学习了。华为杯数学建模本来是中秋节前就应该结束的，主办方呢又推迟到了十一月中旬。也许是开心的事情，可以多一点时间准备嘛。但是恰好，在十月我的好几门课都需要做PPT汇报以及每周的组会。好在，老师们都很谅解我们，由于建模比赛要五天，所以那周的组会取消了。小小开心了一下❤️。这里必须要申明一下，小吴很爱学习的，学习是我快乐！</p><p>国庆后面的四天假期，我基本就是准备建模和刷软考的选择题。上了两天课，又到了我们的组会时间，不得不说，时间过的真快啊。因为比赛时间是10月14日，所以在这之前呢，就一边上课一边准备建模。建模五天可以说是真的很认真了，我不追求得奖。对于我来说就是完成赛题，最后能成功提交论文。</p><p>建模比赛完，十月就已经过了一大半了，18号了。没错，剩下还有近三周就要考试了。考试的论文和案例分析还没准备呢，而且考试那周组会我还要汇报。可以说时间很紧张了。回忆这次组会，我可以说真的划水了，讲了SENet和SKNet（过两天也会更新这两篇论文，我预计在这周三），感觉自己讲的不是很清楚，虽然我导师没说什么（我导向来鼓励为主），但是我自己感到很惭愧。十月的目标还有看完《<strong>被讨厌的勇气</strong>》，好在在11月1号看完了，但是70KM的跑步🏃‍♀️，没有完成呢，只完成了大约一半。</p><p><img src="https://img-blog.csdnimg.cn/af0a075f2cf8402d87c6267fd699824c.png"></p><p>对了，十月广东这边还经历了一次<strong>圆规台风</strong>，第一次因为台风停课，见识浅薄了，莫见笑！</p><p>总的说来，国庆前三天过于放纵，<strong>十月没有周末</strong>，十一月又持续了一周。</p><h3 id="数学建模"><a href="#数学建模" class="headerlink" title="数学建模"></a>数学建模</h3><p>由于我们组三人和老师都是第一次参见这个比赛，理解错了截止提交时间，在最后一分钟才提交论文。</p><p><img src="https://img-blog.csdnimg.cn/35b2491fa46349ff8101ac78c381738e.png"></p><p><strong>总结一次这次比赛的经历。</strong></p><p>比赛这五天，其他所有事情和作业都被搁置了，专心比赛。前几天我和一个小伙伴一直在弄数据，另一个小伙伴做图，导致我们的论文差不多在最后一天才开始写。这是不科学的。较好的做法的，完成一个小题目，就把对应的题目结果和解析写完。最后一天还熬了夜。可以说我是被迫熬夜的，看着还差这么多没写，<strong>我怎么睡的着啊</strong>。就算我躺在床上，我也难以入睡啊，毕竟办公室还有好多小组成员都在抓紧时间做结果。真的也不是我作啊。这里我也和小伙伴们出现了分歧。没事的，新的团队难免有一点意见不统一嘛。我把我能写的、想到的、看过的、有用的内容都写上去了。</p><p><img src="https://img-blog.csdnimg.cn/53946e5e4efd4e5c8ed1214e32c91148.png"></p><p><img src="https://img-blog.csdnimg.cn/119a9c36efba43c7a804f73998e19228.png"></p><p><strong>看到了学校早上六点半的升旗和考研人的勤奋学习，食堂阿姨忙碌和清洁大叔忙碌的身影</strong>。想到，如果不是比赛，我还在呼呼大睡呢，别人早已为了心中的目标而奋斗了。</p><p>同时，我很庆幸那晚的坚持，因为第二天中午就截止了，大家都以为还有一天时间。我已经做了我该做的。早上，老师和另一个小伙伴，也抓紧时间对论文进行了修改和补充。<strong>如果不能完成，这件事对于我的沉没成本太大了，一定要达到预定的目标，成功提交论文</strong>。</p><p>一次建模相当于一次毕业设计，最后论文有56页。我都震惊🤯了，我们组这么能写。</p><h4 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h4><p>首先我们团队缺少沟通，做了一些重复的工作，有时也没有在一起讨论。沟通很重要，充分沟通能提高效率。然后是论文的排版有很大的问题，我现在都不敢看比赛的论文。最后是时间的分配问题，没有合理的分配和规划。</p><p>希望自己明年比赛能够做的更好。</p><h3 id="准备考试"><a href="#准备考试" class="headerlink" title="准备考试"></a>准备考试</h3><p>我参加了2021年的考试，可惜论文没过。这次我也好好准备了论文，自我感觉写的还可以，就是下午的案例分析计算题，我感到了很迷，数据很多，题目没看这么懂。保佑🙏，我这次一定要过啊。嘻嘻😁</p><p>考试的具体情况，我之前也写了一篇文章，感兴趣的同学可以去看看。这门考试还是很有用的。<a href="https://wuliwuxin.github.io/2021/06/29/xin-xi-xi-tong-xiang-mu-guan-li-shi-bei-kao-jing-yan/">信息系统项目管理师备考经验及注意事项</a></p><p><strong>这考试感觉还有点励志哟</strong>。五十几岁的大叔大妈在考试，大肚子的小姐姐也坚持考完了。作为小年轻的我们，怎能不坚持考完呢。当然，这个考试的缺考了也很高。我们考场30个人，有10个没来。🤔，这是为什么呢？都交钱了，别浪费啊。</p><p><img src="https://img-blog.csdnimg.cn/11a23eec35584aab9c39bbf2756a1964.png"></p><p>总体来说，这次题目还是有点意外的，综合知识很多都是较新的内容。</p><p><strong>没事，我能过，我能过，我能过！<br>重要事情说三遍，不接受反驳。</strong></p><h2 id="闲谈"><a href="#闲谈" class="headerlink" title="闲谈"></a>闲谈</h2><p>没有逻辑的闲谈，虽然我的逻辑也不怎么好。</p><p>前段时间，看到<strong>何同学</strong>更新了，突然有一点小思考。何同学，三月更新一个视频，<strong>每个视频都是精华</strong>。真正的转变，是那条《有多快？5G在日常使用中的真实体验》视频的发布。</p><p>在这条视频中，何同学通过下载各种APP实录亲测了5G网速在日常中的应用，有对4G时代的回顾，有对5G未来的畅想，最后的主题升华还让许多网友直呼“全文背诵”。</p><p>自己的二十几岁和别人的二十几岁怎么就相差这么远呢？视频带给我们焦虑感，每次看视频都感觉自己是废材，优秀的人一直在努力！同时，我又会问自己，平凡不好吗？普通不好吗？普通且平凡的快乐也许他们也体会不到啊。强行安慰自己🤣。</p><p>根据友谊的深浅，我们的目的各有不同。有些友谊是为了获得经济支持，有些友谊是为了单纯的快乐，有些友谊是为了获得情感支持，而最好的友谊，是寻求一种灵魂的彼此托付——我们给予对方最大的自由和宽容，同时也将自我的可能性开放到最大，我们为朋友做的一件小小的事情，哪怕那个朋友永远不知道，也能让我们的内心充满巨大的快乐。</p><p>习惯是一个很可怕的东西，当你一个人的时候还没觉得有什么，从两个人再回到一个人的状态那种不适和茫然顿时如潮水一般涌来。</p><p><strong>做很多事情，都需要毅力和决心</strong>。一天不行，一个月；一个月不行，一年；有决心的人，啥学历、智商或资历，那都是借口。</p><p>朋友或熟人的数量没有任何价值。这是与爱之主题有关的话题，我们应该考虑的是关系的距离和深度。这句话是我便签里的，仅供参考。</p><p><strong>十一月，按部就班，回归正轨了，论文也会持续更新了！十一月加油</strong>⛽️</p><p><strong>天冷了，小可爱们注意保暖！</strong></p><p><img src="https://img-blog.csdnimg.cn/150b03a0d09d4c20b993d5f2e065c781.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 总结与反思 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 反思 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>小样本学习和元学习基础知识</title>
      <link href="/2021/09/30/xiao-yang-ben-xue-xi-he-yuan-xue-xi-ji-chu-zhi-shi/"/>
      <url>/2021/09/30/xiao-yang-ben-xue-xi-he-yuan-xue-xi-ji-chu-zhi-shi/</url>
      
        <content type="html"><![CDATA[<h1 id="小样本学习和元学习基础知识"><a href="#小样本学习和元学习基础知识" class="headerlink" title="小样本学习和元学习基础知识"></a>小样本学习和元学习基础知识</h1><p><img src="https://img-blog.csdnimg.cn/e849b63f342f4da69ff89eeb41d3b700.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>人工智能最终依赖于大数据中学习。很难用很少的数据快速概括一个模型。相反，人类可以快速应用他们过去学到的东西来学习新事物。一个重要的方向是缩小人工智能与人类之间的差距。通过有限数据进行学习。</p><h2 id="少样本学习（few-shot-learning）"><a href="#少样本学习（few-shot-learning）" class="headerlink" title="少样本学习（few-shot learning）"></a>少样本学习（few-shot learning）</h2><p>深度学习是data hunger的方法， 需要大量的数据，标注或者未标注。少样本学习研究就是如何从少量样本中去学习。拿分类问题来说,每个类只有一张或者几张样本。少样本学习可以分为zero-shot learning（即要识别训练集中没有出现过的类别样本）和one-shot learning/few shot learning（即在训练集中，每一类都有一张或者几张样本）。</p><p>人类是有少样本学习的能力。以zero-shot learning来说，比如有一个中文 “放弃”，要你从I, your, she, them, abnegation 五个单词中选择出来对应的英文单词，尽管你不知道“放弃”的英文是什么，但是你会将“放弃”跟每个单词对比，而且在你之前的学习中，你已经知道了I, your, she, them的中文意思，都不是“放弃”,所以你会选择abnegation。</p><p>首先明确几个概念<br>（1）<strong>support set</strong> :每次训练的样本集合<br>（2）<strong>query set</strong> :用于与训练样本比对的样本，一般来说query set就是一个样本<br>（3）在support set中，如果有n个种类，每个种类有k个样本，那么这个训练过程叫n -way k-shot ，如下图就是5-way 1-shot。</p><p><img src="https://img-blog.csdnimg.cn/421ebb198f5741ce879c58d68f7c0a16.webp"></p><p><img src="https://img-blog.csdnimg.cn/6e3b6eb3b6c14bb7a74e2726c9352266.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="元学习（meta-learning）"><a href="#元学习（meta-learning）" class="headerlink" title="元学习（meta learning）"></a>元学习（meta learning）</h2><p><strong>元学习是要“学会如何学习”</strong>，即利用以往的知识经验来指导新任务的学习，具有学会学习的能力，元学习被视为实现通用人工智能（Artificial   General Intelligence，AGI）的基础，也必将令人工智能走出深度学习的困境。目前，元学习方法主要分为：度量方法、模型方法、优化方法以及基于数据增强。</p><p>基于度量的元学习的核心思想类似于最近邻算法(k-NN分类、k-means聚类)和核密度估计。该类方法在已知标签的集合上预测出来的概率，是support set中的样本标签的加权和。权重由核函数计算得出，该权重代表着两个数据样本之间的相似性。Convolutional Siamese Neural Network提出了一种用孪生网络做one-shot image  classification的方法；Matching  Network对support set进行特征提取后，在embedding空间中利用Cosine来度量，通过对测试样本计算匹配程度来实现分类；Relation Network关系网络提出的relation module结构替换了Matching Network和Prototypical Network中的Cosine和欧式距离度量，使其成为一种学习的非线性分类器用于判断关系，实现分类；Prototypical Network利用聚类思想，将support set投影到一个度量空间，在欧式距离度量的基础上获取向量均值，对测试样本计算到每个原型的距离，实现分类。然而，虽然训练模型不需要针对测试任务进行调整，但当测试与训练任务距离远时，效果不好，另外，当任务变得更大时，逐对比较会导致计算成本昂贵。</p><p>meta learning 是学习如何学习，few-shot learning 是要达到的目标（用一点点训练资料就可以训练出我们要的结果）。为什么觉得meta learning 和few-shot learning 像呢？就是希望达到few-shot learning，想要一个学习演算法只看到一点点资料就可以学起来。few-shot learning的Algorithm往往是用meta learning 得到的。</p><p><img src="https://img-blog.csdnimg.cn/4021a13ebb064e219f0780151abaa086.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/34c373d39aa846af94999eb5b3b2afe5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/87c122a4d219437b99fec591d6dae1fb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/d19af60b396246dd86112414952c0d52.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_14,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/97e5bb00ea3648faa71aad4b429291b8.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_13,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/aac57dac99f44d728e6b6206963a0c02.webp"></p><p>k-way是support set 里有多少个类别；n-shot是每个类别有多少个例子。</p><p>如果做few-shot 分类，预测的准确率会受support set 的类别数量和样本数量影响。随着分类类别数量增加，准确率会降低；随着number of shot的增加预测值会增加。</p><p>学一个函数来判断相似度。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p><strong>Omniglot数据集</strong></p><p><a href="https://github.com/brendenlake/omniglot/">Office website</a></p><p><a href="http://tensorflow.org/datasets/catalog/omniglot/">Tensorflow</a></p><p>常用的数据集：Omniglot是meta learning最常用的数据集。这个数据集不大，只有几兆，很适合学术界使用。Omniglot有点类似MNIST。MNIST有10个类每个勒有6000个样本；Omniglot的类别很多，每个类的样本却很少，有1600多个类，每个类只有20个样本。</p><p><img src="https://img-blog.csdnimg.cn/f788320fe2a14a598790a6a403922c95.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_17,color_FFFFFF,t_70,g_se,x_16"></p><p>另一个数据集是Mini-ImageNet。一共有100类，每个类有600个样本，样本是84*84的小图片。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">https<span class="token punctuation">:</span><span class="token operator">//</span>deepai<span class="token punctuation">.</span>org<span class="token operator">/</span>dataset<span class="token operator">/</span>imagenet<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>分类问题：<br>（1）Siamese Neural Network<br>（2）Matching Network<br>（3）Prototypical Network<br>（4）Relation Network</strong></p><p>介绍两种训练方法。第一种是每次取两个样本，比较它们的相似度，需要用大的数据集，每类有标注，每类下面有很多个样本。用训练集构造正样本和负样本，正样本告诉神经网络什么东西同一类，负样本可以告诉神经网络它们的区别。正样本是通过每次抽取一张图片，然后从同一类中随机抽取另一张图片，标签设置为1。负样本是随机抽取一张图片，然后排出这类，在其余类中随机抽取一张，两张图片类别不同，标签设置为0。</p><p><img src="https://img-blog.csdnimg.cn/4182b992195c43d598839fefd78d217c.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_16,color_FFFFFF,t_70,g_se,x_16"></p><p>希望神经网络的输出接近标签，把标签和预测的差别记为损失函数，可以是cross entropy。有了损失函数就可以用反向传播来计算梯度，然后用梯度下降来更新模型参数。</p><p>Siamese Network是计算两两之间的相似度。另一种方法是triplet Loss。每次需要三张图做一轮训练，首先从训练集中随机选一张图片作为anchor（锚点），记录下这个锚点，然后从该类别中随机抽取一张图片作为正样本，然后排出这个类别，做随机抽样，得到一个负样本。</p><p><img src="https://img-blog.csdnimg.cn/f1b878e924d14b989b834f62dfe4e61a.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_14,color_FFFFFF,t_70,g_se,x_16"></p><p>Prototypical Networks是基于这样一种思想，对于每个类别，都存在一个嵌入空间中的点，称为类的原型，每个样本的嵌入空间表示都会围绕这个点进行聚类。为了做到这一点，即利用神经网络的非线性映射将输入映射到嵌入空间，并将嵌入空间中支持集的平均值作为类的原型。预测分类的时候，就只需要比较跟支持集类别的哪个类的原型更近了。</p><p>基于度量的元学习的核心思想类似于最近邻算法(k-NN分类、k-means聚类)和核密度估计。该类方法在已知标签的集合上预测出来的概率，是support set中的样本标签的加权和。权重由核函数计算得出，该权重代表着两个数据样本之间的相似性。因此，学到一个好的核函数对于基于度量的元学习模型至关重要。度量元学习正是针对该问题提出的方法，它的目标就是学到一个不同样本之间的度量或者说是距离函数。任务不同，好的度量的定义也不同，但它一定在任务空间上表示了输入之间的联系，并且能够帮助我们解决问题。</p><p><strong>Siamese Neural Network</strong>孪生网络做one-shot  image  classification的方法；<strong>Matching Network</strong>对support set进行特征提取后，在embedding空间中利用Cosine来度量，通过对测试样本计算匹配程度来实现分类；<strong>Relation  Network</strong>关系网络提出的relation  module结构替换了MatchingNet和Prototypical Net中的Cosine和欧式距离度量，使其成为一种学习的非线性分类器用于判断关系，实现分类；<strong>Prototypical Network</strong>利用聚类思想，将support set投影到一个度量空间，在欧式距离度量的基础上获取向量均值，对测试样本计算到每个原型的距离，实现分类。</p><p>然而，虽然训练模型不需要针对测试任务进行调整，但当测试与训练任务距离远时，效果不好，另外，当任务变得更大时，逐对比较会导致计算成本昂贵。基于度量的元学习方向倾向于最大程度上抽取任务样本内含的特征，使用特征比对的方式判定样本的种类，因此如何提取最能代表样本特点的特征便成为了该方向研究重点。相比于普通学习得到的特征表示，元学习得到的特征表示（Meta-learned Representations）是有区别的，更有助于少样本学习。</p><p>使用元学习的特征表示能够提升少样本学习的效果，作者归为两种不同的机制：<br>（1）固定特征提取模块的参数，只更新（微调）最后的分类层（Classification Layer）参数。在这种机制下，类别数据点在特征空间中会更加聚集，那么在微调时，分类边界对于提供的样本会没那么敏感。<br>（2）在模型参数空间寻找最优点作为基础模型，该最优点接近大部分特定任务（Task-specific）模型参数的最优点，那么在面对新的特定任务时，能够通过几步的梯度计算，将基础模型更新为适用于新任务的特定模型。<br>后续会持续更新关于小样本学习的文章。</p><p>每天按时吃饭绝不敷衍，致力于不断寻找更多的人类美食，然后……然后我就胖了。</p><p>大家也要按时吃饭哟♥️</p><p>祝大家国庆节快乐哇！😁</p><p><img src="https://img-blog.csdnimg.cn/f6b5de354f5c45ccbccb843b8dcb3b28.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小样本学习 </tag>
            
            <tag> 元学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SENet</title>
      <link href="/2021/09/21/senet/"/>
      <url>/2021/09/21/senet/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉–SENet"><a href="#带你读论文系列之计算机视觉–SENet" class="headerlink" title="带你读论文系列之计算机视觉–SENet"></a>带你读论文系列之计算机视觉–SENet</h1><p><img src="https://img-blog.csdnimg.cn/484b3d0598274f649859636c5d8360db.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="闲谈"><a href="#闲谈" class="headerlink" title="闲谈"></a>闲谈</h2><p>总有那么瞬间思念远方的故人。八月十五中秋节，让我们放下繁忙工作，回家与老人团圆举杯共餐。这是我第一次没有在家过中秋，感觉也还行。现在节日没有什么节日气氛，最重要的家人团聚。各位小可爱们，中秋佳节，愿你快快乐乐，开开心心；健健康康，轻轻松松；团团圆圆，恩恩爱爱；和和美美，红红火火！❤️</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong><a href="https://arxiv.org/abs/1709.01507">论文：Squeeze-and-Excitation Networks</a></strong></p><p><strong><a href="https://github.com/hujie-frank/SENet">代码</a></strong></p><p>一个可嫁接/整合的Block 😇</p><p>Momenta在ImageNet2017挑战赛中夺冠的网络架构SENet。本文作者为Momenta高级研发工程师胡杰。</p><p><img src="https://img-blog.csdnimg.cn/ef6dea9093a14374b523b55812927da1.jpg"></p><p>Momenta成立于2016年，是<strong>自动驾驶公司</strong>。其核心技术是基于深度学习的环境感知、高精度地图、驾驶决策算法。产品包括不同级别的自动驾驶方案，以及衍生出的大数据服务。Momenta专注于“打造自动驾驶大脑”，拥有世界专业的深度学习专家，如图像识别领域框架Faster R-CNN和ResNet的作者， ImageNet 2015、ImageNet 2017、MS COCO Challenge 2015等多项比赛。团队成员主要来源于清华大学、麻省理工学院、微软亚洲研究院等高校及研究机构，以及百度、阿里、腾讯、华为、商汤等知名高科技公司，拥有深厚的技术积累、极强的技术原创力和丰富的行业经验。</p><p><img src="https://img-blog.csdnimg.cn/91909f8d91df4396b95de758eec80cc7.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>SENet获得了ImageNet2017大赛分类任务的冠军，这也是最后一届ImageNet比赛，论文同时获得了CVPR2018的oral。而且，SENet思路简单，实现方便，计算量小，模块化涉及，可以无缝嵌入主流的网络结构中，实践不断证明其可以使得网络获得更好的任务效果。</p><p>卷积核作为卷积神经网络的核心，通常被看做是在局部感受野上，将空间上（spatial）的信息和特征维度上（channel-wise）的信息进行聚合的信息聚合体。卷积神经网络由一系列卷积层、非线性层和下采样层构成，这样它们能够从全局感受野上去捕获图像的特征来进行图像的描述。</p><p><strong>摘要</strong></p><ol><li>卷积操作是CNN核心其可融合空间和通道的特征；</li><li>已经有人研究增强空间特征的提取；</li><li>本文针对通道特征提出SEblock，其可自适应的校正通道特征；</li><li>SEblock可堆叠成SENet，并在多个数据集上获得较好的效果；</li><li>SENet仅增加少量参数，就大幅提升精度；</li><li>获得ILSVRC冠军；</li></ol><p>对ImageNet数据集进行了广泛评估。SENets不局限于某个特定的数据集或任务。通过利用SENets，我们在ILSVRC2017分类竞赛中排名第一。我们的最佳模型集合在测试集上实现了2.251%的最高5级错误1。与前一年的冠军作品相比，这代表了大约25%的相对改进（前五名的误差为2.991%）。</p><p>从通道维度入手，设计SEBlock。提出一种机制可对特征进行校正，校正后的特征可保留有价值的特征，剔除没价值的特征，即注意力机制。</p><p><img src="https://img-blog.csdnimg.cn/7fa8d4911eee4ff6b552da5cf06f1f53.webp"></p><p>SE构建块的结构如上图所示。特征首先通过Squeeze操作，它通过在其空间维度（H×W）上聚合特征图来产生通道描述符。该描述符的功能是生成通道特征响应的全局分布的嵌入，允许来自网络的全局感受野的信息被其所有层使用。聚合之后是激励操作，它采用简单的self-gating mechanism的形式，将嵌入作为输入并产生每通道调制权重的集合。这些权重应用于特征映射U以生成SE块的输出，该输出可以直接馈入网络的后续层。可以通过简单地堆叠SE块的集合来构建SE网络(SENet)。此外，这些SE块还可以用作网络架构中一定深度范围内原始块。</p><h2 id="论文详情"><a href="#论文详情" class="headerlink" title="论文详情"></a>论文详情</h2><p>思路：让我们的神经网络使用全局信息来<strong>增强</strong>有用的信息，同时<strong>抑制</strong>无用的信息。</p><p>假设：</p><p><img src="https://img-blog.csdnimg.cn/83a0f10804c8494da40c9bcc705704eb.png"></p><p>其中，</p><p><img src="https://img-blog.csdnimg.cn/ab5d2fd0e8a7479b82ced746b1513ee5.webp"></p><p>令K = [K1，K2,…..KC]，其中每个元素Ki为filter kernel<br>于是：</p><p><img src="https://img-blog.csdnimg.cn/8ce688fc37f741abbab3396c14a21b8a.webp"></p><p>其中*代表了conv运算（忽略bias）</p><p><strong>Squeeze阶段</strong>：</p><p><img src="https://img-blog.csdnimg.cn/74c2475d20b544ef8a31ec13790a49ed.webp"></p><p><strong>Excitation阶段</strong>：<br><img src="https://img-blog.csdnimg.cn/00c904406c6049f5a3ade629be8c71a2.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>VGGNets和Inception模型表明，增加网络的深度可以显着提高其能够学习的表示质量。通过调节每层输入的分布，批量归一化(BN)为深度网络中的学习过程增加了稳定性，并产生了更平滑的优化表面。在这些工作的基础上，ResNets证明了用shortcut connection来学习更深入、更强大的网络是可能的。Highway Networks引入了一种self-gating machine来调节信息流捷径连接。在这些工作之后，网络层之间的连接有了进一步的重构，其中显示了对深度网络的学习和表示特性的有希望的改进。</p><ol><li>分组卷积：ResNeXt</li><li>多分支网络GoogLeNet系列</li><li>1*1卷积的应用：Xception 等</li></ol><p>以往的研究通道之间关系时，采用的是局部信息。本论文提出的方法采用全局方法。</p><p>设计和开发新的CNN 架构是一项困难的工程任务，通常需要选择许多新的超参数和层配置。相比之下，SE块的结构很简单，可以直接用于现有的最先进的架构中，通过用SE对应的组件替换，可以有效提高性能。SE模块在计算上也是轻量级的，只在模型复杂性和计算负担上有轻微增加。</p><p><strong>SENet优势</strong>：</p><ol><li>SE block设计简单，即插即用;</li><li>SE block参数少</li></ol><p>Google团队提出MnasNet（<a href="http://arxiv.org/pdf/1807.11626.pdf">MnasNet:Platform-AwareNeuralArchitectureSearchforMobile</a><br>）使用强化学习的思路，提出一种资源约束的终端CNN模型的自动神经结构搜索方法。MnasNet中用了SEblock。</p><ol><li>注意力机制可理解为将最有意义的部分给予更多“关注”；</li><li>注意力机制已在序列学习图像理解、定位、图像描述、唇语识别任务中广泛应用；</li><li>本论文的block 则是针对通道维度进行注意力机制。</li></ol><p><img src="https://img-blog.csdnimg.cn/9c179586c6434219968ed96c2ebf8655.webp"></p><p>首先是 Squeeze 操作，我们顺着空间维度来进行特征压缩，将每个二维的特征通道变成一个实数，这个实数某种程度上具有全局的感受野，并且输出的维度和输入的特征通道数相匹配。它表征着在特征通道上响应的全局分布，而且使得靠近输入的层也可以获得全局的感受野，这一点在很多任务中都是非常有用的。</p><p>其次是 Excitation 操作，它是一个类似于循环神经网络中门的机制。通过参数 w 来为每个特征通道生成权重，其中参数 w 被学习用来显式地建模特征通道间的相关性。</p><p>最后是一个 Reweight 的操作，我们将 Excitation 的输出的权重看做是经过特征选择后的每个特征通道的重要性，然后通过乘法逐通道加权到先前的特征上，完成在通道维度上的对原始特征的重标定。</p><p>SE网络可以通过简单地堆叠SE构件块的集合来生成。SE块也可以用作体系结构中任何深度的原始块的直接替换。但是，虽然构建模块的模板是通用的，它在不同深度处的角色适应网络的需求。在早期层中，它学会以类不可知的方式激发信息特性，支持共享的底层表示的质量。在后面的层次中，SE块变得越来越专业化，并以 highly class-speciﬁc的方式响应不同的输入。因此，SE块进行特征重新校准的好处可以通过整个网络进行累加。SE块的设计很简单，可以直接与现有最先进的体系结构一起使用，这些体系结构的模块可以通过直接替换SE模块来加强。</p><p><img src="https://img-blog.csdnimg.cn/6115c7639cf449908274c0db1255c302.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>用公式描述conv2d过程，并且将卷积核按通道维度来理解。</p><p>conv2d操作将空间信息与通道信息混合到了一起。本文目的是提高通道维度上信息的敏感度，具体操作为Squeeze和excitation。</p><p><img src="https://img-blog.csdnimg.cn/5ad66bafc9f74dd09fbd457e8555668b.webp"></p><p><strong>提出问题</strong>：U没有很好的利用局部感受野之外的上下文信息。<br><strong>解决问题</strong>：利用全局池化，将空间信息压缩为通道描述符，即数据变为通道维度的形式。该操作可看为图像的局部描述算子，这样的操作在特征工程常见。</p><ol><li>为了获取通道之间的信息，加入Excitation；</li><li>为实现该目标，需要遵循两个准则：<br>（1）该操作要能学习通道之间的非线性关系；<br>（2）确保多个通道能够被“强调”；</li><li>采用sigmoid 机制来实现；</li></ol><p><img src="https://img-blog.csdnimg.cn/eeeaafdefa2e4af8bf1871555806d585.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>上图为激活函数挑选的实验。结论：sigmoid最好。</p><p>与其他架构进行整合。论文中把ResNet和Inception进行整合。如下两张图所示。</p><p><img src="https://img-blog.csdnimg.cn/f4d9a1cc2dbd45b88a9e237d6650b879.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_18,color_FFFFFF,t_70,g_se,x_16"></p><p>原始Inception模块（左）和SE-Inception模块（右）的架构。</p><p><img src="https://img-blog.csdnimg.cn/9fb1eb5c9bd3430fab265324b0972431.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_16,color_FFFFFF,t_70,g_se,x_16"></p><p>原始Residual模块（左）和SE-ResNet模块（右）的模式。</p><p><img src="https://img-blog.csdnimg.cn/1d253d3575fa49d4823a072c6f93e7a2.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_13,color_FFFFFF,t_70,g_se,x_16"></p><p>作为这种轻微的额外计算负担的交换，SE-ResNet-50的准确性超过了ResNet-50的准确性，并且实际上接近了需要~7.58GFLOPs的更深的ResNet-101网络的准确性。</p><p>FC层的权重参数引入的总数由下式给出：</p><p><img src="https://img-blog.csdnimg.cn/5680c30e158b42e2aafa2c534d676491.webp"></p><p>其中r表示缩减率，S表示阶段数（阶段是指在公共空间维度的特征图上操作的块的集合），Cs表示输出通道的维度，Ns表示阶段重复块的数量（当偏置项用于FC层时，引入的参数和计算成本通常可以忽略不计）。SE-ResNet-50引入了超过250万个额外参数。</p><ol><li>一个block是2C^2/r ；</li><li>一个stage有N个block ；</li><li>一个模型有S个stage 所以得到以上公式；</li></ol><p>SEblock插入CNN中是很灵活的，因此有多个方式。<br><img src="https://img-blog.csdnimg.cn/4d5f8f6122dd42b38d341b384fa404a3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_17,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/333e4cac1d5a4a02af378d0ca1a6bc34.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>三种变体：(1)SE-PRE块，其中SEblock在残差单元之前移动；(2)SE-POST块，其中SE单元在与恒等分支求和后移动（在ReLU之后）和(3)SE-Identity 块，其中SE单元放置在与残差单元平行的恒等连接上。这些变体如图5 所示，每个变体的性能在表14中报告。我们观察到SE-PRE、SE-Identity和提议的SE块的性能相似。</p><p>SE-ResNet完整架构✊</p><p><img src="https://img-blog.csdnimg.cn/2412575adb884c4cb8b1cb03245a15cd.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>（左）ResNet-50。（中）SE-ResNet-50。（右）带有32×4d模板的SE-ResNeXt-50。括号内列出了残差积木的特定参数设置的形状和操作，而在外面显示了一个阶段中堆叠的积木数量。Byfcin后面的内括号表示一个SE模块中两个全连接层的输出维度。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><strong>讨论点</strong></p><ol><li><strong>横向对比</strong><br><img src="https://img-blog.csdnimg.cn/49a1e434888b42a0a6655e120fccc089.png"><img src="https://img-blog.csdnimg.cn/1fd9ea44a10b4bf696a33d3cb4dc92a0.webp"></li></ol><p>数值越小越好。</p><ol start="2"><li> <strong>调整Reduction比率</strong></li></ol><p>Reduction比率空值这Dense layer 1 的neuron的数量</p><p><img src="https://img-blog.csdnimg.cn/86196e1b5365481f9b4a9777b3aadece.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_18,color_FFFFFF,t_70,g_se,x_16"></p><p>论文推荐r = 16</p><ol start="3"><li>  <strong>GAP v.s. GMP</strong><br><img src="https://img-blog.csdnimg.cn/043aa86d7c294f70943c589036d85096.webp"></li></ol><p>结果显示用Avg Pooling更好</p><ol start="4"><li><p>  <strong>Excitation 阶段中不同的Activation函数对比</strong><br><img src="https://img-blog.csdnimg.cn/d58675d28a134da9825058643e1faa87.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p></li><li><p>  <strong>SE Block的不同位置</strong><br><img src="https://img-blog.csdnimg.cn/c0e6c3e706fe47c3aad9a0a161ed3b74.webp"></p></li></ol><p>结果显示结果都差不多。</p><ol start="6"><li>  <strong>SE Block在ResNet的不同位置</strong><br><img src="https://img-blog.csdnimg.cn/0a7333b5d93b415a97b955c6b2239ba5.webp"></li></ol><p>把SE Block都安插进去效果最好！在深层安插比浅层效果好一点。</p><ol start="7"><li>  <strong>Squeeze的有无带来的影响</strong><br><img src="https://img-blog.csdnimg.cn/3f5c04bfb9c94e6d8afec7dd968484e8.png"></li></ol><p>肯定是有Squeeze效果好了。</p><ol start="8"><li>  <strong>对Excitation的探索</strong><br><img src="https://img-blog.csdnimg.cn/53dde57bb9714154a9c5bb4226644e30.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></li></ol><p>早期的Layer更加general，后期的Layer更Specific，5-2是一个拐点。</p><p>移除后期的layer可以减少param，同时模型不会受太大的影响。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>SENet对卷积层通道数进行权值评分，可以很好与其他网络(VGG, ResNet)结合。</p><p>相比于增加模型宽度(WRN中的width, ResNeXt中的cardinality)，深度(depth)，SE Block权重通道值，增加的参数少，增加的计算量小，增强效果好</p><p><strong>最后说一句，中秋快乐！</strong></p><p><img src="https://img-blog.csdnimg.cn/fdf4dc6565fb4af8b7049d1656b465fd.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DenseNet</title>
      <link href="/2021/09/17/densenet/"/>
      <url>/2021/09/17/densenet/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉–DenseNet"><a href="#带你读论文系列之计算机视觉–DenseNet" class="headerlink" title="带你读论文系列之计算机视觉–DenseNet"></a>带你读论文系列之计算机视觉–DenseNet</h1><p><img src="https://img-blog.csdnimg.cn/285b88c882c443399bf83db7ef1f5df5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_16,color_FFFFFF,t_70,g_se,x_16"></p><p>情若能自控，我定会按捺住我那颗吃货的心。</p><h2 id="闲谈"><a href="#闲谈" class="headerlink" title="闲谈"></a>闲谈</h2><p>今天听了师兄申请博士的经验。第一是感觉历程很心累，压力也很大；二是成功后很喜悦；三是成果很重要，其次是关系，努力和运气。漫长的时间等待与艰辛的的经历。对于现在的我来说，更多的是脚踏实地打好基础，不应该过于急于求成，慢慢来会更快。在一次次的选择后，我需要做到的就是减少自己的后悔。也许每一次的选择并不完美，也有利弊的取舍，收拾好心情又要重新出发。明天太阳🌞升起，又是美好的一天⛽️。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p><strong>论文</strong>：<a href="https://arxiv.org/abs/1608.06993">Densely Connected Convolutional Networks</a></p><p><a href="https://github.com/liuzhuang13/DenseNet"><strong>代码</strong></a></p><p><strong>本文是重新思考认识short path和feature reuse的意义，引入稠密连接思想。</strong></p><p>DenseNet在ResNet的基础上(<a href="https://wuliwuxin.github.io/2021/08/27/resnet-he-resnext/">回顾ResNet</a>🐂，ResNet 经典！！！)，进一步扩展网络连接，对于网络的任意一层，该层前面所有层的feature map都是这层的输入，该层的feature map是后面所有层的输入。</p><p><strong>摘要</strong>：</p><ol><li><p>残差连接使CNN更深、更强、更高效；</p></li><li><p>本文提出DenseNet，特点是前层作为后面所有层的连接；</p></li><li><p>通常L层有L个连接，DenseNet有L*（L+1）/2 ；</p></li><li><p>靠前的层作为靠后所有层的输入；</p></li><li><p>DenseNet优点减轻梯度消失，增强特征传播，加强特征复用，减少权重参数；</p></li><li><p>在4个数据集上进行验证，表现SOTA。</p></li></ol><p>如果将接近输入和输出的层之间短接，卷积神经网络可以更深、精度更高且高效。最后提出了密集卷积网络(DenseNet)，它的每一层在前向反馈模式中都和后面的层有连接，与L层传统卷积神经网络有L个连接不同，DenseNet中每个层都和其之后的层有连接，因此L层的DenseNet有 L(L+1)/2 个连接关系。</p><p>在四个目标识别的基准测试集（CIFAR-10、CIFAR-100、SVHN 和 ImageNet）上评估了我们的结构，可以发现DenseNet在减少计算量的同时取得了更好的表现。</p><h2 id="论文详情"><a href="#论文详情" class="headerlink" title="论文详情"></a>论文详情</h2><p>稠密连接（Dense connectivity）</p><p><img src="https://img-blog.csdnimg.cn/189e3d35498f409d8f4c4e5e94557bca.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16"></p><p>说明了生成的DenseNet的布局。在每一个block中，每一层的输出均会直接连接到后面所有层的输入。为了确保网络中各层之间的最大信息流，我们将所有层（具有匹配的特征图大小）直接相互连接。为了保持前馈性质，每一层从所有前面的层获得额外的输入，并将它自己的特征图传递给所有后续层。</p><p>ResNets和Highway Networks通过身份连接将信号从一层旁路到下一层。随机深度通过在训练期间随机删除层来缩短ResNet，以允许更好的信息和梯度流。</p><p>为了确保网络中各层之间的最大信息流，我们将所有层（具有匹配的特征图大小）直接相互连接。为了保持前馈性质，每一层从所有前面的层获得额外的输入，并将它自己的特征图传递给所有后续层。</p><p><strong>最重要的是，与ResNet不同的是，我们在将特征传递到一个层之前，从不通过求和的方式将它们结合起来；相反，我们通过串联的方式来结合特征。</strong></p><ol><li>稠密连接可用更少参数获得更多特征图；</li><li>传统NN的层可看成一个状态，NN对状态进行修改或保留；</li><li>ResNet通过恒等映射保留信息；</li><li>ResNet中很多特征图作用很小；</li><li>ResNet的状态（特征图）就像RNN网络一样；</li><li>DenseNet不进行特征相加以及信息保留；</li><li>DenseNet网络很窄。</li></ol><p>Highway Network 与ResNet的成功均得益于By passing paths。</p><ol><li>除了加深网络，还有一种加宽的方法来提升网络；</li><li>如GoogLenet ，加宽的ResNet。</li></ol><p><img src="https://img-blog.csdnimg.cn/d947b1d4057e4dc89af508faa6c0b172.webp"></p><p>在深度足够的情况下，ResNet可以提高其性能。FractalNet也在几个数据集上使用广泛的网络结构取得了有竞争力的结果。</p><ul><li>DenseNet不同于其他网络去增加宽度和深度;</li><li>DenseNet利用特征复用，得到易训练且高效的网络。</li></ul><p>DenseNet不是从极深或极广的架构中获取表征能力，而是通过特征重用来发挥网络的潜力，产生易于训练且参数效率高的浓缩模型。将不同层学到的特征图串联起来，增加了后续层输入的变化，提高了效率。这构成了DenseNet 和ResNet的一个主要区别。Inception networks也是将不同层的特征连接起来，与之相比，DenseNet更简单、更有效。</p><p>还有其他值得注意的网络结构创新，它们产生了有竞争力的结果。网络中的网络（NIN）结构将微型多层感知器纳入卷积层的过滤器，以提取更复杂的特征。在Deeply Supervised Net-work(DSN)中，内部各层直接受到辅助分类器的监督，这可以加强早期各层所接收的梯度。梯形网络在自动编码器中引入了横向连接，在半监督学习任务中产生了令人印象深刻的精确度。深度融合网（DFN）被提出，通过结合不同基础网络的中间层来改善信息流。</p><ul><li><p>shortcut connection的更容易优化；</p></li><li><p>缺点是求和的形式会阻碍（impede）信息的流通；</p></li><li><p>CNN需要下采样但Denseblock中分辨率是不会变的</p></li><li><p>在block之间进行特征图分辨率下降</p></li><li><p>利用transition layer来执行</p></li><li><p>BN+1<em>1conv+2</em>2 池化</p></li></ul><ol><li>若每层计算后得到k个特征图，那么第l 层会有k0+k*(l-1)个特征<br>图，因此k不能太大；</li><li>DenseNet的每层就非常的窄，非常的薄，例如k=12；</li><li>这里的k就是超参数Growth Rat；</li><li>k越小，结果越好；</li><li>从state的角度讲解DenseNet；</li></ol><p>这篇文章又一个比较清晰的bottleneck解释。</p><p>每个3×3卷积之前引入1×1卷积作为bottleneck，以减少输入特征图的数量，从而提高计算效率。</p><p>为了进一步提高模型的紧凑性，我们可以减少过渡层的特征图的数量。如果一个密集块包含m个特征图，我们让下面的过渡层生成bθmc输出特征图，其中0&lt;θ≤1称为压缩因子。当θ=1时，跨过渡层的特征图数量保持不变。我们将θ&lt;1的DenseNet称为DenseNet-C，我们在实验中设置θ=0.5。当同时使用θ&lt;1的Bottleneck和过渡层时，我们将我们的模型称为DenseNet-BC。</p><p>在除ImageNet之外的所有数据集上，我们实验中使用的DenseNet具有三个密集块，每个块都有相同的层数。在进入第一个密集块之前，对输入图像执行具有16 个（或DenseNet-BC增长率的两倍）输出通道的卷积。对于内核大小为3×3的卷积层，输入的每一侧都填充了一个像素以保持特征图大小固定。我们使用1×1 卷积，然后是2×2平均池化作为两个连续密集块之间的过渡层。在最后一个密集块的末尾，进行全局平均池化，然后附加一个softmax 分类器。三个密集块中的特征图大小分别为32×32、16×16和8×8。我们用配置{L=40,k=12}、{L=100,k =12}和{L=100,k=24}对基本的DenseNet结构进行实验。对于DenseNet-BC，评估具有配置{L=100,k=12},{L=250,k=24}和{L=190,k=40}的网络。</p><p>在我们在ImageNet上的实验中，我们在224×224 输入图像上使用具有4个密集块的DenseNet-BC结构。初始卷积层包括2k个大小为7×7、步幅为2的卷积；所有其他层中特征图的数量也来自设置k。我们在ImageNet上使用的确切网络配置如下图所示：<br><img src="https://img-blog.csdnimg.cn/518c202e9b7a40a7bd42d7711e0144ff.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>DenseNet-121是指网络总共有121层：(6+12+24+16)*2 + 3(transition layer) + 1(7x7 Conv) + 1(Classification layer) = 121。</p><p>过渡层；<br>1×1卷积，然后是2×2平均池化。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><img src="https://img-blog.csdnimg.cn/22669fc3916a4a8d85cd66a9820c3da9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>L表示网络深度，k为growth rate。蓝色字体表示最优结果，+表示对原数据集进行data augmentation。DenseNet相比ResNet取得更低的错误率，且参数更少。</p><p><strong>讨论DenseNet的优点</strong><br><img src="https://img-blog.csdnimg.cn/c93aad26941d4d568f7870b729bf34d9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/efaa94bbd3ff4a87b5f5347a7e69fc6c.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_19,color_FFFFFF,t_70,g_se,x_16"></p><p>结论：加B，加C更省参数。</p><p><img src="https://img-blog.csdnimg.cn/a6568b3368f2497b8b5f39e2ef3fa06b.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16"></p><p>同样精度时，densenet-bc仅用1/3参数。</p><p><img src="https://img-blog.csdnimg.cn/2e3fc616fe24446dbace6e5145ca08d5.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>同样精度，相差十几倍的参数量。</p><p>将输入进行连接的直接结果是，DenseNets每一层学到的特征图都可以被以后的任一层利用。该方式有助于网络特征的重复利用，也因此得到了更简化的模型。DenseNet-BC仅仅用了大概ResNets 1/3的参数量就获得了相近的准确率</p><p>三个dense block的热度图如下图所示：</p><p><img src="https://img-blog.csdnimg.cn/7a8248450c7843e9a6c1cc7b8598ff1b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>在一个训练有素的密集网络中，卷积层的平均绝对滤波权重。像素(s)的颜色编码了连接卷积层和`密集区的权重的平均水平（按输入特征图的数量归一化）。由黑色矩形突出的三列对应于两个过渡层和分类层。第一行是连接到密集块输入层的权重。</p><p><strong>可以得出以下结论</strong></p><ol><li><p>在同一个block中，所有层都将它的权重传递给其他层作为输入。这表明早期层提取的特征可以被同一个dense block下深层所利用；</p></li><li><p>过渡层的权重也可以传递给之前dense block的所有层，也就是说DenseNet的信息可以以很少的间接方式从第一层流向最后一层；</p></li><li><p>第二个和第三个dense block内的所有层分配最少的权重给过渡层的输出，表明过渡层输出很多冗余特征。这和DenseNet-BC强大的结果有关系；</p></li><li><p>尽管最后的分类器也使用通过整个dense block的权重，但似乎更关注最后的特征图，表明网络的最后也会产生一些高层次的特征。</p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们提出了一种新的卷积网络架构，我们称之为密集卷积网络（DenseNet ）。它引入了具有相同特征图大小的任意两层之间的直接连接。我们展示了DenseNet。自然地扩展到数百层，同时没有表现出优化困难。</p><p>随着参数数量的增加，DenseNets倾向于在准确度上持续提高，而没有任何性能下降或过度拟合的迹象。在多个设置下，它在几个竞争激烈的数据集上取得了最先进的结果。此外，DenseNets需要更少的参数和更少的计算来实现最先进的性能。因为在我们的研究中我们采用了针对残差网络优化的超参数设置，我们相信可以通过更详细地调整超参数和学习率计划来进一步提高<br>DenseNets的准确性。</p><p>在遵循简单的连接规则的同时，DenseNets自然地集成了身份映射、深度监督和多样化深度的特性。它们允许在整个网络中重复使用特征，因此可以学习更紧凑，更准确的模型。由于其紧凑的内部表示和减少的特征冗余，DenseNets 可能是各种基于卷积特征的计算机视觉任务的良好特征提取器。在未来的工作中用DenseNets 研究这种特征转移。</p><p><img src="https://img-blog.csdnimg.cn/8e8fc1bac2f44b6a8f0c348016c1b945.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Inception-V4</title>
      <link href="/2021/09/15/inception-v4/"/>
      <url>/2021/09/15/inception-v4/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉–Inception-V4"><a href="#带你读论文系列之计算机视觉–Inception-V4" class="headerlink" title="带你读论文系列之计算机视觉–Inception V4"></a>带你读论文系列之计算机视觉–Inception V4</h1><p><img src="https://img-blog.csdnimg.cn/5260b9a877e745a795283e4ce9360233.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p> 一直在路上,不是在奔跑,就是在漫步。</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>论文</strong>：<br><strong><a href="https://arxiv.org/abs/1602.07261">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a></strong></p><p><strong>CNN很强，例如我们的Inception；最近的resnet也很强。那强强联手会怎么样呢</strong>？</p><ol><li>速度方面：残差学习可加快inception收敛；</li><li>精度方面：残差学习仅带来一小部分提升；</li><li>提出新模型；</li><li>提出激活值缩放技巧来训练模型；</li><li>在2015ILSVRC挑战中取得了 SOTA(State Of The Art), 它的性能类似于最新一代的Inception-v3 网络；</li><li>使用三个残差和一个Inception-v4的集合，在ImageNet classification (CLS)挑战的测试集上实现3.08%的top-5 错误。</li></ol><p><strong>残差Inception网络在没有残差连接的情况下比同样的Inception网络表现出色。</strong></p><p><a href="https://wuliwuxin.github.io/2021/08/27/resnet-he-resnext/">回顾Res Net</a></p><p>主要思想就是将residual和inception结构相结合，以获得residual带来的好处。</p><h2 id="论文详情"><a href="#论文详情" class="headerlink" title="论文详情"></a>论文详情</h2><p>由于Inception网络往往非常深，因此用残差连接替换Inception架构的过滤器级联阶段。</p><p><strong>ResNet网络的亮点</strong>：</p><ul><li>超神的网络结构（突破1000层）；</li><li>提出Residual模块；</li><li>使用Batch Normalization加速训练（丢弃Dropput）；</li></ul><p><strong>因此Inception获得残差方法的所有好处，同时保持其计算效率。</strong></p><p><a href="https://wuliwuxin.github.io/2021/07/14/googlenet/">带你读论文系列之计算机视觉–GoogLeNet</a></p><p><a href="https://wuliwuxin.github.io/2021/09/12/inception-v2-bn-inception/">带你读论文系列之计算机视觉–Inception v2/BN-Inception</a></p><p><a href="https://wuliwuxin.github.io/2021/09/13/googlenet-v3/">带你读论文系列之计算机视觉–GoogLeNet V3</a></p><p>模型的参数和计算复杂性束缚了Inception V3 的性能。而Inception V4它具有比Inception V3更统一的简化架构和更多的Inception模块。</p><p>Inception V4和Inception-ResNet V2的表现相似，超过了最先进的单帧性能ImageNet验证集。</p><p><img src="https://img-blog.csdnimg.cn/8c352b66ae574ea6997a32418089f249.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_14,color_FFFFFF,t_70,g_se,x_16"></p><p>残差模块的引入。</p><p><img src="https://img-blog.csdnimg.cn/388a6a337a6f4bdfb45f579ef3384bc9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>ResNet的残差连接。</p><p><strong>v4要针对v3进行一系列简洁的优化。</strong></p><p>Inception的结构是很容易调节的，就是说改变一些fitler最终并不会影响结果。但是作者为了优化训练速度小心的调整了每一层的大小。现在因为tensorflow的优化功能，作者认为不需要再像以前一样根据经验小心的调整每一层，现在可以更加标准化的设置每一层的参数。而提出了Inception-V4，网络结构如下：</p><p><img src="https://img-blog.csdnimg.cn/0fe0a191ffba431ab00c058e28027a43.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/9229d3cfe34a4b17a80a44d2e1355ab3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16"></p><p>纯Inception-v4和Inception-ResNet-v2网络的Stem模式。这是这些网络的输入部分。</p><p>Inception V4具体的Block如下图：</p><p><img src="https://img-blog.csdnimg.cn/7cd1669ac43140adb37e828946a208c2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>纯Inception-v4网络的35×35网格模块的模式。这是Inception-V4网络结构中的Inception-A块。</p><p><img src="https://img-blog.csdnimg.cn/c6cfa7565be2410592e67776c0bf0394.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>纯Inception-v4网络的17×17grid模块的模式。这是Inception-V4网络结构中的Inception-B块。</p><p><img src="https://img-blog.csdnimg.cn/97fe75c5d9eb4172bb63165101a85b7d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>纯Inception-v4网络的8×8 grid模块模式。这是Inception-V4网络结构中的Inception- C块。</p><p><img src="https://img-blog.csdnimg.cn/8028063636934dbdbd59b34ac0e41336.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>35×35到17×17reduction模块的模式。</p><p><img src="https://img-blog.csdnimg.cn/e88ee0ae1947417daef6e678991b6e31.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>17×17到8×8grid-reduction模块的模式。这是Inception-V4网络结构中的纯Inception-v4 network使用的reduction模块。</p><p><img src="https://img-blog.csdnimg.cn/2334e63cdb0a4611b7d2d073705b79b8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_19,color_FFFFFF,t_70,g_se,x_16"></p><p>Inception-ResNet-v1网络的35×35网格（Inception-ResNet-A）模块的模式。</p><p><img src="https://img-blog.csdnimg.cn/66b28ae77a0d48c8a6277b89cab221eb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>Inception-ResNet-v1网络的17×17 grid（Inception-ResNet-B）模块的模式。</p><p><img src="https://img-blog.csdnimg.cn/b070d1c0dd4a4d6b8948240176487e52.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>较小的Inception-ResNet-v1网络所使用的这个模块是”Reduction-B”17×17至8×8 grid还原模块。</p><p><img src="https://img-blog.csdnimg.cn/1718910f4adf4a95bdaa35efd588221b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>Inception-ResNet-v1网络的8×8网格（Inception-ResNet-C）模块的模式。</p><p><img src="https://img-blog.csdnimg.cn/040f500ec6a64bb5bede28cffaf9a625.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>Inception-ResNet-v1网络的主干。</p><p><img src="https://img-blog.csdnimg.cn/c9aba3119cc44454b9b682df4c88f2e4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>Inception-ResNet-v1和Inception-ResNet-v2网络的架构。此架构适用于两个网络，但底层组件不同。</p><p>Inception-ResNet-v2具体的Block如下图：</p><p><img src="https://img-blog.csdnimg.cn/e0c325dd2be6417fbb89f10f88c5c7d4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>Inception-ResNet-v2网络的35×35grid（Inception-ResNet-A）模块的模式。</p><p><img src="https://img-blog.csdnimg.cn/6990041aa92840478b9e745b3a2c2e6c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>Inception-ResNet-v2网络的17×17grid（Inception-ResNet-B）模块的模式。</p><p><img src="https://img-blog.csdnimg.cn/a3b4333448de4e9c9dd5597c95eb26bc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>17×17至8×8网格还原模块的模式。图中更广泛的Inception-ResNet-v1network所使用的Reduction-B模块。</p><p><img src="https://img-blog.csdnimg.cn/93c8c8ebc8d04946b622a197031f34f1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>Inception-ResNet-v2网络的8×8 grid（Inception-ResNet-C）模块的模式。</p><p>Inception-V4和Inception-Resnet-V2的总体结构是比较像的，都是一个stem加上多次重复的Inception或者Inception-Resnet block，然后后面再连接reduction，然后重复这样的结构几次。</p><p><img src="https://img-blog.csdnimg.cn/d8eb8f95845e4dcbb651bc0011522164.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>三种Inception变体的Reduction-A模块的filter数量。</p><p><img src="https://img-blog.csdnimg.cn/5e89539eaba34813b5a83995edb77a62.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_19,color_FFFFFF,t_70,g_se,x_16"></p><p>K代表1✖️1 Conv，l代表3✖️3 Conv，m代表 3✖️3 Conv stride为2，n代表 3✖️3 Conv stride为2。</p><p><img src="https://img-blog.csdnimg.cn/d6e1c86c64b24a0c8726e9077949a1f1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>当超过1000个卷积核时，会出现“死”神经元。在最后的平均。池化层之前会出现输出值为0 的现象。解决方案是要么减小learning rate，要么对这些层增加额外的batch normalization。</p><p>如果将残差部分缩放后再跟需要相加的层相加，会使网络在训练过程中更稳定。因此缩放块只是用一个合适的常数来缩放最后的线性激活，通常在0.1 左右，用这个缩放因子去缩放残差网络，然后再做加法。求和前进行缩放，可稳定训练。缩放系数为0.1-0.3之间。</p><p>类似的不稳定在resnet中也有resnet提出warm-up来解决。当卷积核很多，很小的学习率（0.00001）也不能让训练稳定。</p><p><strong>scaling并不是必须的！是否找到某种应用场景，让scaling成为必须的，此为一个可研究方向。</strong></p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p><img src="https://img-blog.csdnimg.cn/067feff851044e58858f708452326df6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>Inception-v3训练期间的TOP-1error与计算成本相似的残余Inception相比。评估是在ILSVRC-2012验证集的非黑名单图像的单一作物上进行的。<strong>Residual version 的训练速度要快得多，最终准确率也比传统的Inception-v4略高</strong>。</p><p><img src="https://img-blog.csdnimg.cn/8dec779cf06a4dc5b885d11262f57aba.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>Single crop-Single model的实验结果。报告了ILSVRC2012验证集的非黑名单子集。</p><p><img src="https://img-blog.csdnimg.cn/ff3548b233dc467cbc153aefdb1ef8d2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>可以看出Inception-V4和Inception-ResNet-V2的差别并不大，但是都比Inception-V3和Inception-ResNet-V1都好很多。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li> <strong>Inception-ResNet-v1</strong>：一个混合的Inception版本</li><li> <strong>Inception-ResNet-v2</strong>：一个成本较高的混合Inception版本，其识别能力显著提高。</li><li> <strong>Inception-V4</strong>：纯粹的Inception变体，无残余连接，其识别能力与Inception-ResNet-v2 大致相同。</li></ol><p>主要研究了如何用residual learning 来提升inception的训练速度（紧扣主题，residual learning 只能加快训练，对精度提升没什么用）。此外，我们最新的模型（有和没有残差连接）优于我们以前的所有网络，仅因为模型尺寸的增加。</p><p><img src="https://img-blog.csdnimg.cn/634f90ba54414607b8c292b48ab3df77.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GoogLeNet V3</title>
      <link href="/2021/09/13/googlenet-v3/"/>
      <url>/2021/09/13/googlenet-v3/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉–GoogLeNet-V3"><a href="#带你读论文系列之计算机视觉–GoogLeNet-V3" class="headerlink" title="带你读论文系列之计算机视觉–GoogLeNet V3"></a>带你读论文系列之计算机视觉–GoogLeNet V3</h1><p><img src="https://img-blog.csdnimg.cn/b444f2a95232469c8811463c19125559.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>化作天边的一朵云在窗外悄悄看着你。</p><h2 id="闲谈"><a href="#闲谈" class="headerlink" title="闲谈"></a>闲谈</h2><p>广东的天气异常热，重庆今日温度28度左右，而广东37度左右。九月的天，让我又进入的夏天😭。近期会频繁更新，原因是我假期太懒了，都是之前累积的论文，现在开始整理了。同时，我把相关文档整理一下，放在我的<a href="https://github.com/wuliwuxin/CV-Paper">GitHub</a>上，欢迎加星, 欢迎提问，欢迎指正错误, 同时也期待能够共同参与。</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>重新思考计算机视觉中的Inception结构</strong>。</p><p><strong>回顾</strong></p><ol><li><a href="https://wuliwuxin.github.io/2021/07/14/googlenet/">GoogLeNet-V1</a>主要采用了多尺度卷积核、1x1卷积操作、辅助损失函数；</li><li><a href="https://wuliwuxin.github.io/2021/09/12/inception-v2-bn-inception/">GoogLeNet-V2</a>在V1的基础上加了BN层，使用小卷积核堆叠替换大卷积核；</li></ol><p>GoogLeNet –V1 采用多尺度卷积核，1✖️1卷积操作，辅助损失函数，实现更深的22层卷积神经网络，夺得ILSVRC-2014 分类和检测冠军，定位亚军。</p><p>GoogLeNet-V2 基础上加入BN层，并将5*5卷积全面替换为2个3✖️3卷积堆叠的形式，进一步提高模型性能。</p><p>VGG网络模型大，参数多，计算量大，不适用于真实场景。</p><p>GoogLeNet比VGG 计算量小；GoogLeNet可用于有限资源下的场景。</p><p><strong>论文：</strong><br><a href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a></p><p><strong>研究意义：</strong></p><ol><li>总结模型设计准则，为卷积神经网络模型设计提供参考；</li><li>提出3个技巧，结合Inception，奠定Inception系列最常用模型——Inception-V3；</li></ol><h2 id="论文详情"><a href="#论文详情" class="headerlink" title="论文详情"></a>论文详情</h2><p><strong>本文优点：</strong><br>1.提出低分辨率分类的方法；<br>2.提出卷积分解提高效率<br>3.BN-auxiliary<br>4.LSR</p><p>GoogLeNet的Inception 架构也被设计为即使在内存和计算预算的严格限制下也能表现良好。例如，GoogLeNet仅使用了500 万个参数，相对于其前身AlexNet使用了6000万个参数，这意味着减少了12 倍。此外，<strong>VGGNet使用的参数比AlexNet多3倍</strong>。</p><p><strong>摘要：</strong></p><ol><li>背景：自2014年以来，深度卷积神经网络成为主流，在多个任务中获得优异成绩；</li><li>问题：目前精度高的卷积神经网络，参数多，计算量大，存在落地困难问题；</li><li>解决：本文提出分解卷积及正则化策略，提升深度卷积神经网络速度和精度；</li><li>成果：单模型+single crop，top-5，5.6%; 模型融合+multi-crop，top-5，3.5%。</li></ol><p><img src="https://img-blog.csdnimg.cn/6350fcbaa9b94239afdb0bd1a60f6771.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_19,color_FFFFFF,t_70,g_se,x_16"></p><p>大卷集合分解成小卷积核堆叠。取代5×5卷积的小型网络。</p><p><strong>解耦</strong>：</p><ul><li>加快训练；</li><li>参数少了，可以用更多的卷积核；</li></ul><p><strong>分解成更小的卷积</strong>：</p><ol><li>小卷积核，计算量小；</li><li>大卷积核，感受野大，可捕获更多信息；</li><li>小卷积核，会降低表达能力；</li></ol><p>具有较大空间滤波器（例如5×5或7×7）的卷积在计算上往往不成比例地昂贵。例如，在一个有过滤器的网格上用5×5个过滤器进行卷积，比用同样数量的过滤器进行3×3卷积的计算成本高25/9=2.78 倍。当然，5×5的滤波器可以捕捉到前几层中更远的单元的激活信号之间的依赖关系，所以减少滤波器的几何尺寸是以很大的扩展性为代价的。</p><p><img src="https://img-blog.csdnimg.cn/d66d4dfacbcf4a7ea542d2955585ae01.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_11,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/ddb7faf11772468dbc8b68de0ed132bc.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_12,color_FFFFFF,t_70,g_se,x_16"></p><p>如果我们放大5✖️5卷积的计算图，我们会看到每个输出看起来像一个小的全连接网络，在其输入上滑动5✖️5块（如上figure 1）。由于我们正在构建视觉网络，因此利用平移不变性似乎很自然再次将全连接组件替换为两层卷积架构：第一层是3×3卷积，第二层是第一层3✖️3 输出网格顶部的全连接层（如上figure 1）。在输入激活网格上滑动这个小网络归结为用两层3✖️3卷积替换5✖️5 卷积（如上figure 4 和 figure 5）。</p><ol><li>3✖️3是否还能分解？可用2✖️2？其实用3✖️1和1✖️3 分解更好；</li><li>asymmetric 和2✖️2带来的参数减少分别为33%和11%。</li></ol><p>通过使用不对称卷积，例如n✖️1，我们可以做得比2×2更好。例如，使用3✖️1卷积，然后再使用1✖️3卷积，就相当于用3✖️3 卷积的相同感受场滑动一个两层网络（见图3）。如果输入和输出滤波器的数量相等，在输出滤波器数量相同的情况下，两层的解决方案仍然便宜33%。相比之下，将3✖️3卷积分解为2✖️2 卷积只节省了11%的计算量。</p><ol><li>一开始不要分解，效果不好！</li><li>特征图在12到20之间是比较好的！3.最好的参数是1✖️7，7✖️1；</li></ol><p><img src="https://img-blog.csdnimg.cn/4c3cd1b82b0e4b5cb22f787b2e466e0e.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>两个Inception模型之间的实验，其中一个使用分解为线性+ReLU layers，另一个使用两个ReLU层。经过386万次操作，前者稳定在76.2%，而后者在验证集上达到77.2%t op-1准确率。</p><p><img src="https://img-blog.csdnimg.cn/834637d8c58a404d850d23f8c14dee04.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_18,color_FFFFFF,t_70,g_se,x_16"></p><p>取代3✖️3演算的小型网络。该网络的底层由3个输出单元的3✖️1卷积组成。</p><p><strong>辅助分类器的效用</strong></p><ol><li>辅助分类层在早期起不到加速收敛作用；</li><li>收敛前，有无辅助分类，训练速度一样；</li><li>快收敛，有辅助分类的超过没有辅助分类的。</li></ol><p><img src="https://img-blog.csdnimg.cn/7b884ecaedd74070913b9f383b193ece.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_12,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/4c31d5a9724441208de0ef0663c4b964.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_13,color_FFFFFF,t_70,g_se,x_16"></p><p>该架构用于最粗糙的(8✖️8)网格以促进高维表示。我们仅在最粗糙的网格上使用此解决方案，因为这是产生高维稀疏表示是最关键的地方，因为与空间聚合相比，局部处理（1✖️1卷积）的比率增加了。</p><p><strong>V1中提到的辅助分类层有助于低层特征提取的假设是不正确的。</strong></p><p>本文认为辅助分类起到正则的作用。如果辅助分支是批量归一化的或具有dropout层，则网络的主分类器性能更好。这也为批量归一化充当正则化器的猜想提供了微弱的支持证据。</p><p><img src="https://img-blog.csdnimg.cn/f272d49fbfd44fc8816ba3fc0640f33c.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>左图表示传统的池化方法，会损失特征图的信息，右图表示先将特征图增大再进行池化的过程，存在问题是计算亮过大；</p><p><strong>解决办法：用卷积得到一半的特征图，池化得到一半的特征图，再进行拼接</strong>。</p><p><img src="https://img-blog.csdnimg.cn/c2e23473a6b9481f8471fafa96396b15.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>注意：该Inception-module用于35x35下降到17x17和17x17下降到8x8；</p><p>Inception模块，在扩展滤波器组的同时减小网格大小。它既便宜又避免瓶颈。右图表示相同的解决方案，但从网格大小而不是操作的角度来看。</p><p><strong>实验</strong></p><p><img src="https://img-blog.csdnimg.cn/59f950dce86c42e68c0c84ca815d5598.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>感受野大小不同但计算成本不变时的识别性能对比。</p><ol><li>299×299感受野，第一层后的stride2和maximum pooling；</li><li>第一层后具有stride1和最大池化的151×151感受野；</li><li>79×79的感受野，第一层后有跨度1和无pooling。</li></ol><p><img src="https://img-blog.csdnimg.cn/486935fb41e84a67889dcbee3336c47b.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_16,color_FFFFFF,t_70,g_se,x_16"></p><p>从v2开始，基于上个模型添加新trick ，最后一个模型称为inception-v3。</p><p><img src="https://img-blog.csdnimg.cn/cf140cfdac754d49ac79252ff3de7891.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>single-model、multi-crop实验结果比较对各种影响因素的累积影响。将我们的数字与ILSVRC2012分类基准上发布的最佳单模型推理结果进行比较。</p><p><img src="https://img-blog.csdnimg.cn/610fdcd7b2484bd39607ac2de9cf61bf.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>比较multi-model、multi-crop报告结果的集成评估结果。我们的数字与ILSVRC 2012分类基准上发布的最佳集成推理结果进行了比较。*所有结果，但报告的前5个集成结果都在验证集上。集成在验证集上产生了3.46%的top-5错误。</p><h2 id="论文总结"><a href="#论文总结" class="headerlink" title="论文总结"></a>论文总结</h2><p><strong>Inception-V3的主要改进点</strong>：</p><ol><li>采用RMSProp优化方法；</li><li>采用标签平滑正则化方法；</li><li>采用非对称卷积提取17x17特征图；</li><li>采用BN的辅助分类层；</li></ol><p><strong>关键点</strong>：</p><ol><li>非对称卷积分解：减少参数计算，为卷积结构设计提供新思路；</li><li>高效特征图下降策略：利用stride=2的卷积与池化，避免信息表征瓶颈；</li><li>标签平滑：避免网络过度自信，减轻过拟合；</li></ol><p><strong>启发点</strong>：</p><ol><li>CNN的分类是CNN视觉任务的基础：在分类上表现好的CNN，通常在其他视觉任务中表现也好；</li><li>GoogLe的很多论文的最优解均是通过大量实验得出，一般玩家难以复现；</li><li>非对称卷积分解在分辨率为12-20的特征图上效果好，且用1x7和7x1进行特征提取；</li><li>在网络训练初期，辅助分类层的加入并没有加快网络收敛，在训练后期，才加快网络的收敛；</li><li>移除两个辅助分类层的第一个，并不影响网络性能；</li><li>标签平滑参数设置，让非标签的概率保持在10-4左右。</li></ol><p><img src="https://img-blog.csdnimg.cn/492d928cf0f2465ba4c44b348736e49d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Inception v2/BN-Inception</title>
      <link href="/2021/09/12/inception-v2-bn-inception/"/>
      <url>/2021/09/12/inception-v2-bn-inception/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉–Inception-v2-BN-Inception"><a href="#带你读论文系列之计算机视觉–Inception-v2-BN-Inception" class="headerlink" title="带你读论文系列之计算机视觉–Inception v2/BN-Inception"></a>带你读论文系列之计算机视觉–Inception v2/BN-Inception</h1><p><img src="https://img-blog.csdnimg.cn/9ea3f5ca05c948908b6b86a70241640a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>我们终其一生，就是要摆脱他人的期待，找到真正的自己。–《无声告白》</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><a href="https://arxiv.org/pdf/1502.03167.pdf">论文：Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p><p><a href="https://wuliwuxin.github.io/2021/07/14/googlenet/">回顾GoogLeNet</a></p><p><strong>Inception-v2结构的改进就是将原来的Inception-v1结构中的5✖️5卷积层进行修改，用两个3✖️3卷积层代替</strong>。</p><p>Batch Normalization是google在2015提出的深度学习的优化技巧。</p><p>它不仅可以加快模型的收敛速度，而且更重要的是在一定程度缓解了深层网络中“梯度弥散”的问题，从而使得训练深层网络模型更加容易和稳定。</p><p>神经网络在训练时候，每一层的网络参数会更新，也就是说下一层的输入的分布都在发生变化，这就要求网络的初始化权重不能随意设置，而且学习率也比较低。因此，我们很难使用饱和非线性部分去做网络训练，作者称这种现象为internal covariate shift。</p><p><strong>Batch Normalization的提出，就是要解决在训练过程中，中间层数据分布发生改变的情况</strong>。</p><p>因为现在神经网络的训练都是采用min-batch SGD，所以Batch Normalization也是针对一个min-batch做归一化，这也就是Batch Normalization中batch的由来。在神经网络的训练中，如果将输入数据进行白化预处理（均值为0，方差为1，去相关）可以加快收敛速度。</p><p>但是白化处理计算量太大，而且不是处处可微的，所以作者做了两个简化处理。一是对每个维度单独计算，二是使用mini-batch来估计估计均值和方差。</p><p><strong>摘要</strong></p><ol><li>数据分布变化导致训练困难；</li><li>低学习率，初始化可解决，但训练慢；</li><li>数据分布变化现象称为ICS；</li><li>提出Batch Normalization层解决问题；</li><li>Batch Normalization 优点：大学习率不关心初始化，正则项不用Dropout；</li><li>成果：ImageNet分类的最佳发布结果：达到4.9%的top-5验证错误（和4.8%的测试错误），超过了人类评估者的准确度。</li></ol><p><strong>BN-Inception网络—关键点</strong></p><ul><li>Batch Normalization（批归一化）。意义，目前BN已经成为几乎所有卷积神经网络的标配技巧。</li><li>5×5卷积核→2个3×3卷积核。相同的感受野。<br><img src="https://img-blog.csdnimg.cn/a7532fff0a5b4f059dc02c80486c2c12.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_14,color_FFFFFF,t_70,g_se,x_16"></li></ul><p><strong>BN 的好处</strong>：</p><ul><li>BN 减少了内部协方差，提高了梯度在网络中的流动，加速了网络的训练。</li><li>BN使得可以设置更高的学习速率。</li><li>BN正则了模型。</li></ul><h2 id="论文详情"><a href="#论文详情" class="headerlink" title="论文详情"></a>论文详情</h2><p> 深度学习极大地提高了视觉、语音和许多其他领域的技术水平。随机梯度下降(SGD)已被证明是训练深度网络的有效方法，并且诸如momentum和<br>Adagrad等SGD变体已被用于实现最先进的性能。SGD优化网络的参数Θ，从而最小化损失。</p><p>使用SGD，训练分步进行，在每一步我们考虑mini-batch。mini-batch用于近似损失函数相对于参数的梯度。</p><p><strong>使用mini-batch的的2个好处</strong>：</p><ol><li>稳定，提高精度；</li><li>高效，加快速度。</li></ol><p>SGD要调参数：</p><ol><li>Learning Rate</li><li>权重初始化</li></ol><p><strong>缺点</strong>：<br>每层的输入受前面所有层的影响，而前面层微小的的改变都会被放大。</p><p>将<strong>Internal Covariate Shift</strong>(<strong>ICS</strong>)定义为训练过程中网络参数的变化引起的网络激活分布的变化。为了改进训练，我们寻求减少内部协变量偏移。通过将层输入的分布固定为训练进度，我们期望提高训练速度。众所周知，如果输入被白化，网络训练收敛得更快——即线性变换为具有零均值和单位方差，并且去相关。由于每一层都观察由下面的各层产生的输入，因此对每一层的输入实现相同的白化将是有利的。通过对每一层的输入进行白化，我们将朝着实现输入的固定分布迈出一步，从而消除内部协变量移位的不良影响。</p><p><strong>已知经验</strong>：<br><strong>当输⼊数据为whitened ,即0均值1方差,训练收敛速度会快</strong>。</p><p>实现白化(whitened)：</p><ol><li>直接改网络</li><li>根据激活值，优化参数，使得输出是白化的。</li></ol><p>我们可以在每个训练步骤或某个时间间隔考虑白化激活，通过直接修改网络或通过更改优化算法的参数以取决于网络激活值。然而，如果这些修改穿插在优化步骤中，那么梯度下降步骤可能会尝试以需要归一化的方式更新参数被更新，这减少了梯度步骤的影响。</p><p><img src="https://img-blog.csdnimg.cn/96dba9faa1b345588f9c1c93438684ec.webp"></p><p>其中期望和方差是在训练数据集上计算的。即使特征不相关，这种归一化也会加速收。通过以上公式把每层的特征进行白化并且是逐个维度的。简单的标准化特征值，会改变网络的表达能力例如sigmoid，限制在线性区域。<br><img src="https://img-blog.csdnimg.cn/9d09cf258adc4b89998750e072aaceab.webp"></p><p>其中gamma和beta是可学习允许模型自动控制是否需要保留原始表征。以上共识是为了保留网络的表征能力。</p><p>在批量设置中，每个训练步骤都是基于整个训练集的，我们将使用整个训练集来对激活进行管理。然而，在使用随机优化时，这是不现实的。因此，我们做了第二个简化：由于我们在随机梯度训练中使用mini-batch，每个mini-batch都产生每个激活的平均值和方差的估计值。这样，用于归一化的统计学可以完全参与到梯度反向传播中。请注意，mini-batch的使用是通过计算每个维度的变量而不是联合协方差来实现的；在联合的情况下，由于mini-batch的大小可能小于被白化的激活的数量，因此需要进行调节，导致奇异协方差矩阵。</p><p><img src="https://img-blog.csdnimg.cn/1754d823bc6b4230b52debf239cdbea0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>在算法1中详细说明了BN。在该算法中，ϵ是一个为了数值稳定性而加到mini-batch variance上的常数。</p><p>但需要注意的是，BN变换并不是独立处理每个训练示例中的激活。相反，BNγ,β(x)取决于训练示例和mini-batch中的其他示例。</p><p><img src="https://img-blog.csdnimg.cn/ad54c8bec1484510af0c850ffa3ef23b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>在传统的深度网络中，过高的学习率可能会导致梯度爆炸或消失，以及陷入不良的局部最小值。批量标准化有助于解决这些问题。通过对整个网络的激活进行标准化，它可以防止参数的微小变化放大为梯度激活的较大和次优变化；例如，它可以防止训练陷入非线性的饱和状态。</p><p>使用批量归一化进行训练时，可以看到一个训练示例与小批量中的其他示例相结合，并且训练网络不再为给定的训练示例生成确定性值。在我们的实验中，我们发现这种效果有利于网络的泛化。Dropout通常用于减少过拟合，在批量归一化网络中，我们发现它可以被移除或降低强度。</p><p><strong>实验</strong></p><p><img src="https://img-blog.csdnimg.cn/92e17b384beb4841af8d745c77f6b297.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>a）使用和不使用批量归一化训练的MNIST网络的测试准确率与训练步骤的数量。Batch Normalization帮助网络更快地训练并获得更高的准确率。</p><p>（b,c)在训练过程中，输入分布向典型的sigmoid演变，显示为{15,50,85}的百分位数。批量归一化使分布更加稳定，并减少了内部协变量的转移。</p><p>将批量归一化应用Inception网络的新变体(2014)，在ImageNet分类任务上进行训练(2014)。该网络有大量的卷积层和池化层，有一个softmax层以从1000种可能性中预测图像类。卷积层使用ReLU函数作为非线性。与Inception网络的新变体中描述的网络的主要区别在于，5×5卷积层被两个连续的3×3卷积层替换，最多128 个滤波器。网络包含13.6·106个参数，除了最上面的softmax层，没有全连接层。</p><p>简单地将批量归一化添加到网络并不能充分利用我们的方法。为此，我们进一步更改了网络及其训练参数，如下：</p><ol><li>增大学习率；</li><li>移除Dropout；</li><li>降低weight decay 降低5倍，减轻限制权重的大小，因为BN允许权重大一些；</li><li>更早的学习率下降总共下降6次；</li></ol><p><img src="https://img-blog.csdnimg.cn/d1c8ff407c4045ccb6b022487cd245ce.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>这个图展示了为什么是6。</p><ol start="5"><li>移除LRN v1中进入inception之前用了LRN；</li><li>彻底shuffle 充当正则；</li><li>减少光照变化因为训练次数少，期望模型看到的是真实的样本。</li></ol><p><img src="https://img-blog.csdnimg.cn/d47982b49bb841389edbcf4d14415175.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>在提供的包含50000个图像的验证集上，与以前的最新技术进行批量标准化初始比较。*根据测试服务器的报告，在ImageNet测试集的100000张图像上，BN初始集成已达到4.82% top-5。</p><p>其中BN-Inception Ensemble，则采用多个网络模型集成学习后得到的结果。</p><p>为了启用深度网络训练中常用的随机优化方法，对每个小批量执行归一化，并通过归一化参数反向传播梯度。批量归一化每次激活仅添加两个额外参数，并且这样做保留了网络的表示能力。文章提出了一种使用批量归一化网络构建、训练和执行推理的算法。由此产生的网络可以用饱和非线性进行训练，对增加的训练率有更大的容忍度，并且通常不需要Dropout进行正则化。</p><p>只加2个参数就保持表征能力。</p><p><strong>优点</strong>：</p><ol><li>可训练饱和激活函数；</li><li>可⽤⼤学习率；</li><li>不需要dropout。</li></ol><p><strong>Inception+bn+优化</strong><br><strong>单模型SOTA<br>多模型SOTA</strong></p><p>批量归一化的目标是在整个训练过程中实现激活值的稳定分布，在我们的实验中，我们在非线性之前应用它，因为这时匹配第一和第二时刻更有可能产生稳定的分布。相反，将标准化层应用于非线性的输出，这导致了更稀疏的激活。在我们的大规模图像分类实验中，我们没有观察到非线性输入是稀疏的，无论是使用还是不使用批量规范化。</p><p><strong>下一步研究</strong></p><ol><li> BN+RNN，RNN的ICS更严重；</li><li> BN+domain adaptation 仅重新计算mean+std 就可以了。</li></ol><p><img src="https://img-blog.csdnimg.cn/35d0f14538c941a4a0fc471e0760c538.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RCNN</title>
      <link href="/2021/09/01/rcnn/"/>
      <url>/2021/09/01/rcnn/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉RCNN"><a href="#带你读论文系列之计算机视觉RCNN" class="headerlink" title="带你读论文系列之计算机视觉RCNN"></a>带你读论文系列之计算机视觉RCNN</h1><p><img src="https://img-blog.csdnimg.cn/c6dbf5873193455aa98f2dd163d645f6.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="但是这样，我们总是习惯了不愿改变。"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>RCNN系列的文章主要是<strong>RCNN，Fast RCNN， Faster RCNN， Mask RCNN, Cascade RCNN</strong>,这一系列的文章是目标检测two-stage算法的代表，这系列的算法精度高，效果好，是一类重要的方法。</p><p>先来讲解目标检测开山之作R-CNN</p><p><a href="https://arxiv.org/abs/1311.2524"><strong>Rich feature hierarchies for accurate object detection and semantic segmentation</strong></a></p><p>这是一篇比较早的Object Detection算法，发表在2014年的CVPR，也是R-CNN系列算法的开山之作，网上可以搜到很多相关的博客讲解，本篇没有按论文顺序来讲述，而是结合自己经验来看这个算法，希望给初学者一个直观的感受，细节方面不需要太纠结，因为很多部分在后来的算法中都改进了。</p><p>R-CNN作为第一个将RPN理念与CNN结合的论文，在后续不断改进，诞生了Faster-RCNN，Mask-RCNN等一系列经典模型，所以是一篇入门CV必读的经典论文。</p><h2 id="01-寻找推荐区域"><a href="#01-寻找推荐区域" class="headerlink" title="01 寻找推荐区域"></a>01 寻找推荐区域</h2><p>在R-CNN中架构的第一步是要寻找推荐区域（Region Proposal），也就是找出可能的感兴趣区域（Region Of Interest, ROI）。获取推荐区域的方法有下三种，分为：滑动窗口、规则块和选择性搜索。</p><p>第一种就是滑动窗口。滑动窗口本质上就是穷举法，利用不同的尺度和长宽比把所有可能的大大小小的块都穷举出来，然后送去识别，识别出来概率大的就留下来。很明显，这样的方法复杂度太高，产生了很多的冗余候选区域，在现实当中不可行。</p><p>第二种是规则块。在穷举法的基础上进行了一些剪枝，只选用固定的大小和长宽比。但是对于普通的目标检测来说，规则块依然需要访问很多的位置，复杂度高。</p><p>第三种是<strong>选择性搜索</strong>。从机器学习的角度来说，前面的方法召回是不错了，但是精度差强人意，所以问题的核心在于如何有效地去除冗余候选区域。<strong>其实冗余候选区域大多是发生了重叠，选择性搜索利用这一点，自底向上合并相邻的重叠区域，从而减少冗余。</strong></p><h2 id="02-R-CNN结构"><a href="#02-R-CNN结构" class="headerlink" title="02 R-CNN结构"></a>02 R-CNN结构</h2><p>R-CNN主要由<strong>三部分</strong>结构构成，分别为：</p><p><strong>第一阶段</strong>：Region Proposals提取阶段。主要使用的是之前就已经提出的技术：selective search，该技术我们不细讲，如感兴趣可在最后看一下该论文的具体实现细节。我们只要明白该阶段输入了图像，会返回大约2k个region proposals.</p><p><strong>第二阶段</strong>：是在得到了很多region proposal后我们将其分别输入到一个CNN网络中，每一个region proposals输入一次，返回一个该region proposal对应的特征向量（4096维），在CNN的具体结构上，论文作者使用了Alexnet作为模型骨架。</p><p>有的人可能已经发现问题了，第一阶段提取的region proposal都是不同大小的，而CNN的输入往往都是要求固定的，在本文要求CNN的输入大小固定为227*227，那么我们如何解决region proposal的大小不匹配问题呢。</p><p><strong>第三阶段</strong>：在得到了每个region proposal的特征向量后，我们使用SVM二分类器对每一个region proposal进行预测。</p><p>有同学又有疑问了，为啥这么麻烦，直接跟Alexnet一样用一个Softmax直接做分类不香么，干嘛还用SVM一个个去分类呢?</p><p>主要由于：正负样本类别不平衡，负样本的数量远大于正样本数量，训练过程中以128的batch_size为例，仅有32个正样本，96个负样本，而且负样本都是随机取样，而SVM有着比Softmax更好的利用困难样本的能力。</p><p><strong>正样本</strong></p><p>本类的真值标定框。</p><p><strong>负样本</strong></p><p>考察每一个候选框，如果和本类所有标定框的重叠都小于0.3，认定其为负样本。</p><h2 id="03-R-CNN详情"><a href="#03-R-CNN详情" class="headerlink" title="03 R-CNN详情"></a>03 R-CNN详情</h2><p>R-CNN的工作流程</p><p><img src="https://img-blog.csdnimg.cn/77895e7adc1741c1871ff45f3c6ecbce.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>RCNN算法分为4个步骤</p><ul><li>一张图像生成1K~2K个候选区域；</li><li>对每个候选区域，使用深度网络提取特征；</li><li>特征送入每一类的SVM 分类器，判别是否属于该类；</li><li>使用回归器精细修正候选框位置；</li></ul><p>VOC 2007 训练的扭曲训练样本。</p><p><img src="https://img-blog.csdnimg.cn/a811c0b95737445e8b0d9b23abcca283.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/7e51eab8401043cda8f85fc06d22bd2f.webp"></p><p>VOC 2010 测试的检测平均精度 (%)。R-CNN 与 UVA 和 Regionlets 最直接可比，因为所有方法都使用选择性搜索区域建议。边界框回归（BB）。在发布时，SegDPM 是 PASCAL VOC 排行榜上的最佳表现。DPM 和 SegDPM 使用其他方法未使用的上下文重新评分。</p><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>论文发表的2014年，DPM已经进入瓶颈期，即使使用复杂的特征和结构得到的提升也十分有限。本文将深度学习引入检测领域，一举将PASCAL VOC上的检测率从35.1%提升到53.7%。</p><p>本文的前两个步骤（候选区域提取+特征提取）与待检测类别无关，可以在不同类之间共用。这两步在GPU上约需13秒。</p><p>同时检测多类时，需要倍增的只有后两步骤（判别+精修），都是简单的线性运算，速度很快。这两步对于100K类别只需10秒。</p><p>参考：<br><a href="https://zhuanlan.zhihu.com/p/168742724">https://zhuanlan.zhihu.com/p/168742724</a><br><a href="https://blog.csdn.net/qq_30091945/">https://blog.csdn.net/qq_30091945/</a></p><p><img src="https://img-blog.csdnimg.cn/78c89ca6b1544b67ac297b16294d232a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BoTNet</title>
      <link href="/2021/08/27/botnet/"/>
      <url>/2021/08/27/botnet/</url>
      
        <content type="html"><![CDATA[<h1 id="初识BoTNet：视觉识别的Bottleneck-Transformers"><a href="#初识BoTNet：视觉识别的Bottleneck-Transformers" class="headerlink" title="初识BoTNet：视觉识别的Bottleneck Transformers"></a>初识BoTNet：视觉识别的Bottleneck Transformers</h1><p><img src="https://img-blog.csdnimg.cn/db15391103464d429425369c9f336796.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="人生何必纠结，放下就是晴天！"></p><h2 id="杂谈"><a href="#杂谈" class="headerlink" title="杂谈"></a>杂谈</h2><p>最近，我的思想有点消极，对自己的未来很迷茫，不知道要从事什么，又在担心行业的内卷严重，有几篇论文看完了也没有写文章总结，这也是为什么我有时候不怎么更新的原因。一边否定自己，一边又给自己力量。也许科研道路就是要黑暗中前行，我们需要给自己一束灯光，或做自己的太阳。在消极的时候，我一般会看点书，电视剧或电影，出去散步或者锻炼。人生宝贵，也许有些事情我们无法改变。但如何提升自己却可以由我们自己决定。未来还有无数美好，在等着与更好的你相遇。请相信，那些你流过的汗，读过的书，走过的路，兴国的山，最终都会回馈到自己身上。</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong><a href="https://arxiv.org/abs/2101.11605">Bottleneck Transformers for Visual Recognition</a></strong></p><p><strong><a href="https://github.com/lucidrains/bottleneck-transformer-pytorch/">代码</a></strong></p><p>BoTNet：一种简单却功能强大的backbone，该架构将自注意力纳入了多种计算机视觉任务，包括图像分类，目标检测和实例分割。该方法在实例分割和目标检测方面显著改善了基线，同时还减少了参数，从而使延迟最小化。</p><p><strong>创新点</strong><br><img src="https://img-blog.csdnimg.cn/634e6ac76b5c4c5f95186b10e30b2753.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_15,color_FFFFFF,t_70,g_se,x_16"><br>左边的是ResNet的bottleneck结构，右边的是引入multi-head self-attention的bottleneck，称作BoT。两者唯一的不同在3*3的卷积和MHSA，其它的没有任何区别。在Mask RCNN中的ResNet50加入BoT，并且其它超参不变的情况下，COCO实例分割的beachmark的mask AP提升了1.2%。</p><p>论文就是修改经典网络ResNet，用Multi-Head Self-Attention替换ResNet Bottleneck中的3*3卷积，其他不进行修改。这一个简单的改变，就能使性能提升。</p><p><img src="https://img-blog.csdnimg.cn/ad0c9ed228934134947a09d8d29c7a89.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>BoTNet是一个混合模型（CNN + Transformer）。近期华为诺亚也使用这种混合模型提出了CMT。</p><p><strong><a href="https://arxiv.org/abs/2107.06263">CMT: Convolutional Neural Networks Meet Vision Transformers</a></strong></p><p><strong><a href="https://github.com/FlyEgle/CMT-pytorch">代码</a></strong></p><p><img src="https://img-blog.csdnimg.cn/cdecd99e5d624bb888103a009188f4fe.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>DeiT直接将输入图像拆分为非重叠图像块，图像块的结构信息则通过线性投影方式弱建模。采用类似ResNet的stem架构，它由三个3*3卷积构成，但激活函数采用了GELU，而非ResNet的ReLU。</p><p>类似经典CNN(如ResNet)架构设计，所提CMT包含四个阶段以生成多尺度特征(这对于稠密预测任务非常重要)。为生成分层表达，在每个阶段开始之前采用卷积降低特征分辨率并提升通道维度。在每个阶段，堆叠多个CMT模块进行特征变换同时保持特征分辨率不变，每个CMT模块可以同时捕获局部与长距离依赖关系。在模型的尾部，我们采用GAP+FC方式进行分类。</p><p><img src="https://img-blog.csdnimg.cn/a984143d8cae4cfcb976bc59a4032364.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>上表给出了所提方法与其他CNN、Transformer的性能对比，从中可以看到：</p><ul><li>所提CMT取得了更佳的精度，同时具有更少的参数量、更少的计算复杂度；</li><li>所提CMT-S凭借4.0B FLOPs取得了83.5%的top1精度，这比DeiT-S高3.7%，比CPVT高2.0%；</li><li>所提CMT-S比EfficientNet-B4指标高0.6%，同时具有更低的计算复杂度。</li></ul><h2 id="回顾ResNet"><a href="#回顾ResNet" class="headerlink" title="回顾ResNet"></a>回顾ResNet</h2><p><a href="https://wuliwuxin.github.io/2021/08/27/resnet-he-resnext/">带你读论文系列之计算机视觉–ResNet</a></p><p>ResNet在2015年由微软实验室提出，斩获当年ImageNet竞赛中分类任务第一名，目标检测第一名。获得COCO数据集中目标检测第一名，图像分割第一名。</p><p><img src="https://img-blog.csdnimg.cn/44b5f279224447988f789dcbf4090f5c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>注意：主分支与shortcut的输出特征矩阵shape必须相同。</p><p>ResNet-34层网络结构<br><img src="https://img-blog.csdnimg.cn/35484e7bcd9b471fb451b07c94b1f9ea.png"></p><p><strong>网络中的亮点：</strong></p><ul><li>超深的网络结构（突破1000层）</li><li>提出Residual模块</li><li>使用Batch Normalization加速训练（丢弃Dropout）</li></ul><p><strong>网络并不是越深越好。</strong></p><p><img src="https://img-blog.csdnimg.cn/d84d53b3f3c7486d86b2b905b4dc1d69.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br><strong>原因</strong>:</p><ul><li>梯度消失或梯度爆炸</li><li>退化问题</li></ul><p>可以通过对数据的标准化，权重初始化和BN处理，解决梯度消失或梯度爆炸的问题。而退化问题能通过残差结构不断加深网络获得更好的效果。</p><p><img src="https://img-blog.csdnimg.cn/a7e4e58dfc774caf9acfe676674660d7.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="BotNet详解"><a href="#BotNet详解" class="headerlink" title="BotNet详解"></a>BotNet详解</h2><p><img src="https://img-blog.csdnimg.cn/ec2e95d0a7ad4ba4a49925a8dbfb92e1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>左边可以看作是传统的Transformer模型，中间就是本文主角BoTNet，右图就是一个BoT block。</p><p>带有MHSA层的ResNet botlteneck可以被看作是具有bottleneck的Transformer块。，但有一些细微的差别，如剩余连接、归一化层的选择等等。</p><p><strong>Transformer中的MHSA和BoTNet中的MHSA的区别：</strong></p><p>1、 归一化，Transformer使用 Layer Normalization，而BoTNet使用 Batch Normalization。</p><p>2、非线性激活，Transformer仅仅使用一个非线性激活在FPN block模块中，BoTNet使用了3个非线性激活。</p><p>3、输出投影，Transformer中的MHSA包含一个输出投影，BoTNet则没有。</p><p>4、优化器，Transformer使用Adam优化器训练，BoTNet使用sgd+ momentum</p><p>深度学习优化算法经历了 SGD -&gt; SGDM -&gt; NAG -&gt;AdaGrad -&gt; AdaDelta -&gt; Adam -&gt; Nadam 这样的发展历程。</p><p><strong>算法固然美好，数据才是根本。</strong></p><p>先用Adam快速下降，再用SGD调优</p><ol><li>什么时候切换优化算法？——如果切换太晚，Adam可能已经跑到自己的盆地里去了，SGD再怎么好也跑不出来了。</li><li>切换算法以后用什么样的学习率？——Adam用的是自适应学习率，依赖的是二阶动量的累积，SGD接着训练的话，用什么样的学习率？</li></ol><p>优化算法的选择和使用方面的一些tricks<br>1、首先，各大算法孰优孰劣并无定论。如果是刚入门，优先考虑 SGD+Nesterov Momentum或者Adam.（Standford 231n : The two recommended updates to use are either SGD+Nesterov Momentum or Adam）；</p><p>2、 <strong>选择你熟悉的算法</strong>——这样你可以更加熟练地利用你的经验进行调参。</p><p>3、 <strong>充分了解你的数据</strong>——如果模型是非常稀疏的，那么优先考虑自适应学习率的算法。</p><p>4、<strong>根据你的需求来选择</strong>——在模型设计实验过程中，要快速验证新模型的效果，可以先用Adam进行快速实验优化；在模型上线或者结果发布前，可以用精调的SGD进行模型的极致优化。</p><p>5、先用小数据集进行实验。有论文研究指出，随机梯度下降算法的收敛速度和数据集的大小的关系不大。（The mathematics of stochastic gradient descent are amazingly independent of the training set size. In particular, the asymptotic SGD convergence rates are independent from the sample size. [2]）因此可以先用一个具有代表性的小数据集进行实验，测试一下最好的优化算法，并通过参数搜索来寻找最优的训练参数。</p><p>6、 <strong>考虑不同算法的组合。</strong>先用Adam进行快速下降，而后再换到SGD进行充分的调优。切换策略可以参考本文介绍的方法。</p><p>7、数据集一定要充分的打散（shuffle）。这样在使用自适应学习率算法的时候，可以避免某些特征集中出现，而导致的有时学习过度、有时学习不足，使得下降方向出现偏差的问题。</p><p>8、训练过程中<strong>持续监控训练数据和验证数据</strong>上的目标函数值以及精度或者AUC等指标的变化情况。对训练数据的监控是要保证模型进行了充分的训练——下降方向正确，且学习率足够高；对验证数据的监控是为了避免出现过拟合。</p><p>9、 <strong>制定一个合适的学习率衰减策略</strong>。可以使用定期衰减策略，比如每过多少个epoch就衰减一次；或者利用精度或者AUC等性能指标来监控，当测试集上的指标不变或者下跌时，就降低学习率。</p><p><img src="https://img-blog.csdnimg.cn/d2f34af49e2f4a768cc7fb2ac609f77a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>上图是ResNet-50和BoTNet-50的区别，唯一的不同在c5。而且BoTNe-50t的参数量只有ResNet-50的0.82倍，但是steptime略有增加。</p><p>只将ResNet的c5 block中的残差结构替换为MHSA结构。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><strong>BoTNet vs ResNet</strong><br>设置训练策略：一个训练周期定义为12个epoch，以此类推。<br><img src="https://img-blog.csdnimg.cn/90eeca7aa872431c9b99c5d9127c9966.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br><strong>Multi-Scale Jitter对BoTNet的帮助更大</strong><br><img src="https://img-blog.csdnimg.cn/480f586b804e41dfa6237964bceddd95.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_19,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/f7ae675bdfd044aeb6846612b7e8fd39.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_19,color_FFFFFF,t_70,g_se,x_16"><br>就是对分辨率的一个多尺度变化。从上图可以得出图像分辨率越大，它提升的性能越高。</p><p>加入 <strong>relative position encodings</strong> ，还能进一步提升性能！</p><p><img src="https://img-blog.csdnimg.cn/f4436d374c9b424bab0e5dd136271df9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>第一行是R50什么夜不加，原始的ResNet；第二行只加了自注意力机制，提升了0.6；第三行只加了相对位置编码。相对位置编码比自注意力机制提神的性能要高一点。第四行，加入了自注意力机制和相对位置编码，性能提升了1.5；第五行加入了自注意力机制和绝对位置编码只提高了0.4。</p><p><img src="https://img-blog.csdnimg.cn/61ef9541a8044e998106497f49997ea5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>这个图是几个网络性能的对比图。BoTNet是红色线，SENet是黑色线，EfficientNet是蓝色线。T3和T4的性能比SENet差一点，而在T5的时候两者性能差不多。这可以得出纯卷积模型在准确率上可达到83%。T7准确率达到84.7%，与EfficientNet B7的精度相当，效率提升了1.64倍，BoTNet的性能优于DeiT-384。</p><p>BoTNet要替换ResNet中的3*3的卷积部分代码<br><img src="https://img-blog.csdnimg.cn/63f6cf2978fa46389cacbb890bb10d12.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>MHSA的部分代码<br><img src="https://img-blog.csdnimg.cn/4f81acb7ce114027a72bc3c241dde3f7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/3d4e198e055947af83db71e7a034fa65.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>在没有任何附加条件的情况下，BoTNet使用Mask R-CNN框架在COCO实例分割基准上取得了44.4%的MaskAP和49.7%的Box AP；</li><li>卷积和混合（卷积和self-attention）模型仍然是很强的模型；</li><li>在ImageNet上BoTNet高达84.7％的top-1精度，性能优于SENet、EfficientNet等</li></ul><p>与这篇论文思路相似的论文，还有京东AI开源的ResNet变体CoTNet–即插即用的视觉识别模块。</p><p><a href="https://arxiv.org/abs/2107.12292">论文</a></p><p><a href="https://github.com/JDAI-CV/CoTNet">代码</a></p><p><img src="https://img-blog.csdnimg.cn/49075572a99f4797bae2154403c45eba.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/a8f6b63626a14af2b095a066900b9b2f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>京东AI研究院梅涛团队在自注意力机制方面的探索，不同于现有注意力机制仅采用局部或者全局方式进行上下文信息获取，他们创造性的将Transformer中的自注意力机制的动态上下文信息聚合与卷积的静态上下文信息聚合进行了集成，提出了一种新颖的Transformer风格的“即插即用”CoT模块，它可以直接替换现有ResNet架构Bottleneck中的卷积并取得显著的性能提升。无论是ImageNet分类，还是COCO检测与分割，所提CoTNet架构均取得了显著性能提升且参数量与FLOPs保持同水平。比如，相比EfficientNet-B6的84.3%，所提SE-CoTNetD-152取得了84.6%同时具有快2.75倍的推理速度。</p><p><img src="https://img-blog.csdnimg.cn/25a8c9d360f541b4833fa6fe7a3b071f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>用”CoT模块”，它可以直接替换现有ResNet架构Bottleneck中的卷积并取得显著的性能提升。无论是ImageNet分类，还是COCO检测与分割，所提CoTNet架构均取得了显著性能提升且参数量与FLOPs保持同水平。比如，相比EfficientNet-B6的84.3%，所提SE-CoTNetD-152取得了84.6%同时具有快2.75倍的推理速度。<br><img src="https://img-blog.csdnimg.cn/c2d3e0eafe124393a7b5c8a8071f9e71.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p><img src="https://img-blog.csdnimg.cn/a2c8f5a5657445e0a51cbb83727ade7a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br>具体来说，CoTNet-50直接采用CoT替换Bottlenck中的卷积；类似的，CoTNeXt-50采用CoT模块替换对应的组卷积，为获得相似计算量，对通道数、分组数进行了调整：CoTNeXt-50的参数量是ResNeXt-50的1.2倍，FLOPs则是1.01倍。</p><p><strong>可以看到</strong>：</p><ul><li>所提CoTNet、CoTNeXt均具有比其他ResNet改进版更优的性能；</li><li>相比ResNeSt-50，ResNeSt-101，所提CoTNeXt-50与CoTNeXt-101分别取得了1.0%与0.9%的性能提升；</li><li>相比BoTNet，所提CoTNet同样具有更优的性能；甚至于，SE-CoTNetD-152(320)取得了比BoTNet-S1-128(320)、EfficientNet-B7更优的性能。<br><img src="https://img-blog.csdnimg.cn/126dee476ce94102b65710a98310a4df.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> CNN+Transformers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResNet和ResNeXt</title>
      <link href="/2021/08/27/resnet-he-resnext/"/>
      <url>/2021/08/27/resnet-he-resnext/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉–ResNet和ResNeXt"><a href="#带你读论文系列之计算机视觉–ResNet和ResNeXt" class="headerlink" title="带你读论文系列之计算机视觉–ResNet和ResNeXt"></a>带你读论文系列之计算机视觉–ResNet和ResNeXt</h1><p><img src="https://img-blog.csdnimg.cn/aec20b2bdeda4a2ca7d7dec0aae42961.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p><strong>ResNet 强！</strong></p><p>ResNet发布于2015年，目前仍有大量CV任务用其作为backbone（尤其是顶会实验比较），而且当前很多网络都在使用残差模块。</p><p><strong>Deep Residual Learning for Image Recognition</strong></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">https://arxiv.org/abs/1512.03385<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>代码：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pytorch：https://github.com/fastai/fastaitensorflow：https://github.com/tensorflow/models/tree/master/research/deeplab<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>网络中的亮点：</strong></p><ul><li>超深的网络结构（突破1000层）</li><li>提出Residual模块</li><li>使用Batch Normalization加速训练（丢弃Dropout）</li></ul><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>随着深度对于网络的重要性，出现了一个问题：<strong>学些更好的网络是否像堆叠更多的层一样容易</strong>？回答这个问题的一个障碍是<strong>梯度消失/爆炸</strong>这个众所周知的问题，它从一开始就阻碍了收敛。然而，这个问题通过<strong>标准初始化（normalized initialization）</strong>，<strong>中间标准化层</strong>（intermediate normalization layers）和<strong>批量归一化</strong>（BN）在很大程度上已经解决，这使得数十层的网络能通过具有反向传播的随机梯度下降（SGD）开始收敛。（<strong>ResNet解决的不是梯度消失/爆炸问题</strong>）</p><p>当更深的网络能够开始收敛时，暴露了一个<strong>退化问题</strong>：随着网络深度的增加，准确率达到饱和，然后迅速下降。意外的是，这种退化<strong>不是由过拟合引起的</strong>，并且在适当的深度模型上添加更多的层会导致更高的训练误差。</p><p><img src="https://img-blog.csdnimg.cn/76a406e5d0af4339a6a6ec7f58ad442e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>在本文中，我们通过引入深度残差学习框架<strong>解决了退化问题</strong>。我们明确地让这些层<strong>拟合残差映射</strong>，而不是希望每几个堆叠的层直接拟合期望的底层映射。我们假设残差映射比原始的、未参考的映射更容易优化。在极端情况下，如果一个恒等映射是最优的，那么将残差置为零比通过一堆非线性层来拟合恒等映射更容易。</p><p>恒等快捷连接（Identity shortcut connections）既不增加额外的参数也不增加计算复杂度。</p><p>我们发现：1）我们极深的残差网络易于优化，但当深度增加时，对应的“简单”网络（简单堆叠层）表现出更高的训练误差；2）我们的深度残差网络可以从大<strong>大增加的深度中轻松获得准确性收益</strong>，生成的结果实质上比以前的网络更好。</p><p>残差表示。在图像识别中，VLAD是一种通过关于字典的残差向量进行编码的表示形式，Fisher矢量可以表示为VLAD的概率版本。它们都是图像检索和图像分类中强大的浅层表示。对于矢量量化，<strong>编码残差矢量被证明比编码原始矢量更有效。</strong></p><p>在低级视觉和计算机图形学中，为了<strong>求解偏微分方程（PDE）</strong>，广泛使用的Multigrid方法将系统重构为在多个尺度上的子问题，其中每个子问题负责较粗尺度和较细尺度的残差解。Multigrid的替代方法是层次化基础预处理，它依赖于<strong>表示两个尺度之间残差向量的变量。已经被证明这些求解器比不知道解的残差性质的标准求解器收敛得更快。这些方法表明，良好的重构或预处理可以简化优化</strong>。</p><h2 id="残差学习"><a href="#残差学习" class="headerlink" title="残差学习"></a>残差学习</h2><p>关于退化问题的反直觉现象激发了这种重构。<strong>如果添加的层可以被构建为恒等映射，更深模型的训练误差应该不大于它对应的更浅版本</strong>。退化问题表明<strong>求解器通过多个非线性层来近似恒等映射可能有困难。通过残差学习的重构，如果恒等映射是最优的，求解器可能简单地将多个非线性连接的权重推向零来接近恒等映射。</strong></p><p>在实际情况下，<strong>恒等映射不太可能是最优的</strong>，但是我们的重构可能有助于对问题进行预处理。如果最优函数比零映射更接近于恒等映射，则求解器应该更容易找到关于恒等映射的抖动，而不是将该函数作为新函数来学习。我们通过实验显示<strong>学习的残差函数通常有更小的响应，表明恒等映射提供了合理的预处理。</strong></p><p><strong>恒等映射足以解决退化问题</strong>，因此Ws（1x1卷积）仅在匹配维度时使用。残差函数的形式是可变的。</p><p>ResNet引入残差网络结构（residual network），即在输入与输出之间（称为堆积层）引入一个前向反馈的shortcut connection，这有点类似与电路中的“短路”，也是文中提到identity mapping（恒等映射y=x）。原来的网络是学习输入到输出的映射H(x)，而残差网络学习的是F(x)=H(x)−x。残差学习的结构如下图所示：</p><p><img src="https://img-blog.csdnimg.cn/3c2eff9ecb474276b562e0cd9fecb052.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_18,color_FFFFFF,t_70,g_se,x_16"></p><p>作者在文中提到：深层网络的训练误差一般比浅层网络更高；但是对一个浅层网络，添加多层<strong>恒等映射</strong>（y=x）变成一个深层网络，这样的深层网络却可以得到与浅层网络相等的训练误差。由此可以说明恒等映射的层比较好训练。</p><p>我们来假设：对于残差网络，当残差为0时，此时堆积层仅仅做了恒等映射，根据上面的结论，理论上网络性能至少不会下降。这也是作者的灵感来源，最终实验结果也证明，残差网络的效果确实非常明显。</p><p>但是为什么残差学习相对更容易？从直观上看残差学习需要学习的内容少，因为残差一般会比较小，学习难度小。另外我们可以从数学的角度来分析这个问题，首先残差单元可以表示为：</p><p><img src="https://img-blog.csdnimg.cn/9deabb3854ab4dfdb96885440955c459.png"></p><p>其中 x_{l} 和 x_{l+1} 分别表示的是第 l 个残差单元的输入和输出，注意每个残差单元一般包含多层结构。F 是残差函数，表示学习到的残差，而h表示恒等映射， f 是ReLU激活函数。基于上式，我们求得从浅层 l 到深层 L 的学习特征为：</p><p><img src="https://img-blog.csdnimg.cn/ed5b52f333b54b6c9346a1ead1d2cd1e.webp"></p><p>利用链式规则，可以求得反向过程的梯度：</p><p><img src="https://img-blog.csdnimg.cn/717a64382a0043829204f1647cda4325.png"></p><p>式子的第一个因子表示的损失函数到达 L 的梯度，小括号中的1表明短路机制可以无损地传播梯度，而另外一项残差梯度则需要经过带有weights的层，梯度不是直接传递过来的。残差梯度不会那么巧全为-1，而且就算其比较小，有1的存在也不会导致梯度消失。所以残差学习会更容易。</p><h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><p><strong>简单网络</strong>。卷积层主要有3×3的滤波器，并遵循两个简单的设计规则：（i）对于相同的输出特征图尺寸，层具有相同数量的滤波器；（ii）如果特征图尺寸减半，则滤波器数量加倍，以便保持每层的时间复杂度。我们通过步长为2的卷积层直接执行下采样。</p><p>我们的模型与VGG网络相比，<strong>有更少的滤波器和更低的复杂度</strong>。我们的34层基准有36亿FLOP(乘加)，仅是VGG-19（196亿FLOP）的18%。</p><p>在每个卷积之后和激活之前，我们采用批量归一化（BN）。</p><p><img src="https://img-blog.csdnimg.cn/dbce2b4dec894d908b846b39ad40e489.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_12,color_FFFFFF,t_70,g_se,x_16"></p><p> ImageNet 的更深的残差函数 F。左图：ResNet-34 的积木块（在 56×56 特征图上），如下图所示。右图：ResNet-50/101/152 的“瓶颈”构建块。</p><p><img src="https://img-blog.csdnimg.cn/e3cbb1475cdf43fe8fead5b672b297aa.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_16,color_FFFFFF,t_70,g_se,x_16"></p><p>图像被调整大小，其较短的边在 [256,480] 中随机采样以进行缩放。从图像或其水平翻转中随机采样 224×224 的裁剪，减去每个像素的平均值 。使用了标准颜色增强。我们在每次卷积之后和激活之前采用批量归一化（BN)。初始化权重并从头开始训练所有普通/残差网络。我们使用 SGD，mini-batch 大小为 256。学习率从 0.1 开始，当误差平稳时除以 10，模型最多训练 60×10的4 次迭代。我们使用 0.0001 的权重衰减和 0.9 的动量。我们不使用 dropout。</p><p>在测试中，为了进行比较研究，我们采用了标准的10-crop测试。为了获得最好的结果，我们采用完全卷积形式，并对多个尺度的分数进行平均（图像被调整为短边在{224，256，384，480，640}）。</p><p><img src="https://img-blog.csdnimg.cn/4b7fa438d4c6487cbbb56b359d342d14.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/0bc153b1ffe9499190372c9fc2c874c8.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/776a41bd050c4ae8a4ee8b6a2cd998da.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/791cd02ecede4e9ba792a435d8f1ae0f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_19,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/9d9608483d6b45bbae7bfd5a9fe0cf32.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>ImageNet验证集上的single-model结果的错误率（%）（测试集上的报告除外）。</p><p><img src="https://img-blog.csdnimg.cn/ffd2e7cdf1bd4ff2a1708875402b88f3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>集合的错误率 (%)。top-5 错误在 ImageNet 的测试集上，由测试服务器报告。</p><p><img src="https://img-blog.csdnimg.cn/528ca4df7e834e41a79978dc31473d55.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>在CIFAR-10上的训练。虚线表示训练误差，粗线表示测试误差。左边：普通网络。普通110的误差高于60%，没有显示。中：ResNets。右：有110层和1202层的ResNet。</p><p><img src="https://img-blog.csdnimg.cn/4dea52e4c58248d88b4b2c4b5a6bc443.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>CIFAR-10上各层响应的标准偏差（std）。响应是每个3×3层的输出，在BN之后和非线性之前。顶部：各层按其原始顺序显示。底部：响应按降序排列。</p><p><img src="https://img-blog.csdnimg.cn/37c15956a9374959835e544f7b7f9901.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_19,color_FFFFFF,t_70,g_se,x_16"></p><p>总结</p><ol><li><p>当堆积层的输入x和输出y不同维度的时候，即f是一个从低维向高维的映射时，这个时候不能简单的添加恒等映射作为shortcut connection，需要加上一个线性投影Ws，等于一个连接矩阵，这种结构称为投影结构。</p></li><li><p>残差网络不仅可以运用到全连接层，还可以用到卷积层。</p></li><li><p>作者做了对比投影结构与恒等结构对实验结果的实验。发现投影结构对效果有细微提升，但是应该归功于投影连接增加的额外参数。</p></li><li><p>作者测试了1000层的残差网络，测试结果比110层更差，但是训练误差却与110层相似，造成这种现象应该是过拟合，对于小型的数据集，1000多层的网络属于杀鸡牛刀了，如果真的需要用到这么深的网络，可能需要更强的正则化。</p></li><li><p>ResNet在目标分类上有了非常好的泛化性能，作者将它应用到目标检测领域，将Faster R-CNN的基础网络用VGG-16与ResNet-101对比，性能均有大幅提升。</p></li></ol><p><a href="https://wuliwuxin.github.io/2021/07/06/vgg/">带你读论文系列之计算机视觉–VGG</a></p><p><a href="https://wuliwuxin.github.io/2021/06/28/alexnet/">带你读论文系列之计算机视觉–AlexNet</a></p><h2 id="ResNeXt"><a href="#ResNeXt" class="headerlink" title="ResNeXt"></a>ResNeXt</h2><p><strong>Aggregated Residual Transformations for Deep Neural Networks</strong></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">https://arxiv.org/abs/1611.05431<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>代码和模型公布在</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">https://github.com/facebookresearch/ResNeXt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>亮点</strong></p><ol><li>提出简洁、高度模块化的网络</li><li>主要特色是聚合变换</li><li>block都一致，超参数很少</li><li>cardinality 来衡量模型复杂度</li><li>ImageNet上发现，增加cardinality可提高网络性能且比增加深度和宽度更高效</li><li>ILSVRC第二名，5K 和COCO超越ResNet</li></ol><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>ResNet网络的升级版：<strong>ResNeXt。提出ResNeXt的主要原因在于：传统的要提高模型的准确率，都是加深或加宽网络，但是随着超参数数量的增加（比如channels数，filter size等等），网络设计的难度和计算开销也会增加。因此本文提出的 ResNeXt 结构可以在不增加参数复杂度的前提下提高准确率，同时还减少了超参数的数量(得益于子模块的拓扑结构)。</strong></p><p>首先提到VGG，VGG主要采用堆叠网络来实现，之前的 ResNet 也借用了这样的思想。然后提到 Inception 系列网络，简单讲就是 split-transform-merge 的策略，但是 Inception 系列网络有个问题：<strong>网络的超参数设定的针对性比较强，当应用在别的数据集上时需要修改许多参数，因此可扩展性一般</strong>。</p><p>网络 ResNeXt，同时采用 VGG 堆叠的思想和 Inception 的 split-transform-merge 思想，但是可扩展性比较强，可以认为是在增加准确率的同时基本不改变或降低模型的复杂度。这里提到一个名词<strong>cardinality</strong>，原文的解释是the size of the set of transformations，如下图 Fig1 右边是 cardinality=32 的样子，这里注意<strong>每个被聚合的拓扑结构都是一样的</strong>(这也是和 Inception 的差别，减轻设计负担)。</p><p><img src="https://img-blog.csdnimg.cn/9b0ffe6aafec47889984a747b8900a1b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>附上原文比较核心的一句话，点明了增加 cardinality 比增加深度和宽度更有效，这句话的实验结果在后面有展示：</p><p><img src="https://img-blog.csdnimg.cn/38e02ceb8cef4b19838a4dbc1c18b76c.webp"></p><p><strong>相关工作</strong></p><ol><li><p>多分支网络广泛应用；ResNets可以被认为是两个分支网络，其中一个分支是身份映射。深度神经决策森林是具有学习分裂函数的树模式多分支网络；深度网络决策树也是多分支结构multi-path有群众基础。</p></li><li><p>分组卷积有广泛应用；几乎没有证据表明分组卷积可提升网络性能。</p></li><li><p>模型压缩有广泛研究；本文不同于模型压缩，本文设计的结构自身就有很强的性能和低计算量。</p></li><li><p>模型集成是有效的提高精度的方法；本文模型并不是模型集成，因为各模块的训练是一起同时训练的，并不是独立的。</p></li></ol><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>列举了 ResNet-50 和 ResNeXt-50 的内部结构，另外最后两行说明二者之间的参数复杂度差别不大。</p><p><img src="https://img-blog.csdnimg.cn/a75e4df03f1c4cd7b65d24b252c76abb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>（左）ResNet-50。（右）带有32×4d模板的ResNeXt-50（使用图3（c）中的重构）。括号内是残块的形状，括号外是舞台上堆叠的块数。“C=32”建议分组卷积有32个组。这两个模型之间的参数数量和FLOPs相似。</p><p>这些块具有相同的拓扑结构，并且受VGG/ResNet启发的两个简单规则的约束：（i）如果生成相同大小的空间图，则这些块共享相同的超参数（宽度和过滤器大小），以及（ii）每个当空间图按因子2下采样时，块的宽度乘以因子2。第二条规则确保计算复杂性，以FLOP（浮点运算，在#乘加），对于所有块大致相同。</p><p>3种不同不同的 <strong>ResNeXt blocks</strong></p><p><img src="https://img-blog.csdnimg.cn/28de62c801bc4839aa72f2474b507507.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>ResNeXt的等效构建块。(a)：聚合残差变换，与图1右侧相同。(b)：等效于(a)的块，实现为早期串联。(c)：等效于(a,b)，实现为分组卷积。加粗的符号突出了重新制定的变化。一层表示为（#输入通道，过滤器大小，#输出通道）。</p><p>fig3.a：aggregated residual transformations；</p><p>fig3.b：则采用两层卷积后 concatenate，再卷积，有点类似 Inception-ResNet，只不过这里的 paths 都是相同的拓扑结构；</p><p>fig 3.c：采用了一种更加精妙的实现，<strong>Group convolution分组卷积</strong>。</p><p>作者在文中明确说明这三种结构是严格等价的，并且用这三个结构做出来的结果一模一样，在本文中展示的是fig3.c的结果，因为<strong>fig3.c的结构比较简洁而且速度更快。</strong></p><p><img src="https://img-blog.csdnimg.cn/aeefba204ec44daa898e74a4d7c9c0af.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>（左）：聚合深度=2的转换。（右）：一个等效的块，稍微宽一些</p><p>ResNeXt在不增加参数及计算量的情况提高了精度。</p><h4 id="分组卷积"><a href="#分组卷积" class="headerlink" title="分组卷积"></a>分组卷积</h4><p>Group convolution 分组卷积，最早在AlexNet中出现，由于当时的硬件资源有限，训练AlexNet时卷积操作不能全部放在同一个GPU处理，因此作者把feature maps分给多个GPU分别进行处理，最后把多个GPU的结果进行融合。</p><p><img src="https://img-blog.csdnimg.cn/604c335a71f1471f983720218b883cf6.webp"></p><p>有趣的是，分组卷积在当时可以说是一种工程上的妥协，因为今天能够简单训练的AlexNet。在当时很难训练, 显存不够，Hinton跟他的学生不得不把网络拆分到两张GTX590上面训练了一个礼拜，当然，两张GPU之间如何通信是相当复杂的，幸运的是今天tensorflow这些库帮我们做好了多GPU训练的通信问题。就这样Hinton和他的学生发明了分组卷积. 另他们没想到的是:分组卷积的思想影响比较深远，当前一些轻量级的<strong>SOTA（State Of The Art）网络</strong>，都用到了分组卷积的操作，以节省计算量。</p><p>疑问：如果分组卷积是分在不同GPU上的话，每个GPU的计算量就降低到 1/groups，但如果依然在同一个GPU上计算，最终整体的计算量是否不变？</p><p>实际上并不是这样的，Group convolution本身就大大减少了参数，比如当input_channel= 256, output_channel=256,kernel size=3x3:不做分组卷积的时候，分组卷积的参数为256x256x3x3。</p><p>当分组卷积的时候，比如说group=2,每个group的input_channel、output_channel=128,参数数量为2x128x128x3x3,为原来的1/2.</p><p>最后输出的feature maps通过concatenate的方式组合，而不是elementwise add. 如果放到两张GPU上运算，那么速度就提升了4倍.</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="https://img-blog.csdnimg.cn/ad42c51e211a4da88c382ead40f30d57.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>ImageNet-1K的训练曲线。(左):ResNet/ResNeXt-50，保留了复杂性（41亿FLOPs，2500万参数）；（右）。保留复杂性的ResNet/ResNeXt-101(78亿FLOPs，4400万参数)。</p><p><img src="https://img-blog.csdnimg.cn/f85e84b83da147d5b221e82de1b8fdba.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>在ImageNet-1K 上进行的消融实验。(顶部):保留复杂性的ResNet-50（41 亿FLOPs）；（底部）：保留复杂性的ResNet-101（78亿FLOPs）。误差率是在224×224像素的单一作物上评估的。</p><p><img src="https://img-blog.csdnimg.cn/50013076e6654af884af92e519463845.webp?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_18,color_FFFFFF,t_70,g_se,x_16"></p><p>当FLOPs的数量增加到ResNet-101的2倍时，在ImageNet-1K上的比较。错误率是在224×224像素的单一作物上评估的。突出显示的因素是增加复杂性的因素。</p><p><strong>总结</strong>：</p><ul><li>ResNeXt结合了inception与resnet的优点(其实还有分组卷积)，既有残缺结构(便于训练)又对特征层进行了concat(对特征多角度理解)。这就类似于模型融合了，把具有不同优点模型融合在一起，效果的更好。</li><li>核心创新点就在于提出了 aggregrated transformations，用一种平行堆叠相同拓扑结构的blocks代替原来 ResNet 的三层卷积的block，在不明显增加参数量级的情况下提升了模型的准确率，同时由于拓扑结构相同，超参数也减少了，便于模型移植。</li></ul><p>参考文章：</p><p><a href="https://www.jianshu.com/p/11f1a979b384">https://www.jianshu.com/p/11f1a979b384</a></p><p><a href="https://www.cnblogs.com/FLYMANJB/p/10126850.html">https://www.cnblogs.com/FLYMANJB/p/10126850.html</a></p><p><img src="https://img-blog.csdnimg.cn/612dc594d31d4844bc8e306455dd6345.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L-b6Zi25aqb5bCP5ZC0,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ViT</title>
      <link href="/2021/08/15/vit/"/>
      <url>/2021/08/15/vit/</url>
      
        <content type="html"><![CDATA[<h1 id="初识-CV-Transformer-之Vision-Transformer-ViT"><a href="#初识-CV-Transformer-之Vision-Transformer-ViT" class="headerlink" title="初识 CV Transformer 之Vision Transformer (ViT)"></a>初识 CV Transformer 之Vision Transformer (ViT)</h1><p><img src="https://img-blog.csdnimg.cn/301c3f48793e4c7cb88c406e77b82248.webp?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="请没有征服不了的高山"></p><h2 id="0-回顾"><a href="#0-回顾" class="headerlink" title="0 回顾"></a>0 回顾</h2><p><img src="https://img-blog.csdnimg.cn/88feb5dcb14544b6b50099d310aebd9a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/23cec76c6e2a4d33810cdbfc522a190a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/39149dc298a9451c83aa134a685002c5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/9cc0e4eae2a2410fb318935e2a029404.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><img src="https://img-blog.csdnimg.cn/3310d82ecb4f42e092202bfb027525e6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/b750e1b780c14f4e8a111c3ade235c33.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/9da3e5f699804afcaaae1dc2c671a28c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><strong>Attention Is All You Need</strong></p><p>RNN、LSTM时序网络，存在一定的问题：</p><ol><li>记忆长度有限，像RNN记忆时序比较短，后面就提出了LSTM；</li><li>无法并行化，即只有计算完t0时刻才能计算t1时刻，计算效率比较低。</li></ol><p>Google提出了Transformer，在理论上不受硬件的限制，记忆长度可以无限长，并且可以并行化。</p><p><strong>Embedding层有什么用？</strong><br><img src="https://img-blog.csdnimg.cn/593768affb074d09a5534f6e92de7e70.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>Eembedding层, Keras中文文档中对嵌入层 Embedding的介绍除了一句 “嵌入层将正整数（下标）转换为具有固定大小的向量”之外就不愿做过多的解释。那么我们为什么要使用嵌入层 Embedding呢? 主要有这两大原因:</p><ol><li><p>使用One-hot方法编码的向量会很高维也很稀疏。假设我们在做自然语言处理（NLP）中遇到了一个包含2000个词的字典，当使用One-hot编码时，每一个词会被一个包含2000个整数的向量来表示，其中1999个数字是0，如果字典再大一点，这种方法的计算效率会大打折扣。</p></li><li><p>训练神经网络的过程中，每个嵌入的向量都会得到更新。通过上面的图片我们就会发现在多维空间中词与词之间有多少相似性，这使我们能可视化的了解词语之间的关系，不仅仅是词语，任何能通过嵌入层 Embedding 转换成向量的内容都可以这样做。</p></li></ol><p>上面说的概念可能还有些不清楚，那我们就举个例子看看嵌入层Embedding对下面的句子怎么处理的。Embedding的概念来自于word embeddings，如果您有兴趣阅读更多内容，可以查询word2vec。</p><p><img src="https://img-blog.csdnimg.cn/0c80054324d04212b1cb6d93caabbb91.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="图片来自：A Survey on Visual Transformer"></p><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h2><blockquote><p>论文题目：An Image is Worth 16x16 Words:Transformers for Image Recognition<br>at Scale</p></blockquote><h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>Transformer提出后在NLP领域中取得了极好的效果，其全Attention的结构，不仅增强了特征提取能力，还保持了并行计算的特点，可以又快又好的完成NLP领域内几乎所有任务，极大地推动自然语言处理的发展。</p><p>虽然Transformer很强，但在其在计算机视觉领域的应用还非常有限。在此之前只有目标检测(Objectdetection)中的DETR大规模使用了Transformer，其他领域很少，而纯Transformer结构的网络则是没有。</p><p>下图是该方向论文必出现的图：</p><p><img src="https://img-blog.csdnimg.cn/351eba39ea9a4b848e2750da6db20a77.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/633b544a28d646f5985ae2cc19c5191e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><strong>Transformer的优势</strong></p><ol><li>并行计算；</li><li>全局视野；</li><li>灵活的堆叠能力；</li></ol><h3 id="研究成果及意义"><a href="#研究成果及意义" class="headerlink" title="研究成果及意义"></a>研究成果及意义</h3><p>ViT和ResNet Baseline取得了不相上下的结果</p><p><img src="https://img-blog.csdnimg.cn/48aec390c8c04ea898f7285df442b937.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>JFT：谷歌闭源数据集，规模是ImageNet的30倍左右</p><p>ViT-H/14：ViT-Huge模型，输入序列14x14</p><p>ViT的历史意义：展示了在计算机视觉中使用纯Transformer结构的可能。</p><p>   图片→Backbone(CNNs)→Transformer→结果</p><p>   图片→Transformer→结果</p><h2 id="2-论文算法模型总览"><a href="#2-论文算法模型总览" class="headerlink" title="2 论文算法模型总览"></a>2 论文算法模型总览</h2><h3 id="一切的开端：Self-Attention"><a href="#一切的开端：Self-Attention" class="headerlink" title="一切的开端：Self-Attention"></a>一切的开端：Self-Attention</h3><p>Attention是什么？以机器翻译为例。</p><p><img src="https://img-blog.csdnimg.cn/9dee07b26c814ffda86d0dc749d22066.png"><img src="https://img-blog.csdnimg.cn/7950f0c0bae14b4f9b7869daf4aea8f3.png"></p><p><img src="https://img-blog.csdnimg.cn/c5a6c2d369c4454faf7eaaa5d3a6bbce.png"></p><p><img src="https://img-blog.csdnimg.cn/d253b172b170476b9afc052044c5651b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><strong>每次输出只与输入的某几个词有关，关系深，权重大，关系浅，权重小。</strong></p><p><strong>Attention Mechanism</strong></p><p>Attention的本质：加权平均</p><p>Attention的计算：实际上就是相似度计算</p><p><img src="https://img-blog.csdnimg.cn/9eec11b8e694475cbba3fd4c38065571.png"></p><p><img src="https://img-blog.csdnimg.cn/caa22e2ea71e4171a2a66313452127d3.png"></p><p><strong>Self-Attention怎么计算？</strong></p><p>Self Attention 计算：实际上是在进行相似度计算，计算每个q分别和每个k的相似度</p><p>公式：</p><p><img src="https://img-blog.csdnimg.cn/2546cfc4ffea47bd9198a2615e238c26.png"></p><p>Q，K，V是什么？</p><p>Query：查询，询问；</p><p><img src="https://img-blog.csdnimg.cn/7477d518a008472594118a672b3cc61a.png"></p><p>Key：键值，关键词；</p><p><img src="https://img-blog.csdnimg.cn/70d0b6b1ecfc45d6b0768166c80a2a28.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>Value：价值，数值。</p><p><img src="https://img-blog.csdnimg.cn/a4af820b319d43bb9728f42680440ad2.png"></p><p><strong>点积为什么可以衡量q与k的相似度？</strong></p><p>公式：<br>q1·k1= |q1| x |k1| x cos</p><p>q1·k2= |q1| x |k2| x cos</p><p><img src="https://img-blog.csdnimg.cn/b667aa4f28cf490da7844cb3b930f981.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="Attention计算"><a href="#Attention计算" class="headerlink" title="Attention计算"></a>Attention计算</h3><p><img src="https://img-blog.csdnimg.cn/0c8fa648024648f8a930e7f3331ecc53.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/55b44b5dca624b96a2a220ede0f7f245.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>假设的input是x1-x4，是一个sequence，每一个input (vector)先乘以矩阵W得到embedding，即向量a1-a4。接着这个embedding进入self-attention层，每一个向量a1-a4分别乘上3个不同的transformation matrix Wq，Wk，Wv，以向量a1为例，分别得到3个不同的向量q1，k1，v1；接下来使用每个query q去对每个key k做attention，attention就是做点积，匹配这2个向量有多接近，然后除以q和k的维度的开平方。</p><p><img src="https://img-blog.csdnimg.cn/e00890167e2643e7971230dbedc90ebf.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/d1b349551a12488596dd004f19ae4c7c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/3e127e9790214706b85c8a670c204111.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/607729b448e74af38d1169645d0853d7.png"><br><img src="https://img-blog.csdnimg.cn/c667fba233f74cdaab041a37fd9b61f3.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/126dc2513df941409f2c42896aee18d5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="MultiHead-Attention"><a href="#MultiHead-Attention" class="headerlink" title="MultiHead Attention"></a>MultiHead Attention</h3><p><img src="https://img-blog.csdnimg.cn/b667cd031d144a40b7c44b90ef54b688.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/9cc2c3d627454356a6ff1e66c5953fd6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/6eb6f41f6883406f8527e6780948acb4.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="ViT结构"><a href="#ViT结构" class="headerlink" title="ViT结构"></a>ViT结构</h3><p>受NLP中Transformer扩展成功的启发，我们尝试将一个标准的Transformer直接应用于图像，并尽可能少地进行修改。为此，我们将图像分割成补丁，并将这些补丁的线性嵌入序列作为转化器的一个输入。图像斑块的处理方式与NLP应用中的记号（单词）相同。我们以监督的方式训练图像分类的模型。</p><p><img src="https://img-blog.csdnimg.cn/f412de189fa749a785014708b4aad0cc.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/eb7c3976a91b4f6e881fd638f3ea2183.png"></p><ol><li><p>将图像切分转化为序列化数据：原本HxWxC维的图片被转化为N个 D维的向量（或者一个NxD维的二维矩阵）；</p></li><li><p>Position Embedding：采用position embedding（紫色框） + patch embedding（粉色框）方式来结合position信息；</p></li><li><p>Learnable Embedding：Xclass（带星号的粉色框）是可学习的vector，这个token没有语义信息（即在句子中与任何的词无关，在图像中与任何的patch无关），它与图片label有关，经过encoder得到的结果使得整体表示偏向于这个指定embedding的信息；</p></li><li><p>Transformer Encoder：将前面得到的Z0作为transformer的初始输入，transformer encoder是由多个MSA和MLP块交替组成的，每次在MSA和MLP前都要进行LN归一化。</p></li></ol><h3 id="位置编码-Positional-Encoding"><a href="#位置编码-Positional-Encoding" class="headerlink" title="位置编码 Positional Encoding"></a>位置编码 Positional Encoding</h3><p><strong>为什么要位置编码？</strong></p><p>图像切分重排（由二维变一维）后失去了位置/空间信息，并且Transformer的内部运算是空间信息无关的，所以需要把位置信息编码重新传进网络；</p><p>ViT使用了一个可学习的vector（Xclass）来编码，编码vector和patch vector直接相加组成输入；</p><p><strong>为什么直接相加，而不是concat？</strong><br>因为相加是concat的一种特例</p><p>相加形式：W(I+P)=WI+WP</p><p>concat形式：</p><p>当W1=W2时，两式内涵一致</p><p><img src="https://img-blog.csdnimg.cn/c87ccc3762744bbf9c6be90a363ea809.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="BN和LN的区别"><a href="#BN和LN的区别" class="headerlink" title="BN和LN的区别"></a>BN和LN的区别</h3><p><strong>为什么采用LN？</strong><br>LN其实就是在每个样本上都计算均值和方差，将输入数据转化成均值为0，方差为1的数据。而不采用BN是因为，Batch Normalization的处理对象是对一批样本，是对这批样本的同一维度特征做归一化，Layer Normalization 的处理对象是单个样本，是对这单个样本的所有维度特征做归一化，而此处输入的N+1个序列，每个序列的长度可能是不同的。</p><p><img src="https://img-blog.csdnimg.cn/ca26391ef5df4f52b8acec154421a3af.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h2 id="3-实验结果分析"><a href="#3-实验结果分析" class="headerlink" title="3 实验结果分析"></a>3 实验结果分析</h2><p>先在大数据集上预训练，然后到小数据集上Fine Tune</p><p>迁移过去后，需要把原本的MLP Head换掉，换成对应类别数的FC层，处理不同尺寸输入的时候需要对Positional Encoding的结果进行插值。</p><p><img src="https://img-blog.csdnimg.cn/1eebf9ca147e45b8b126b80dd822a25a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>在中等规模的数据集上（例如ImageNet），transformer模型的表现不如ResNets；</p><p>而当数据集的规模扩大，transformer模型的效果接近或者超过了目前的一些<strong>SOTA</strong>(state of the art)结果。</p><p>BiT : 一个大ResNet进行监督+迁移学习的模型</p><p>Noisy Student：一个半监督学习的EfficientNet-L2</p><p>ViT-H/14：ViT-Huge模型，输入序列14x14</p><p><img src="https://img-blog.csdnimg.cn/519063363a2e47839286b0bf63c38a79.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/976c9bc250f344309cd3e86a9e19d29f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>Attention距离和网络层数的关系。Attention的距离可以等价为Conv中的感受野大小，层数越深，Attention跨越的距离越远，但是在最底层，也有的head可以覆盖到很远的距离。这说明Transformer可以进行Global信息整合。</p><p><img src="https://img-blog.csdnimg.cn/ca3ad2428c1140749acfe633ce60d4ea.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepLab系列</title>
      <link href="/2021/08/08/deeplab/"/>
      <url>/2021/08/08/deeplab/</url>
      
        <content type="html"><![CDATA[<h1 id="语义分割模型之DeepLab系列"><a href="#语义分割模型之DeepLab系列" class="headerlink" title="语义分割模型之DeepLab系列"></a>语义分割模型之DeepLab系列</h1><p><img src="https://img-blog.csdnimg.cn/1fc6027f0a1d49748c36a8bc65ebe82b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="空气新鲜，风景宜人"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>DeepLab系列一共有四篇文章，分别对应DeepLab V1、DeepLab V2、DeepLab V3和DeepLab V3+。</p><h3 id="DeepLab-V1"><a href="#DeepLab-V1" class="headerlink" title="DeepLab V1"></a>DeepLab V1</h3><p>论文题目：<a href="https://arxiv.org/abs/1606.00915">Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs</a></p><p>开源代码：<a href="https://github.com/TheLegendAli/DeepLab-Context">TheLegendAli/DeepLab-Context</a></p><h3 id="DeepLab-V2"><a href="#DeepLab-V2" class="headerlink" title="DeepLab V2"></a>DeepLab V2</h3><p>论文题目：<a href="https://arxiv.org/abs/1606.00915">DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</a></p><p>开源代码：<a href="https://github.com/DrSleep/tensorflow-deeplab-resnet">DrSleep/tensorflow-deeplab-resnet</a></p><h3 id="DeepLab-V3"><a href="#DeepLab-V3" class="headerlink" title="DeepLab V3"></a>DeepLab V3</h3><p>论文题目：<a href="https://arxiv.org/abs/1706.05587">Rethinking Atrous Convolution for Semantic Image Segmentation</a></p><p>开源代码：<a href="https://github.com/eveningdong/DeepLabV3-Tensorflow">leonndong/DeepLabV3-Tensorflow</a></p><h3 id="DeepLab-V3-1"><a href="#DeepLab-V3-1" class="headerlink" title="DeepLab V3+"></a>DeepLab V3+</h3><p>论文题目：<a href="https://arxiv.org/abs/1802.02611">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</a></p><p>开源代码：<a href="https://github.com/jfzhang95/pytorch-deeplab-xception">jfzhang95/pytorch-deeplab-xception</a></p><h3 id="DeepLab系列的思想"><a href="#DeepLab系列的思想" class="headerlink" title="DeepLab系列的思想"></a>DeepLab系列的思想</h3><p>图像分割CNN是根据classification这种high-level semantics改编的，但CNN做语义分割时精准度不够，根本原因是 DCNNs 的高级特征的平移不变性，即高层次特征映射，根源于重复的池化和下采样会丢失localization信息，即无法对像素点精确定位语义（low-level semantics）。</p><p>针对下采样或池化降低分辨率，DeepLab采用了空洞卷积代替池化操作来扩展感受野，获取更多的上下文信息。同时DeepLab v1v2 结合了深度卷积神经网络（DCNNs）和概率图模型（DenseCRFs）的方法。DeepLab v2提出了串行的ASPP模块，ASPP增强了网络在多尺度下多类别分割时的鲁棒性， 使用不同的采样比例与感受野提取输入特征，能在多个尺度上捕获目标与上下文信息，虽然大大扩展了卷积核的感受野，但<strong>随着感受野越来越接近图像大小，会退化为1x1卷积。</strong></p><p>为了解决这个问题，<strong>DeepLab v3改进了ASPP空洞卷积空间金字塔池化层，不同的dilation卷积并行操作，然后归一尺寸后求和</strong>。ASPP模块借鉴PSPNet思想，通过不同采样率的空洞卷积并行采样，捕捉图像不同尺度的上下文信息。</p><p>DeepLab v3+通过添加一个简单而有效的解码器模块扩展DeepLab v3以优化分割结果，在PASCAL VOC 2012数据集和Cityscapes数据集中分别取得了89%和82.1%的MIOU。</p><h3 id="语义分割面临的主要挑战"><a href="#语义分割面临的主要挑战" class="headerlink" title="语义分割面临的主要挑战"></a>语义分割面临的主要挑战</h3><p><strong>分辨率</strong><br>连续的池化或下采样操作会导致图像的分辨率大幅度下降，从而损失了原始信息， 且在上采样过程中难以恢复。因此，越来越多的网络都在试图减少分辨率的损失， 比如使用空洞卷积，或者用步长为2的卷积操作代替池化。</p><p><strong>多尺度特征</strong><br>同一张图片中不同大小物体的分割精度不同，因为不同尺度卷积核对不同大小物体的分割效果不同。在分辨率较小的情况下，小物体的位置信息经常被丢失，通过设置不同参数的卷积层或池化层， 提取到不同尺度的特征图。将这些特征图送入网络做融合，对于整个网络性能的提升很大。但是由于图像金字塔的多尺度输入，造成计算时保存了大量的梯度，从而导致对硬件的要求很高。</p><h2 id="1-DeepLab-V1"><a href="#1-DeepLab-V1" class="headerlink" title="1 DeepLab V1"></a>1 DeepLab V1</h2><p>DeepLab v1是结合了深度卷积神经网络（DCNNs）和概率图模型（DenseCRFs）的方法</p><p><strong>深度卷积神经网络（DCNNs）</strong></p><ul><li>采用FCN思想，修改VGG16网络，得到 coarse score map并插值到原图像大小</li><li>使用Atrous convolution得到更dense且感受野不变的feature map</li></ul><p><strong>概率图模型（DenseCRFs）</strong></p><ul><li>借用fully connected CRF对从DCNNs得到的分割结果进行细节上的refine。</li></ul><p>DeepLab v1:VGG16+空洞卷积+CRF对边缘分割结果进行后处理。针对下采样或池化降低分辨率，DeepLab采用了空洞卷积来扩展感受野，获取更多的上下文信息。同时，采用完全连接的条件随机场（CRF）提高模型捕获细节的能力。</p><p>感受域和步长以及卷积核之间的对应关系：</p><p><img src="https://img-blog.csdnimg.cn/a8f41fd5c21e4c74b0d31e9364a34143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/4e1d625a98ca4387a30e25cdca49970c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><img src="https://img-blog.csdnimg.cn/b61c961872bc4924984567fae16a4a2c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="DeepLab-v1-的网络结构"><a href="#DeepLab-v1-的网络结构" class="headerlink" title="DeepLab v1 的网络结构"></a>DeepLab v1 的网络结构</h3><ol><li>把全连接层（fc6、fc7、fc8）改成卷积层（端到端训练）</li><li>把最后两个池化层（pool4、pool5）的步长2改成1（保证feature的分辨率下降到原图的1/8）。</li><li>把最后三个卷积层（conv5_1、conv5_2、conv5_3）的dilate rate设置为2，且第一个全连接层的dilate rate设置为4（保持感受野）。</li><li>把最后一个全连接层fc8的通道数从1000改为21（分类数为21）。</li><li>第一个全连接层fc6， 通道数从4096变为1024， 卷积核大小从7x7变为3x3，后续实验中发现此处的dilate rate为12时（LargeFOV），效果最好。</li></ol><p><img src="https://img-blog.csdnimg.cn/4a8ad99eb87642d981a39d73b965d6ab.png"></p><h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p>网络变形：</p><p>DeepLab-MSc：类似FCN，加入特征融合</p><p>DeepLab-7×7：替换全连接的卷积核大小为7× 7</p><p>DeepLab-4×4：替换全连接的卷积核大小为4× 4</p><p>DeepLab-LargeFOV：替换全连接的卷积核大小为3×3，空洞率为12。</p><p><img src="https://img-blog.csdnimg.cn/e7d2acf16f7c43beb9201d210deaa11c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>损失函数：交叉熵 + softmax</p><p>优化器：SGD + momentum 0.9</p><p>batchsize：20</p><p>学习率：10^−3（每经过2000个epoch，学习率 * 0.1）</p><p><img src="https://img-blog.csdnimg.cn/28f5116a5f3a49e9b4b0e2cf7dcc488e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h2 id="2-DeepLab-V2"><a href="#2-DeepLab-V2" class="headerlink" title="2 DeepLab V2"></a>2 DeepLab V2</h2><p><img src="https://img-blog.csdnimg.cn/79368d35d18c44baa83cf82934c2a179.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>Deeplab v2：VGG16/ResNet+串行的ASPP模块+CRF对边缘分割结果进行后处理。添加了ASPP空洞卷积空间金字塔池化层，通过不同的dilation卷积串行操作，来取代导致浅层特征损失的池化操作，大大扩大了感受野。</p><h3 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h3><h4 id="空洞卷积（Atrous-Convolution）"><a href="#空洞卷积（Atrous-Convolution）" class="headerlink" title="空洞卷积（Atrous Convolution）"></a>空洞卷积（Atrous Convolution）</h4><p><strong>稠密映射：</strong></p><p>标准3×3卷积：3*3大小的区域对应一个输出值</p><p>空洞卷积(rate=2)：5*5大小的区域对应一个输出值<br><img src="https://img-blog.csdnimg.cn/bf1eed852a744827b67d5c8149644d9f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/b529ef0fafeb4bd08c2d93d4ad979a10.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>标准3×3卷积（rate为1），感受野为3；空洞卷积（rate为2），卷积核尺寸为5x5，感受野为7；空洞卷积（rate为4），卷积核尺寸为9x9，感受野为15。</p><p><img src="https://img-blog.csdnimg.cn/8a492b155ee043c3b1387185d64cecf6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="请添加图片描述"></p><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>变化率：残差的引入去掉了主体部分，从而突出了微小的变化。</p><p>主要思想：用一个神经网络去拟合y=x这样的恒等映射，比用一个神经网络去拟合y=0这样的0映射要难。因为拟合y=0的时候，只需要将权重和偏置都逼近0就可以了。</p><p><img src="https://img-blog.csdnimg.cn/340184514adc45a3921c12dbdd109c3c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/be07ad33cbb642d3bd7acf079bdf53bb.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="Network-amp-ASPP"><a href="#Network-amp-ASPP" class="headerlink" title="Network&amp;ASPP"></a>Network&amp;ASPP</h3><p>ASPP模块构成——&gt;DeepLab v1到DeepLab v2的进化——&gt;基于VGG16的DeepLab v2在v1的基础上做了进一步调整（FC6-FC8替换为ASPP）</p><p><img src="https://img-blog.csdnimg.cn/b842e05ebe80484cb3ea615aa30ba410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/aab30393be6444d6894618db556e3d44.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="实验设置-1"><a href="#实验设置-1" class="headerlink" title="实验设置"></a>实验设置</h3><p>损失函数：交叉熵 + softmax</p><p>优化器：SGD + momentum 0.9</p><p>Batchsize：20</p><p>学习率策略：step：10^−3（每经过2000个epoch，学习率 * 0.1）</p><p>poly：<br><img src="https://img-blog.csdnimg.cn/22a9897753804089839eb9c42ca6d1e5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>网络变形：</p><p>LargeFOV：3×3卷积 + rate=12(DeepLab v1最好结果)</p><p>ASPP-S：r = 2, 4, 8, 12</p><p>ASPP-L：r = 6, 12, 18, 24</p><p><img src="https://img-blog.csdnimg.cn/892a2d8ff7de4c868abeefc1ee873650.png"><img src="https://img-blog.csdnimg.cn/4f8af814fad5448ba65d2d83cde09262.png"></p><h2 id="3-DeepLab-V3"><a href="#3-DeepLab-V3" class="headerlink" title="3 DeepLab V3"></a>3 DeepLab V3</h2><p><img src="https://img-blog.csdnimg.cn/db29db5edd9a49bc886c88d673509bee.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>Deeplab v3：ResNet+改进后的并行ASPP模块。随着采样率的增大，有效滤波器权重的数量（应用于有效特征的权重而不是padding补充的0）变少，在空洞率接近特征映射大小的极端情况下，3×3滤波器不是捕获整个图像上下文，而是退化为简单的1×1卷积（只有中心滤波器权重是有效的）。因此，v3使用了并行ASPP模块，最后一个分支拼接全局池化模块来捕获全局上下文信息。</p><p><strong>语义分割常用特征提取框架</strong></p><ol><li>图像金字塔：从输入图像入手，将不同尺度的图像分别送入网络进行特征提取，后期再融合。</li><li>编解码结构：编码器部分利用下采样进行特征提取，解码器部分利用上采样还原特征图尺寸。</li><li>深度网络vs空洞卷积：经典分类算法利用连续下采样提取特征，而空洞卷积是利用不同的采样率。</li><li>空间金字塔结构：除ASPP外，仍有其他网络使用了该思想，如SPPNet、PSPNet等。</li></ol><p><img src="https://img-blog.csdnimg.cn/5c2621c7e62c433cb2d955fde3babed4.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>经典分类算法网络架构，如ResNet  ——&gt;  DeepLab v3空洞卷积串行网络结构  ——&gt;  DeepLab v3空洞卷积并行网络结构（调整了ASPP模块）</p><p><img src="https://img-blog.csdnimg.cn/8a8614ad97e441d3941bf2e14a69c68e.png"><br><img src="https://img-blog.csdnimg.cn/b90c7a3e5d704250813cda1bfe7647bd.png"><br><img src="https://img-blog.csdnimg.cn/6de7fa641b194aef9cb714c9e0545635.png"></p><h3 id="实验设置-2"><a href="#实验设置-2" class="headerlink" title="实验设置"></a>实验设置</h3><p><strong>裁剪尺寸</strong>：裁剪图片至513x513（为了更好的拟合空洞率）</p><p>学习率策略：采用poly策略，原理同v2</p><p><strong>BN层策略</strong>：当output_stride=16时，batchsize=16，同时BN层做参数衰减decay=0.9997。在增强的数据集上，以初始学习率0.007训练30K后，冻结BN层参数。当output_stride=8时，batchsize=8，使用初始学习率0.001训练30K。</p><h2 id="4-DeepLab-V3"><a href="#4-DeepLab-V3" class="headerlink" title="4 DeepLab V3+"></a>4 DeepLab V3+</h2><p><img src="https://img-blog.csdnimg.cn/3fce4d09fb3b4e269eea88763b02c23d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>Deeplab v3+：DeepLabv3+的核心是通过添加一个简单而有效的解码器模块来恢复对象边界（沿着对象边界来细化分割结果），扩展了DeepLab v3。以Xcepition/ResNet为骨架，采用深度可分离卷积进行编码，在多尺度特征提取ASPP模块后再接一个简单的解码器模块。</p><h3 id="背景知识-1"><a href="#背景知识-1" class="headerlink" title="背景知识"></a>背景知识</h3><h4 id="深度可分离卷积"><a href="#深度可分离卷积" class="headerlink" title="深度可分离卷积"></a>深度可分离卷积</h4><p><strong>标准卷积：</strong><br>标准输入图片尺寸为12×12×3，用1个5×5×3的卷积核进行卷积操作，会得到8×8×1的输出；<br>用256个5×5×3的卷积核进行卷积操作，会得到8×8×256的输出。<br>参数计算：256×5×5×3 = 19200<br><img src="https://img-blog.csdnimg.cn/c89edb27b5024cfdab086cce6c5fa16b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/1688fe0d78bd44419c859dfb5dadcf65.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><strong>分组卷积：</strong><br>组卷积是对输入特征图进行分组，每组分别进行卷积。<br>假设输入特征图的尺寸为C<em>H</em>W (12× 5×5)，输出特征图的数量为N (6)个，如果设定要分成G (3)个groups，则每组的输入特征图数量为C/G (4)，每 组 的 输出特征图数量为N/G (2)，每个卷积核的尺寸为(C/G)<em>K</em>K (4×5×5)，卷积核的总数仍为N (6)个，每组的卷积核数量为N/G (2)，每个卷积核只与其同组的输入特征图进行卷积，卷积核的总参数量为N*(C/G)<em>K</em>K，可见，总参数量减少为原来的1/G。</p><p>深度可分离卷积是组卷积的一种极端情况，也就是输入有多少个通道，对应的分组就有多少个组，即分组的组数=输入特征图的通道数。<br><img src="https://img-blog.csdnimg.cn/f3d42843851b418198593087b1e631f0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/a5c19f7d3e2b45ae9b32b0ca92eddd5b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><strong>深度可分离卷积 = 深度卷积 + 逐点卷积</strong></p><p><strong>深度卷积</strong>：每个5×5×1的卷积核对应输入图像中的一个通道，得到三个8×8×1的输出， 拼接后得到8×8×3的结果</p><p><strong>逐点卷积</strong>：设置256个1×1×3的卷积核，对深度卷积的输出再进行卷积操作，最终得到<br>8×8×256的输出</p><p><strong>参数计算：</strong><br>深度卷积参数 = 5×5×3 = 75</p><p>逐点卷积参数 = 256×1×1×3 = 768</p><p>总参数 = 75 + 768 = 843 &lt;&lt; 19200</p><p><img src="https://img-blog.csdnimg.cn/ab7f954841c742f0a3e8cfb3bed2deb9.png"><img src="https://img-blog.csdnimg.cn/88a7b178f787413b988845637267109a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h3><p><strong>编码器：</strong></p><ol><li>使用DeepLab v3作为编码器结构，输出与输入尺寸之比16(output_stride = 16)。</li><li>ASPP：一个1×1卷积 + 三个3×3卷积(rate = {6, 12, 18}) + 全局平均池化。</li></ol><p><strong>解码器：</strong></p><ol><li>先把encoder的结果上采样4倍（双线性插值），然后与编码器中相对应尺寸的特征图进行拼接融合，再进行3x3的卷积， 最后上采样4倍得到最终结果</li><li>融合低层次信息前，先进行1x1的卷积， 目的是降低通道数。</li></ol><p><img src="https://img-blog.csdnimg.cn/1da65cd0dc424bd6909775d7fb95481c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>DeepLab v3+对Xception进行了微调：</p><p><img src="https://img-blog.csdnimg.cn/3c2a712dda4747999a01a4b8a821a00e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/464b22aff4be4d0baab40e86d8807878.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/312255e342ef4d718f1c594f88c1518a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><ol><li>更深的Xception结构，原始middle flow迭代8次，微调后迭代16次。</li><li>所有max pooling结构被stride=2的深度可分离卷积替代。</li><li>每个3x3的depthwise convolution（结合了空洞卷积）后都跟BN和Relu。</li></ol><h3 id="实验设置-3"><a href="#实验设置-3" class="headerlink" title="实验设置"></a>实验设置</h3><p>剪尺寸：裁剪图片至513*513</p><p>学习率策略：采用poly策略，原理同v2 v3</p><p><img src="https://img-blog.csdnimg.cn/8cdd6315658b41bdbfd6991e1d0bde7e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/d6b6db83db33440f83c2ee466866ed94.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h2 id="论文总结"><a href="#论文总结" class="headerlink" title="论文总结"></a>论文总结</h2><p><strong>DeepLab系列发展历程</strong></p><p>v1：修改经典分类网络(VGG16)，将空洞卷积应用于模型中，试图解决分辨率过低及提取多尺度特征问题，用CRF做后处理（VGG16+空洞卷积+CRF对边缘分割结果进行后处理）</p><p>v2：设计ASPP模块，将空洞卷积的性能发挥到最大，沿用VGG16作为主网络，尝试使用ResNet-101进行对比实验，用CRF做后处理（VGG16/ResNet+串行的ASPP模块+CRF对边缘分割结果进行后处理）</p><p>v3：以ResNet为主网络，设计了一种串行和一种并行的DCNN网络，微调ASPP模块，取消CRF做后处理（ResNet+改进后的并行ASPP模块）</p><p>v3+：以ResNet或Xception为主网络，结合编解码结构设计了一种新的算法模型，以v3作为编码器结构，另行设计了解码器结构，取消CRF做后处理（ResNet/Xception+并行的ASPP模块+编码器结构）</p><p><img src="https://img-blog.csdnimg.cn/0e4dda37ed6f41d4bb1245ef9fc9d198.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/23d1c632752747d0b5355e5ead2f5230.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> 语义分割 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树</title>
      <link href="/2021/07/20/jue-ce-shu/"/>
      <url>/2021/07/20/jue-ce-shu/</url>
      
        <content type="html"><![CDATA[<h2 id="1-什么是决策树"><a href="#1-什么是决策树" class="headerlink" title="1. 什么是决策树"></a>1. 什么是决策树</h2><h3 id="1-1-决策树的基本思想"><a href="#1-1-决策树的基本思想" class="headerlink" title="1.1 决策树的基本思想"></a>1.1 决策树的基本思想</h3><p>其实用一下图片能更好的理解LR模型和决策树模型算法的根本区别，我们可以思考一下一个决策问题：是否去相亲，一个女孩的母亲要给这个女孩介绍对象。</p><p><img src="https://img-blog.csdnimg.cn/20210720130343601.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>大家都看得很明白了吧！LR模型是一股脑儿的把所有特征塞入学习，而决策树更像是编程语言中的if-else一样，去做条件判断，这就是根本性的区别。</p><h3 id="1-2-“树”的成长过程"><a href="#1-2-“树”的成长过程" class="headerlink" title="1.2 “树”的成长过程"></a>1.2 “树”的成长过程</h3><p>决策树基于“树”结构进行决策的，这时我们就要面临两个问题 ：</p><ul><li>“树”怎么长。</li><li>这颗“树”长到什么时候停。</li></ul><p>弄懂了这两个问题，那么这个模型就已经建立起来了，决策树的总体流程是“分而治之”的思想，一是自根至叶的递归过程，一是在每个中间节点寻找一个“划分”属性，相当于就是一个特征属性了。接下来我们来逐个解决以上两个问题。</p><h4 id="这颗“树”长到什么时候停"><a href="#这颗“树”长到什么时候停" class="headerlink" title="这颗“树”长到什么时候停"></a>这颗“树”长到什么时候停</h4><ul><li>当前结点包含的样本全属于同一类别，无需划分；例如：样本当中都是决定去相亲的，属于同一类别，就是不管特征如何改变都不会影响结果，这种就不需要划分了。</li><li>当前属性集为空，或是所有样本在所有属性上取值相同，无法划分；例如：所有的样本特征都是一样的，就造成无法划分了，训练集太单一。</li><li>当前结点包含的样本集合为空，不能划分。</li></ul><h3 id="1-3-“树”怎么长"><a href="#1-3-“树”怎么长" class="headerlink" title="1.3 “树”怎么长"></a>1.3 “树”怎么长</h3><p>在生活当中，我们都会碰到很多需要做出决策的地方，例如：吃饭地点、数码产品购买、旅游地区等，你会发现在这些选择当中都是依赖于大部分人做出的选择，也就是跟随大众的选择。其实在决策树当中也是一样的，当大部分的样本都是同一类的时候，那么就已经做出了决策。</p><p>我们可以把大众的选择抽象化，这就引入了一个概念就是纯度，想想也是如此，大众选择就意味着纯度越高。好，在深入一点，就涉及到一句话：<strong>信息熵越低，纯度越高</strong>。我相信大家或多或少都听说过“熵”这个概念，信息熵通俗来说就是用来度量包含的“信息量”，如果样本的属性都是一样的，就会让人觉得这包含的信息很单一，没有差异化，相反样本的属性都不一样，那么包含的信息量就很多了。</p><p>一到这里就头疼了，因为马上要引入信息熵的公式，其实也很简单：</p><p><img src="https://latex.codecogs.com/gif.latex?Ent(D)=-%5Csum_%7Bk=1%7D%5E%7B%7Cy%7C%7Dp_klog_2p_k"></p><p>Pk表示的是：当前样本集合D中第k类样本所占的比例为Pk。</p><p><strong>信息增益</strong></p><p>废话不多说直接上公式：</p><p><img src="https://img-blog.csdnimg.cn/20210720130402746.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>看不懂的先不管，简单一句话就是：划分前的信息熵–划分后的信息熵。表示的是向纯度方向迈出的“步长”。</p><p>好了，有了前面的知识，我们就可以开始“树”的生长了。</p><h4 id="1-3-1-ID3算法"><a href="#1-3-1-ID3算法" class="headerlink" title="1.3.1 ID3算法"></a>1.3.1 ID3算法</h4><p>解释：在根节点处计算信息熵，然后根据属性依次划分并计算其节点的信息熵，用根节点信息熵–属性节点的信息熵=信息增益，根据信息增益进行降序排列，排在前面的就是第一个划分属性，其后依次类推，这就得到了决策树的形状，也就是怎么“长”了。</p><p>如果不理解的，可以查看我分享的图片示例，结合我说的，包你看懂：</p><p><img src="https://img-blog.csdnimg.cn/20210720124641339.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="第一张图"><br><img src="https://img-blog.csdnimg.cn/2021072012465192.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="第二张图"><br><img src="https://img-blog.csdnimg.cn/20210720124747106.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="第三张图"><br><img src="https://img-blog.csdnimg.cn/20210720124710420.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="第四张图"></p><p>不过，信息增益有一个问题：对可取值数目较多的属性有所偏好，例如：考虑将“编号”作为一个属性。为了解决这个问题，引出了另一个 算法C4.5。</p><h4 id="1-3-2-C4-5"><a href="#1-3-2-C4-5" class="headerlink" title="1.3.2 C4.5"></a>1.3.2 C4.5</h4><p>为了解决信息增益的问题，引入一个信息增益率：</p><p><img src="https://latex.codecogs.com/gif.latex?Gain_ratio(D,a)=%5Cfrac%7BGain(D,a)%7D%7BIV(a)%7D"></p><p>其中：</p><p><img src="https://latex.codecogs.com/gif.latex?IV(a)=-%5Csum_%7Bv=1%7D%5E%7BV%7D%5Cfrac%7B%7CD%5Ev%7C%7D%7B%7CD%7C%7Dlog_2%5Cfrac%7B%7CD%5Ev%7C%7D%7B%7CD%7C%7D"></p><p>属性a的可能取值数目越多(即V越大)，则IV(a)的值通常就越大。<strong>信息增益比本质： 是在信息增益的基础之上乘上一个惩罚参数。特征个数较多时，惩罚参数较小；特征个数较少时，惩罚参数较大。</strong>不过有一个缺点：</p><ul><li>缺点：信息增益率偏向取值较少的特征。</li></ul><p>使用信息增益率：基于以上缺点，并不是直接选择信息增益率最大的特征，而是现在候选特征中找出信息增益高于平均水平的特征，然后在这些特征中再选择信息增益率最高的特征。</p><h4 id="1-3-3-CART算法"><a href="#1-3-3-CART算法" class="headerlink" title="1.3.3 CART算法"></a>1.3.3 CART算法</h4><p>数学家真实聪明，想到了另外一个表示纯度的方法，叫做基尼指数(讨厌的公式)：</p><p><img src="https://img-blog.csdnimg.cn/20210720130427569.jpg"></p><p>表示在样本集合中一个随机选中的样本被分错的概率。举例来说，现在一个袋子里有3种颜色的球若干个，伸手进去掏出2个球，颜色不一样的概率，这下明白了吧。<strong>Gini(D)越小，数据集D的纯度越高。</strong></p><h5 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h5><p>假设现在有特征 “学历”，此特征有三个特征取值： “本科”，“硕士”， “博士”，</p><p>当使用“学历”这个特征对样本集合D进行划分时，划分值分别有三个，因而有三种划分的可能集合，划分后的子集如下：</p><p>1.划分点： “本科”，划分后的子集合 ： {本科}，{硕士，博士}</p><p>2.划分点： “硕士”，划分后的子集合 ： {硕士}，{本科，博士}</p><p>3.划分点： “硕士”，划分后的子集合 ： {博士}，{本科，硕士}}</p><p>对于上述的每一种划分，都可以计算出基于 <strong>划分特征= 某个特征值</strong> 将样本集合D划分为两个子集的纯度：</p><p><img src="https://latex.codecogs.com/gif.latex?Gini(D,A)=%5Cfrac%7B%7CD_1%7C%7D%7B%7CD%7C%7DGini(D_1)+%5Cfrac%7B%7CD_2%7C%7D%7B%7CD%7C%7DGini(D_2)"></p><p>因而<strong>对于一个具有多个取值（超过2个）的特征，需要计算以每一个取值作为划分点，对样本D划分之后子集的纯度Gini(D,Ai)，(其中Ai 表示特征A的可能取值)</strong></p><p>然后从所有的可能划分的Gini(D,Ai)中找出Gini指数最小的划分，这个划分的划分点，便是使用特征A对样本集合D进行划分的最佳划分点。到此就可以长成一棵“大树”了。</p><h4 id="1-3-4-三种不同的决策树"><a href="#1-3-4-三种不同的决策树" class="headerlink" title="1.3.4 三种不同的决策树"></a>1.3.4 三种不同的决策树</h4><ul><li><p><strong>ID3</strong>：取值多的属性，更容易使数据更纯，其信息增益更大。</p><p>训练得到的是一棵庞大且深度浅的树：不合理。</p></li><li><p><strong>C4.5</strong>：采用信息增益率替代信息增益。</p></li><li><p><strong>CART</strong>：以基尼系数替代熵，最小化不纯度，而不是最大化信息增益。</p></li></ul><h2 id="2-树形结构为什么不需要归一化"><a href="#2-树形结构为什么不需要归一化" class="headerlink" title="2. 树形结构为什么不需要归一化?"></a>2. 树形结构为什么不需要归一化?</h2><p>因为数值缩放不影响分裂点位置，对树模型的结构不造成影响。<br>按照特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会有不同。而且，树模型是不能进行梯度下降的，因为构建树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，因此树模型是阶跃的，阶跃点是不可导的，并且求导没意义，也就不需要归一化。</p><p>既然树形结构（如决策树、RF）不需要归一化，那为何非树形结构比如Adaboost、SVM、LR、Knn、KMeans之类则需要归一化。</p><p>对于线性模型，特征值差别很大时，运用梯度下降的时候，损失等高线是椭圆形，需要进行多次迭代才能到达最优点。<br>但是如果进行了归一化，那么等高线就是圆形的，促使SGD往原点迭代，从而导致需要的迭代次数较少。</p><h2 id="3-分类决策树和回归决策树的区别"><a href="#3-分类决策树和回归决策树的区别" class="headerlink" title="3. 分类决策树和回归决策树的区别"></a>3. 分类决策树和回归决策树的区别</h2><p>Classification And Regression Tree(CART)是决策树的一种，CART算法既可以用于创建分类树（Classification Tree），也可以用于创建回归树（Regression Tree），两者在建树的过程稍有差异。</p><p><strong>回归树</strong>：</p><p>CART回归树是假设树为二叉树，通过不断将特征进行分裂。比如当前树结点是基于第j个特征值进行分裂的，设该特征值小于s的样本划分为左子树，大于s的样本划分为右子树。 </p><p><img src="https://julyedu-img.oss-cn-beijing.aliyuncs.com/quesbase6415343854853617715.png"></p><p>而CART回归树实质上就是在该特征维度对样本空间进行划分，而这种空间划分的优化是一种NP难问题，因此，在决策树模型中是使用启发式方法解决。典型CART回归树产生的目标函数为：</p><p><img src="https://julyedu-img.oss-cn-beijing.aliyuncs.com/quesbase64153438551488112806.png"></p><p>因此，当我们为了求解最优的切分特征j和最优的切分点s，就转化为求解这么一个目标函数：</p><p><img src="https://julyedu-img.oss-cn-beijing.aliyuncs.com/quesbase6415343855213970444.png"></p><p>所以我们只要遍历所有特征的的所有切分点，就能找到最优的切分特征和切分点。最终得到一棵回归树。</p><p>参考文章：<a href="https://blog.csdn.net/jiede1/article/details/76034328">经典算法详解–CART分类决策树、回归树和模型树</a></p><h2 id="4-决策树如何剪枝"><a href="#4-决策树如何剪枝" class="headerlink" title="4. 决策树如何剪枝"></a>4. 决策树如何剪枝</h2><p>决策树的剪枝基本策略有 预剪枝 (Pre-Pruning) 和 后剪枝 (Post-Pruning)。</p><ul><li><strong>预剪枝</strong>：其中的核心思想就是，在每一次实际对结点进行进一步划分之前，先采用验证集的数据来验证如果划分是否能提高划分的准确性。如果不能，就把结点标记为叶结点并退出进一步划分；如果可以就继续递归生成节点。</li><li><strong>后剪枝</strong>：后剪枝则是先从训练集生成一颗完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来泛化性能提升，则将该子树替换为叶结点。</li></ul><p>参考文章：<a href="https://blog.csdn.net/am290333566/article/details/81187562">决策树及决策树生成与剪枝</a></p><h2 id="5-代码实现"><a href="#5-代码实现" class="headerlink" title="5. 代码实现"></a>5. 代码实现</h2><h3 id="用决策树模型完成分类问题"><a href="#用决策树模型完成分类问题" class="headerlink" title="用决策树模型完成分类问题"></a>用决策树模型完成分类问题</h3><h4 id="把需要的工具库import进来"><a href="#把需要的工具库import进来" class="headerlink" title="把需要的工具库import进来"></a>把需要的工具库import进来</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#用于数据处理和分析的工具包</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token comment">#引入用于数据预处理/特征工程的工具包</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing<span class="token comment">#import决策树建模包</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> tree<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="读数据"><a href="#读数据" class="headerlink" title="读数据"></a>读数据</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">adult_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./DecisionTree.csv'</span><span class="token punctuation">)</span><span class="token comment">#读取前5行，了解一下数据</span>adult_data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20210720125416550.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">adult_data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>adult_data<span class="token punctuation">.</span>shape<span class="token comment">#(32561, 9)</span>adult_data<span class="token punctuation">.</span>columns<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="区分一下特征-属性-和目标"><a href="#区分一下特征-属性-和目标" class="headerlink" title="区分一下特征(属性)和目标"></a>区分一下特征(属性)和目标</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">feature_columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">u'workclass'</span><span class="token punctuation">,</span> <span class="token string">u'education'</span><span class="token punctuation">,</span> <span class="token string">u'marital-status'</span><span class="token punctuation">,</span> <span class="token string">u'occupation'</span><span class="token punctuation">,</span> <span class="token string">u'relationship'</span><span class="token punctuation">,</span> <span class="token string">u'race'</span><span class="token punctuation">,</span> <span class="token string">u'gender'</span><span class="token punctuation">,</span> <span class="token string">u'native-country'</span><span class="token punctuation">]</span>label_column <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'income'</span><span class="token punctuation">]</span><span class="token comment">#区分特征和目标列</span>features <span class="token operator">=</span> adult_data<span class="token punctuation">[</span>feature_columns<span class="token punctuation">]</span>label <span class="token operator">=</span> adult_data<span class="token punctuation">[</span>label_column<span class="token punctuation">]</span>features<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20210720125627697.png"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">label<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20210720125718973.png"></p><h4 id="特征处理-特征工程"><a href="#特征处理-特征工程" class="headerlink" title="特征处理/特征工程"></a>特征处理/特征工程</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">features <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>features<span class="token punctuation">)</span>features<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment">#2 rows × 102 columns</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#初始化一个决策树分类器</span>clf <span class="token operator">=</span> tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span>criterion<span class="token operator">=</span><span class="token string">'entropy'</span><span class="token punctuation">,</span> max_depth<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token comment">#用决策树分类器拟合数据</span>clf <span class="token operator">=</span> clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>features<span class="token punctuation">.</span>values<span class="token punctuation">,</span> label<span class="token punctuation">.</span>values<span class="token punctuation">)</span>clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>features<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="可视化一下这颗决策树"><a href="#可视化一下这颗决策树" class="headerlink" title="可视化一下这颗决策树"></a>可视化一下这颗决策树</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pydotplus<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> display<span class="token punctuation">,</span> Imagedot_data <span class="token operator">=</span> tree<span class="token punctuation">.</span>export_graphviz<span class="token punctuation">(</span>clf<span class="token punctuation">,</span>                                 out_file<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>                                 feature_names<span class="token operator">=</span>features<span class="token punctuation">.</span>columns<span class="token punctuation">,</span>                                class_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;=50k'</span><span class="token punctuation">,</span> <span class="token string">'&gt;50k'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                filled <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>                                rounded <span class="token operator">=</span><span class="token boolean">True</span>                               <span class="token punctuation">)</span>graph <span class="token operator">=</span> pydotplus<span class="token punctuation">.</span>graph_from_dot_data<span class="token punctuation">(</span>dot_data<span class="token punctuation">)</span>display<span class="token punctuation">(</span>Image<span class="token punctuation">(</span>graph<span class="token punctuation">.</span>create_png<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/20210720130011942.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 面试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>逻辑回归</title>
      <link href="/2021/07/18/luo-ji-hui-gui/"/>
      <url>/2021/07/18/luo-ji-hui-gui/</url>
      
        <content type="html"><![CDATA[<h2 id="1-什么是逻辑回归"><a href="#1-什么是逻辑回归" class="headerlink" title="1. 什么是逻辑回归"></a>1. 什么是逻辑回归</h2><p>逻辑回归是用来做分类算法的，大家都熟悉线性回归，一般形式是Y=aX+b，y的取值范围是[-∞, +∞]，有这么多取值，怎么进行分类呢？不用担心，伟大的数学家已经为我们找到了一个方法。</p><p>也就是把Y的结果带入一个非线性变换的<strong>Sigmoid函数</strong>中，即可得到[0,1]之间取值范围的数S，S可以把它看成是一个概率值，如果我们设置概率阈值为0.5，那么S大于0.5可以看成是正样本，小于0.5看成是负样本，就可以进行分类了。</p><h2 id="2-什么是Sigmoid函数"><a href="#2-什么是Sigmoid函数" class="headerlink" title="2. 什么是Sigmoid函数"></a>2. 什么是Sigmoid函数</h2><p>函数公式如下：</p><p><img src="https://img-blog.csdnimg.cn/20210720130704407.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>函数中t无论取什么值，其结果都在[0,-1]的区间内，回想一下，一个分类问题就有两种答案，一种是“是”，一种是“否”，那0对应着“否”，1对应着“是”，那又有人问了，你这不是[0,1]的区间吗，怎么会只有0和1呢？这个问题问得好，我们假设分类的<strong>阈值</strong>是0.5，那么超过0.5的归为1分类，低于0.5的归为0分类，阈值是可以自己设定的。</p><p>好了，接下来我们把aX+b带入t中就得到了我们的逻辑回归的一般模型方程：</p><p><img src="https://latex.codecogs.com/gif.latex?H(a,b)=%5Cfrac%7B1%7D%7B1+e%5E%7B(aX+b)%7D%7D"></p><p>结果P也可以理解为概率，换句话说概率大于0.5的属于1分类，概率小于0.5的属于0分类，这就达到了分类的目的。</p><h2 id="3-损失函数是什么"><a href="#3-损失函数是什么" class="headerlink" title="3. 损失函数是什么"></a>3. 损失函数是什么</h2><p>逻辑回归的损失函数是 <strong>log loss</strong>，也就是<strong>对数似然函数</strong>，函数公式如下：</p><p><img src="https://img-blog.csdnimg.cn/20210720130736546.jpg"></p><p>公式中的 y=1 表示的是真实值为1时用第一个公式，真实 y=0 用第二个公式计算损失。为什么要加上log函数呢？可以试想一下，当真实样本为1是，但h=0概率，那么log0=∞，这就对模型最大的惩罚力度；当h=1时，那么log1=0，相当于没有惩罚，也就是没有损失，达到最优结果。所以数学家就想出了用log函数来表示损失函数。</p><p>最后按照梯度下降法一样，求解极小值点，得到想要的模型效果。</p><h2 id="4-可以进行多分类吗？"><a href="#4-可以进行多分类吗？" class="headerlink" title="4.可以进行多分类吗？"></a>4.可以进行多分类吗？</h2><p>可以的，其实我们可以从二分类问题过度到多分类问题(one vs rest)，思路步骤如下：</p><p>1.将类型class1看作正样本，其他类型全部看作负样本，然后我们就可以得到样本标记类型为该类型的概率p1。</p><p>2.然后再将另外类型class2看作正样本，其他类型全部看作负样本，同理得到p2。</p><p>3.以此循环，我们可以得到该待预测样本的标记类型分别为类型class i时的概率pi，最后我们取pi中最大的那个概率对应的样本标记类型作为我们的待预测样本类型。</p><p><img src="https://img-blog.csdnimg.cn/20210720130803586.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>总之还是以二分类来依次划分，并求出最大概率结果。</p><h2 id="5-逻辑回归有什么优点"><a href="#5-逻辑回归有什么优点" class="headerlink" title="5.逻辑回归有什么优点"></a>5.逻辑回归有什么优点</h2><ul><li>LR能以概率的形式输出结果，而非只是0,1判定。</li><li>LR的可解释性强，可控度高(你要给老板讲的嘛…)。</li><li>训练快，feature engineering之后效果赞。</li><li>因为结果是概率，可以做ranking model。</li></ul><h2 id="6-逻辑回归有哪些应用"><a href="#6-逻辑回归有哪些应用" class="headerlink" title="6. 逻辑回归有哪些应用"></a>6. 逻辑回归有哪些应用</h2><ul><li>CTR预估/推荐系统的learning to rank/各种分类场景。</li><li>某搜索引擎厂的广告CTR预估基线版是LR。</li><li>某电商搜索排序/广告CTR预估基线版是LR。</li><li>某电商的购物搭配推荐用了大量LR。</li><li>某现在一天广告赚1000w+的新闻app排序基线是LR。</li></ul><h2 id="7-逻辑回归常用的优化方法有哪些"><a href="#7-逻辑回归常用的优化方法有哪些" class="headerlink" title="7. 逻辑回归常用的优化方法有哪些"></a>7. 逻辑回归常用的优化方法有哪些</h2><h3 id="7-1-一阶方法"><a href="#7-1-一阶方法" class="headerlink" title="7.1 一阶方法"></a>7.1 一阶方法</h3><p>梯度下降、随机梯度下降、mini 随机梯度下降降法。随机梯度下降不但速度上比原始梯度下降要快，局部最优化问题时可以一定程度上抑制局部最优解的发生。 </p><h3 id="7-2-二阶方法：牛顿法、拟牛顿法："><a href="#7-2-二阶方法：牛顿法、拟牛顿法：" class="headerlink" title="7.2 二阶方法：牛顿法、拟牛顿法："></a>7.2 二阶方法：牛顿法、拟牛顿法：</h3><p>这里详细说一下牛顿法的基本原理和牛顿法的应用方式。牛顿法其实就是通过切线与x轴的交点不断更新切线的位置，直到达到曲线与x轴的交点得到方程解。在实际应用中我们因为常常要求解凸优化问题，也就是要求解函数一阶导数为0的位置，而牛顿法恰好可以给这种问题提供解决方法。实际应用中牛顿法首先选择一个点作为起始点，并进行一次二阶泰勒展开得到导数为0的点进行一个更新，直到达到要求，这时牛顿法也就成了二阶求解问题，比一阶方法更快。我们常常看到的x通常为一个多维向量，这也就引出了Hessian矩阵的概念（就是x的二阶导数矩阵）。</p><p>缺点：牛顿法是定长迭代，没有步长因子，所以不能保证函数值稳定的下降，严重时甚至会失败。还有就是牛顿法要求函数一定是二阶可导的。而且计算Hessian矩阵的逆复杂度很大。</p><p>拟牛顿法： 不用二阶偏导而是构造出Hessian矩阵的近似正定对称矩阵的方法称为拟牛顿法。拟牛顿法的思路就是用一个特别的表达形式来模拟Hessian矩阵或者是他的逆使得表达式满足拟牛顿条件。主要有DFP法（逼近Hession的逆）、BFGS（直接逼近Hession矩阵）、 L-BFGS（可以减少BFGS所需的存储空间）。</p><h2 id="8-逻辑斯特回归为什么要对特征进行离散化。"><a href="#8-逻辑斯特回归为什么要对特征进行离散化。" class="headerlink" title="8. 逻辑斯特回归为什么要对特征进行离散化。"></a>8. 逻辑斯特回归为什么要对特征进行离散化。</h2><ol><li>非线性！非线性！非线性！逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合； 离散特征的增加和减少都很容易，易于模型的快速迭代； </li><li>速度快！速度快！速度快！稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展； </li><li>鲁棒性！鲁棒性！鲁棒性！离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰； </li><li>方便交叉与特征组合：离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力； </li><li>稳定性：特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问； </li><li>简化模型：特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。</li></ol><h2 id="9-逻辑回归的目标函数中增大L1正则化会是什么结果。"><a href="#9-逻辑回归的目标函数中增大L1正则化会是什么结果。" class="headerlink" title="9. 逻辑回归的目标函数中增大L1正则化会是什么结果。"></a>9. 逻辑回归的目标函数中增大L1正则化会是什么结果。</h2><p>所有的参数w都会变成0。</p><h2 id="10-代码实现"><a href="#10-代码实现" class="headerlink" title="10. 代码实现"></a>10. 代码实现</h2><h3 id="10-1-数据"><a href="#10-1-数据" class="headerlink" title="10.1 数据"></a>10.1 数据</h3><p><strong>用于信用评分的机器学习</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;银行在市场经济中发挥着至关重要的作用。他们决定谁可以获得资金以及以什么条件获得资金，并且可以做出或破坏投资决策。为了让市场和社会发挥作用，个人和公司需要获得信贷。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;信用评分算法对违约概率进行猜测，是银行用来确定是否应授予贷款的方法。这项比赛要求参与者通过预测某人在未来两年内遇到财务困境的可能性来提高信用评分的最新水平。<a href="https://www.kaggle.com/c/GiveMeSomeCredit">数据集</a></p><p>属性信息：<br><img src="https://img-blog.csdnimg.cn/20210718152357421.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="10-2-数据处理"><a href="#10-2-数据处理" class="headerlink" title="10.2 数据处理"></a>10.2 数据处理</h3><p>将数据读入 Pandas</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdpd<span class="token punctuation">.</span>set_option<span class="token punctuation">(</span><span class="token string">'display.max_columns'</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span><span class="token keyword">import</span> zipfile<span class="token keyword">with</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span><span class="token string">'KaggleCredit2.csv.zip'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> z<span class="token punctuation">:</span>   <span class="token comment">#读取zip里的文件</span>    f <span class="token operator">=</span> z<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'KaggleCredit2.csv'</span><span class="token punctuation">)</span>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>f<span class="token punctuation">,</span> index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>shape <span class="token comment">##(112915, 11)</span>data<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>   <span class="token comment">#去掉为空的数据</span>data<span class="token punctuation">.</span>shape <span class="token comment">##(108648, 11)</span>y <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'SeriousDlqin2yrs'</span><span class="token punctuation">]</span>X <span class="token operator">=</span> data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'SeriousDlqin2yrs'</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>y<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#求取均值：0.06742876076872101</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="10-3-练习"><a href="#10-3-练习" class="headerlink" title="10.3 练习"></a>10.3 练习</h3><p>1、把数据切分成训练集和测试集</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> model_selectionx_tran<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_tran<span class="token punctuation">,</span>y_test<span class="token operator">=</span>model_selection<span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment">##(21730, 10)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2、使用logistic regression/决策树/SVM/KNN…等sklearn分类算法进行分类，尝试查sklearn API了解模型参数含义，调整不同的参数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression<span class="token comment">## https://blog.csdn.net/sun_shengyun/article/details/53811483</span>lr<span class="token operator">=</span>LogisticRegression<span class="token punctuation">(</span>multi_class<span class="token operator">=</span><span class="token string">'ovr'</span><span class="token punctuation">,</span>solver<span class="token operator">=</span><span class="token string">'sag'</span><span class="token punctuation">,</span>class_weight<span class="token operator">=</span><span class="token string">'balanced'</span><span class="token punctuation">)</span>lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_tran<span class="token punctuation">,</span>y_tran<span class="token punctuation">)</span>score<span class="token operator">=</span>lr<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_tran<span class="token punctuation">,</span>y_tran<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>score<span class="token punctuation">)</span> <span class="token comment">#最好的分数是1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3、在测试集上进行预测，计算准确度</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_scoretrain_score<span class="token operator">=</span>accuracy_score<span class="token punctuation">(</span>y_tran<span class="token punctuation">,</span>lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_tran<span class="token punctuation">)</span><span class="token punctuation">)</span>test_score<span class="token operator">=</span>lr<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集准确率：'</span><span class="token punctuation">,</span>train_score<span class="token punctuation">)</span> <span class="token comment">#训练集准确率： 0.9323730412572769</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试集准确率：'</span><span class="token punctuation">,</span>test_score<span class="token punctuation">)</span>  <span class="token comment">#测试集准确率： 0.9332719742291763</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4、查看sklearn的官方说明，了解分类问题的评估标准，并对此例进行评估。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#召回率</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> recall_scoretrain_recall<span class="token operator">=</span>recall_score<span class="token punctuation">(</span>y_tran<span class="token punctuation">,</span>lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_tran<span class="token punctuation">)</span><span class="token punctuation">,</span>average<span class="token operator">=</span><span class="token string">'macro'</span><span class="token punctuation">)</span>test_recall<span class="token operator">=</span>recall_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">,</span>average<span class="token operator">=</span><span class="token string">'macro'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集召回率：'</span><span class="token punctuation">,</span>train_recall<span class="token punctuation">)</span> <span class="token comment">#训练集召回率： 0.4999938302834368</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试集召回率：'</span><span class="token punctuation">,</span>test_recall<span class="token punctuation">)</span> <span class="token comment">#测试集召回率： 0.4999753463833144</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5、银行通常会有更严格的要求，因为fraud带来的后果通常比较严重，一般我们会调整模型的标准。<br>比如在logistic regression当中，一般我们的概率判定边界为0.5，但是我们可以把阈值设定低一些，来提高模型的“敏感度”，试试看把阈值设定为0.3，再看看这时的评估指标(主要是准确率和召回率)。</p><p>tips:sklearn的很多分类模型，predict_prob可以拿到预估的概率，可以根据它和设定的阈值大小去判断最终结果(分类类别)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npy_pro<span class="token operator">=</span>lr<span class="token punctuation">.</span>predict_proba<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span> <span class="token comment">#获取预测概率值</span>y_prd2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">(</span>p<span class="token operator">&gt;=</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>index<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span>p <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>y_pro<span class="token punctuation">)</span><span class="token punctuation">]</span>   <span class="token comment">#设定0.3阈值，把大于0.3的看成1分类。</span>train_score<span class="token operator">=</span>accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_prd2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>train_score<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归</title>
      <link href="/2021/07/18/xian-xing-hui-gui/"/>
      <url>/2021/07/18/xian-xing-hui-gui/</url>
      
        <content type="html"><![CDATA[<h2 id="1-什么是线性回归"><a href="#1-什么是线性回归" class="headerlink" title="1.什么是线性回归"></a>1.什么是线性回归</h2><ul><li>线性：两个变量之间的关系<strong>是</strong>一次函数关系的——图象<strong>是直线</strong>，叫做线性。</li><li>非线性：两个变量之间的关系<strong>不是</strong>一次函数关系的——图象<strong>不是直线</strong>，叫做非线性。</li><li>回归：人们在测量事物的时候因为客观条件所限，求得的都是测量值，而不是事物真实的值，为了能够得到真实值，无限次的进行测量，最后通过这些测量数据计算<strong>回归到真实值</strong>，这就是回归的由来。</li></ul><h2 id="2-能够解决什么样的问题"><a href="#2-能够解决什么样的问题" class="headerlink" title="2. 能够解决什么样的问题"></a>2. 能够解决什么样的问题</h2><p>对大量的观测数据进行处理，从而得到比较符合事物内部规律的数学表达式。也就是说寻找到数据与数据之间的规律所在，从而就可以模拟出结果，也就是对结果进行预测。解决的就是通过已知的数据得到未知的结果。例如：对房价的预测、判断信用评价、电影票房预估等。</p><h2 id="3-一般表达式是什么"><a href="#3-一般表达式是什么" class="headerlink" title="3. 一般表达式是什么"></a>3. 一般表达式是什么</h2><p><img src="https://latex.codecogs.com/gif.latex?Y=wx+b"></p><p>w叫做x的系数，b叫做偏置项。</p><h2 id="4-如何计算"><a href="#4-如何计算" class="headerlink" title="4. 如何计算"></a>4. 如何计算</h2><h3 id="4-1-Loss-Function–MSE"><a href="#4-1-Loss-Function–MSE" class="headerlink" title="4.1 Loss Function–MSE"></a>4.1 Loss Function–MSE</h3><p><img src="https://latex.codecogs.com/gif.latex?J=%5Cfrac%7B1%7D%7B2m%7D%5Csum%5E%7Bi=1%7D_%7Bm%7D(y%5E%7B%27%7D-y)%5E2"></p><p>利用<strong>梯度下降法</strong>找到最小值点，也就是最小误差，最后把 w 和 b 给求出来。</p><h2 id="5-过拟合、欠拟合如何解决"><a href="#5-过拟合、欠拟合如何解决" class="headerlink" title="5. 过拟合、欠拟合如何解决"></a>5. 过拟合、欠拟合如何解决</h2><p>使用正则化项，也就是给loss function加上一个参数项，正则化项有<strong>L1正则化、L2正则化、ElasticNet</strong>。加入这个正则化项好处：</p><ul><li>控制参数幅度，不让模型“无法无天”。</li><li>限制参数搜索空间</li><li>解决欠拟合与过拟合的问题。</li></ul><h3 id="5-1-什么是L2正则化-岭回归"><a href="#5-1-什么是L2正则化-岭回归" class="headerlink" title="5.1 什么是L2正则化(岭回归)"></a>5.1 什么是L2正则化(岭回归)</h3><p>方程：</p><p><img src="https://latex.codecogs.com/gif.latex?J=J_0+%5Clambda%5Csum_%7Bw%7Dw%5E2"></p><p><img src="https://latex.codecogs.com/gif.latex?J_0">表示上面的 loss function ，在loss function的基础上加入w参数的平方和乘以 <img src="https://latex.codecogs.com/gif.latex?%5Clambda"> ，假设：</p><p><img src="https://latex.codecogs.com/gif.latex?L=%5Clambda(%7Bw_1%7D%5E2+%7Bw_2%7D%5E2)"></p><p>回忆以前学过的单位元的方程：</p><p><img src="https://latex.codecogs.com/gif.latex?x%5E2+y%5E2=1"></p><p>正和L2正则化项一样，此时我们的任务变成在L约束下求出J取最小值的解。求解J0的过程可以画出等值线。同时L2正则化的函数L也可以在w1w2的二维平面上画出来。如下图：</p><p><img src="https://img-blog.csdnimg.cn/20210718150029340.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>L表示为图中的黑色圆形，随着梯度下降法的不断逼近，与圆第一次产生交点，而这个交点很难出现在坐标轴上。这就说明了L2正则化不容易得到稀疏矩阵，同时为了求出损失函数的最小值，使得w1和w2无限接近于0，达到防止过拟合的问题。</p><h3 id="5-2-什么场景下用L2正则化"><a href="#5-2-什么场景下用L2正则化" class="headerlink" title="5.2 什么场景下用L2正则化"></a>5.2 什么场景下用L2正则化</h3><p>只要数据线性相关，用LinearRegression拟合的不是很好，<strong>需要正则化</strong>，可以考虑使用岭回归(L2), 如何输入特征的维度很高,而且是稀疏线性关系的话， 岭回归就不太合适,考虑使用Lasso回归。</p><h3 id="5-3-什么是L1正则化-Lasso回归"><a href="#5-3-什么是L1正则化-Lasso回归" class="headerlink" title="5.3 什么是L1正则化(Lasso回归)"></a>5.3 什么是L1正则化(Lasso回归)</h3><p>L1正则化与L2正则化的区别在于惩罚项的不同：</p><p><img src="https://latex.codecogs.com/gif.latex?J=J_0+%5Clambda(%7Cw_1%7C+%7Cw_2%7C)"></p><p>求解J0的过程可以画出等值线。同时L1正则化的函数也可以在w1w2的二维平面上画出来。如下图：</p><p><img src="https://img-blog.csdnimg.cn/20210718150255507.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>惩罚项表示为图中的黑色棱形，随着梯度下降法的不断逼近，与棱形第一次产生交点，而这个交点很容易出现在坐标轴上。<strong>这就说明了L1正则化容易得到稀疏矩阵。</strong></p><h3 id="5-4-什么场景下使用L1正则化"><a href="#5-4-什么场景下使用L1正则化" class="headerlink" title="5.4 什么场景下使用L1正则化"></a>5.4 什么场景下使用L1正则化</h3><p><strong>L1正则化(Lasso回归)可以使得一些特征的系数变小,甚至还使一些绝对值较小的系数直接变为0</strong>，从而增强模型的泛化能力 。对于高的特征数据,尤其是线性关系是稀疏的，就采用L1正则化(Lasso回归),或者是要在一堆特征里面找出主要的特征，那么L1正则化(Lasso回归)更是首选了。</p><h3 id="5-5-什么是ElasticNet回归"><a href="#5-5-什么是ElasticNet回归" class="headerlink" title="5.5 什么是ElasticNet回归"></a>5.5 什么是ElasticNet回归</h3><p><strong>ElasticNet综合了L1正则化项和L2正则化项</strong>，以下是它的公式：</p><p><img src="https://latex.codecogs.com/gif.latex?min(%5Cfrac%7B1%7D%7B2m%7D%5B%5Csum_%7Bi=1%7D%5E%7Bm%7D(%7By_i%7D%5E%7B%27%7D-y_i)%5E2+%5Clambda%5Csum_%7Bj=1%7D%5E%7Bn%7D%5Ctheta_j%5E2%5D+%5Clambda%5Csum_%7Bj=1%7D%5E%7Bn%7D%7C%5Ctheta%7C)"></p><h3 id="5-6-ElasticNet回归的使用场景"><a href="#5-6-ElasticNet回归的使用场景" class="headerlink" title="5.6  ElasticNet回归的使用场景"></a>5.6  ElasticNet回归的使用场景</h3><p>ElasticNet在我们发现用Lasso回归太过(太多特征被稀疏为0),而岭回归也正则化的不够(回归系数衰减太慢)的时候，可以考虑使用ElasticNet回归来综合，得到比较好的结果。</p><h2 id="6-线性回归要求因变量服从正态分布？"><a href="#6-线性回归要求因变量服从正态分布？" class="headerlink" title="6. 线性回归要求因变量服从正态分布？"></a>6. 线性回归要求因变量服从正态分布？</h2><p>我们假设线性回归的噪声服从均值为0的正态分布。 当噪声符合正态分布N(0,delta^2)时，因变量则符合正态分布N(ax(i)+b,delta^2)，其中预测函数y=ax(i)+b。这个结论可以由正态分布的概率密度函数得到。也就是说当噪声符合正态分布时，其因变量必然也符合正态分布。 </p><p>在用线性回归模型拟合数据之前，首先要求数据应符合或近似符合正态分布，否则得到的拟合函数不正确。</p><h2 id="7-代码部分"><a href="#7-代码部分" class="headerlink" title="7.代码部分"></a>7.代码部分</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这篇介绍的是我在做房价预测模型时的python代码，房价预测在机器学习入门中已经是个经典的题目了，但我发现目前网上还没有能够很好地做一个demo出来，使得入门者不能很快的找到“入口”在哪，所以在此介绍我是如何做的预测房价模型的题目，仅供参考。</p><h3 id="7-1-题目"><a href="#7-1-题目" class="headerlink" title="7.1 题目"></a>7.1 题目</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从给定的房屋基本信息以及房屋销售信息等，建立一个回归模型预测房屋的销售价格。<br>数据下载请点击：<a href="https://pan.baidu.com/s/1-hA9QUx70WGDkNlzK67CBA">下载</a>，密码：66ms。</p><ul><li><strong>数据说明</strong>：<br>数据主要包括2014年5月至2015年5月美国King County的房屋销售价格以及房屋的基本信息。<br>数据分为训练数据和测试数据，分别保存在kc_train.csv和kc_test.csv两个文件中。<br>其中训练数据主要包括10000条记录，14个字段，主要字段说明如下：<br>第一列“销售日期”：2014年5月到2015年5月房屋出售时的日期a<br>第二列“销售价格”：房屋交易价格，单位为美元，是目标预测值<br>第三列“卧室数”：房屋中的卧室数目<br>第四列“浴室数”：房屋中的浴室数目<br>第五列“房屋面积”：房屋里的生活面积<br>第六列“停车面积”：停车坪的面积<br>第七列“楼层数”：房屋的楼层数<br>第八列“房屋评分”：King County房屋评分系统对房屋的总体评分<br>第九列“建筑面积”：除了地下室之外的房屋建筑面积<br>第十列“地下室面积”：地下室的面积<br>第十一列“建筑年份”：房屋建成的年份<br>第十二列“修复年份”：房屋上次修复的年份<br>第十三列”纬度”：房屋所在纬度<br>第十四列“经度”：房屋所在经度</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;测试数据主要包括3000条记录，13个字段，跟训练数据的不同是测试数据并不包括房屋销售价格，学员需要通过由训练数据所建立的模型以及所给的测试数据，得出测试数据相应的房屋销售价格预测值。</p><h3 id="7-2-步骤"><a href="#7-2-步骤" class="headerlink" title="7.2 步骤"></a>7.2 步骤</h3><p><img src="http://www.wailian.work/images/2018/12/10/12400f554.png"></p><ul><li>1.选择合适的模型，对模型的好坏进行评估和选择。</li><li>2.对缺失的值进行补齐操作，可以使用均值的方式补齐数据，使得准确度更高。</li><li>3.数据的取值一般跟属性有关系，但世界万物的属性是很多的，有些值小，但不代表不重要，所有为了提高预测的准确度，统一数据维度进行计算，方法有特征缩放和归一法等。</li><li>4.数据处理好之后就可以进行调用模型库进行训练了。</li><li>5.使用测试数据进行目标函数预测输出，观察结果是否符合预期。或者通过画出对比函数进行结果线条对比。</li></ul><h3 id="7-3-模型选择"><a href="#7-3-模型选择" class="headerlink" title="7.3 模型选择"></a>7.3 模型选择</h3><p>这里我们选择多元线性回归模型。公式如下：选择多元线性回归模型。<br><img src="http://www.wailian.work/images/2018/12/10/12409d868.png"></p><p>y表示我们要求的销售价格，x表示特征值。需要调用sklearn库来进行训练。</p><h3 id="7-4-环境配置"><a href="#7-4-环境配置" class="headerlink" title="7.4 环境配置"></a>7.4 环境配置</h3><ul><li>python3.5</li><li>numpy库</li><li>pandas库</li><li>matplotlib库进行画图</li><li>seaborn库</li><li>sklearn库</li></ul><h3 id="7-5csv数据处理"><a href="#7-5csv数据处理" class="headerlink" title="7. 5csv数据处理"></a>7. 5csv数据处理</h3><p>下载的是两个数据文件，一个是真实数据，一个是测试数据，打开<em>kc_train.csv</em>，能够看到第二列是销售价格，而我们要预测的就是销售价格，所以在训练过程中是不需要销售价格的，把第二列删除掉，新建一个csv文件存放销售价格这一列，作为后面的结果对比。</p><h3 id="7-6数据处理"><a href="#7-6数据处理" class="headerlink" title="7.6数据处理"></a>7.6数据处理</h3><p>首先先读取数据，查看数据是否存在缺失值，然后进行特征缩放统一数据维度。代码如下：(注：最后会给出完整代码)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#读取数据</span>housing <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'kc_train.csv'</span><span class="token punctuation">)</span>target<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'kc_train2.csv'</span><span class="token punctuation">)</span>  <span class="token comment">#销售价格</span>t<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'kc_test.csv'</span><span class="token punctuation">)</span>         <span class="token comment">#测试数据</span><span class="token comment">#数据预处理</span>housing<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">#查看是否有缺失值</span><span class="token comment">#特征缩放</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScalerminmax_scaler<span class="token operator">=</span>MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>minmax_scaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>housing<span class="token punctuation">)</span>   <span class="token comment">#进行内部拟合，内部参数会发生变化</span>scaler_housing<span class="token operator">=</span>minmax_scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>housing<span class="token punctuation">)</span>scaler_housing<span class="token operator">=</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>scaler_housing<span class="token punctuation">,</span>columns<span class="token operator">=</span>housing<span class="token punctuation">.</span>columns<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="7-7-模型训练"><a href="#7-7-模型训练" class="headerlink" title="7.7 模型训练"></a>7.7 模型训练</h3><p>使用sklearn库的线性回归函数进行调用训练。梯度下降法获得误差最小值。最后使用均方误差法来评价模型的好坏程度，并画图进行比较。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#选择基于梯度下降的线性回归模型</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegressionLR_reg<span class="token operator">=</span>LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#进行拟合</span>LR_reg<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>scaler_housing<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token comment">#使用均方误差用于评价模型好坏</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_errorpreds<span class="token operator">=</span>LR_reg<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>scaler_housing<span class="token punctuation">)</span>   <span class="token comment">#输入数据进行预测得到结果</span>mse<span class="token operator">=</span>mean_squared_error<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>target<span class="token punctuation">)</span>   <span class="token comment">#使用均方误差来评价模型好坏，可以输出mse进行查看评价值</span><span class="token comment">#绘图进行比较</span>plot<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       <span class="token comment">#画布大小</span>num<span class="token operator">=</span><span class="token number">100</span>x<span class="token operator">=</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>              <span class="token comment">#取100个点进行比较</span>plot<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>target<span class="token punctuation">[</span><span class="token punctuation">:</span>num<span class="token punctuation">]</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'target'</span><span class="token punctuation">)</span>      <span class="token comment">#目标取值</span>plot<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>preds<span class="token punctuation">[</span><span class="token punctuation">:</span>num<span class="token punctuation">]</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'preds'</span><span class="token punctuation">)</span>        <span class="token comment">#预测取值</span>plot<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">)</span>  <span class="token comment">#线条显示位置</span>plot<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后输出的图是这样的：<br><img src="http://www.wailian.work/images/2018/12/10/124094e96.png"><br>从这张结果对比图中就可以看出模型是否得到精确的目标函数，是否能够精确预测房价。</p><ul><li>如果想要预测test文件里的数据，那就把test文件里的数据进行读取，并且进行特征缩放，调用：</li></ul><p><strong>LR_reg.predict(test)</strong><br>就可以得到预测结果，并进行输出操作。</p><ul><li>到这里可以看到机器学习也不是不能够学会，只要深入研究和总结，就能够找到学习的方法，重要的是总结，最后就是调用一些机器学习的方法库就行了，当然这只是入门级的，我觉得入门级的写到这已经足够了，很多人都能够看得懂，代码量不多。但要理解线性回归的概念性东西还是要多看资料。</li></ul><h2 id="8-完整代码"><a href="#8-完整代码" class="headerlink" title="8. 完整代码"></a>8. 完整代码</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 兼容 pythone2,3</span><span class="token keyword">from</span> __future__ <span class="token keyword">import</span> print_function<span class="token comment"># 导入相关python库</span><span class="token keyword">import</span> os<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token comment">#设定随机数种子</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">36</span><span class="token punctuation">)</span><span class="token comment">#使用matplotlib库画图</span><span class="token keyword">import</span> matplotlib<span class="token keyword">import</span> seaborn<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plot<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token comment">#读取数据</span>housing <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'kc_train.csv'</span><span class="token punctuation">)</span>target<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'kc_train2.csv'</span><span class="token punctuation">)</span>  <span class="token comment">#销售价格</span>t<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'kc_test.csv'</span><span class="token punctuation">)</span>         <span class="token comment">#测试数据</span><span class="token comment">#数据预处理</span>housing<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">#查看是否有缺失值</span><span class="token comment">#特征缩放</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScalerminmax_scaler<span class="token operator">=</span>MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>minmax_scaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>housing<span class="token punctuation">)</span>   <span class="token comment">#进行内部拟合，内部参数会发生变化</span>scaler_housing<span class="token operator">=</span>minmax_scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>housing<span class="token punctuation">)</span>scaler_housing<span class="token operator">=</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>scaler_housing<span class="token punctuation">,</span>columns<span class="token operator">=</span>housing<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>mm<span class="token operator">=</span>MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>mm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>t<span class="token punctuation">)</span>scaler_t<span class="token operator">=</span>mm<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>t<span class="token punctuation">)</span>scaler_t<span class="token operator">=</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>scaler_t<span class="token punctuation">,</span>columns<span class="token operator">=</span>t<span class="token punctuation">.</span>columns<span class="token punctuation">)</span><span class="token comment">#选择基于梯度下降的线性回归模型</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegressionLR_reg<span class="token operator">=</span>LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#进行拟合</span>LR_reg<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>scaler_housing<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token comment">#使用均方误差用于评价模型好坏</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_errorpreds<span class="token operator">=</span>LR_reg<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>scaler_housing<span class="token punctuation">)</span>   <span class="token comment">#输入数据进行预测得到结果</span>mse<span class="token operator">=</span>mean_squared_error<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>target<span class="token punctuation">)</span>   <span class="token comment">#使用均方误差来评价模型好坏，可以输出mse进行查看评价值</span><span class="token comment">#绘图进行比较</span>plot<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       <span class="token comment">#画布大小</span>num<span class="token operator">=</span><span class="token number">100</span>x<span class="token operator">=</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>              <span class="token comment">#取100个点进行比较</span>plot<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>target<span class="token punctuation">[</span><span class="token punctuation">:</span>num<span class="token punctuation">]</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'target'</span><span class="token punctuation">)</span>      <span class="token comment">#目标取值</span>plot<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>preds<span class="token punctuation">[</span><span class="token punctuation">:</span>num<span class="token punctuation">]</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'preds'</span><span class="token punctuation">)</span>        <span class="token comment">#预测取值</span>plot<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">)</span>  <span class="token comment">#线条显示位置</span>plot<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#输出测试数据</span>result<span class="token operator">=</span>LR_reg<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>scaler_t<span class="token punctuation">)</span>df_result<span class="token operator">=</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>result<span class="token punctuation">)</span>df_result<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"result.csv"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机视觉入门</title>
      <link href="/2021/07/17/ji-suan-ji-shi-jue-ru-men/"/>
      <url>/2021/07/17/ji-suan-ji-shi-jue-ru-men/</url>
      
        <content type="html"><![CDATA[<h1 id="带你入门计算机视觉"><a href="#带你入门计算机视觉" class="headerlink" title="带你入门计算机视觉"></a>带你入门计算机视觉</h1><p><img src="https://img-blog.csdnimg.cn/20210717162236513.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/5252204a92784f3b8e4ac445552d932e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="思维导图"></p><p><strong>计算机视觉</strong>，相对比自然语言处理这个领域来说入门门槛会稍微低些，而且图片视频相对于文字来说也更具有趣味性和易于理解。然而，这也会导致CV圈越来越卷，通过知乎相关热门问答便能体会到：</p><ul><li><strong>2016年——深度学习的春天是不是要来了?</strong></li><li><strong>2017年——人工智能是不是一个泡沫？</strong></li><li><strong>2018年——算法岗是否值得进入？</strong></li><li><strong>2019年——如何看待算法岗竞争激烈，供不应求？</strong></li><li><strong>2020年——如何看待算法岗一片红海，诸神黄昏?</strong></li><li><strong>2021年——如何看待算法岗灰飞烟灭？</strong><br>小卷怡情，大卷伤身，强卷灰飞烟灭。正所谓人在CV圈，哪有不被卷？<br>希望大家早日从“调参侠”的包袱中脱离出来，成为一名真正合格的算法工程师。</li></ul><p>以下三大维度为大家逐一展开介绍<br><img src="https://img-blog.csdnimg.cn/20210717163203105.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h2 id="软件基础"><a href="#软件基础" class="headerlink" title="软件基础"></a>软件基础</h2><blockquote><p>软基础，可以理解为技能栈，它是支撑整个发展路线的核心。</p></blockquote><h3 id="数学与英语基础"><a href="#数学与英语基础" class="headerlink" title="数学与英语基础"></a>数学与英语基础</h3><p>相信对于任何一个理工科的学生而言，数学的重要性是不言而喻的。因此，掌握好数学基础，有助于我们更好地理解其它知识以及为后面的学习做铺垫。然而，数学领域所涉及到知识可谓非常广泛，如果漫无目的的看，可能对于90%的人来说第一关就已经从入门到放弃了。下面，我们将给出计算机视觉领域所涉及到的一些数学基础，对于需要重点掌握的知识我们均会提及一下，其余未涉及到的知识点可视个人时间精力和研究方向自行查阅相关资料</p><h4 id="微积分"><a href="#微积分" class="headerlink" title="微积分"></a>微积分</h4><p><strong>《微积分》</strong>是现代数学的基础，也是支撑后续几门数学分支的重要基石。顾名思义，微积分里面包含的两个核心组件便是微分和积分。其中，与微分比较接近的概念便是<strong>导数</strong>，熟练的计算导数有助于我们后面推导整个梯度下降的过程。其次，掌握<strong>上确界</strong>和<strong>下确界</strong>的概念有助于我们理解诸如Wasserstein距离，它作为一种损失函数被应用于WGAN以解决训练不稳定的问题。此外，有涉及到GAN方向的同学也可以理解下<strong>Lipschitz连续性</strong>的概念，它对提高GAN训练的稳当性分析具有不可替代的作用。而对于基础的深度学习原理来说，我们更多的需要掌握的概念是：<strong>梯度、偏导数、链式求导法则、导数与函数的极值&amp;单调性&amp;凹凸性判断、定积分与不定积分</strong>。最后，我们可以着重理解下<strong>泰勒公式</strong>，它是理解各种优化算法的核心。</p><h4 id="线性代数与矩阵论"><a href="#线性代数与矩阵论" class="headerlink" title="线性代数与矩阵论"></a>线性代数与矩阵论</h4><p>《线性代数》是工科生的必备基础。由于计算机现有的运算方式大都是基于并行计算的，无论是机器学习或者深度学习模型来说，数据都是以矩阵或者向量化的形式传入的。因此，我们首先要明白<strong>线性空间、向量、标量、矩阵、范数、秩</strong>的概念以及着重掌握矩阵和向量的基本运算方式，这对于我们后面理解一些网络模型结构，如自注意力机制是非常有必要的。此外，对于后面涉及到的机器学习算法学习，我们还应该理解<strong>特征值、特征向量以及矩阵的正定</strong>概念，同时也应该掌握<strong>特征值分解</strong>（主成分分析和线性判别分析等）以及<strong>奇异值分解</strong>（正太贝叶斯分类器及主题模型等）。矩阵论则是线性代数的进一步升华，所要掌握的重点知识为<strong>矩阵分解、线性变换、相似矩阵、欧式空间、正交矩阵、对称矩阵、正定矩阵</strong>。</p><h4 id="概率论与信息论"><a href="#概率论与信息论" class="headerlink" title="概率论与信息论"></a>概率论与信息论</h4><p>《概率论与数理统计》是工科生数理基础的三把斧之一，也是支撑整个机器学习与深度学习原理的核心理论。概率论，本质上是用于描述对不确定性的度量，深度学习本质上也是通过网络进行学习，最终对输入图像计算出一个概率值。对于这门课，我们需要重点掌握的概念有：<strong>随机变量、概率分布、条件概率、统计与假设检验、概率密度及质量函数、贝叶斯公式、期望、方差、协方差</strong>。此外，我们还需要重点掌握一些常见的分布函数，如<strong>0-1分布、二项分布（伯努利分布）、几何分布、高斯分布、指数分布、泊松分布</strong>。最后，我们还应该重点理解<strong>最小二乘法、最大似然估计、指数移动平均</strong>等。而对于《信息论》来说，最需要掌握的一个知识点必定是<strong>熵</strong>。除了理解熵的概念以外，可以着重了解下几种不同的熵理论，如<strong>条件熵、联合熵、相对熵、最大熵以及互信息</strong>。</p><h4 id="最优化方法"><a href="#最优化方法" class="headerlink" title="最优化方法"></a>最优化方法</h4><p>首先，我们可以简单的理解下什么是“最优化”？最优化，直白的说便是指在完成一个目标的时候，我们总是希望能够在<strong>资源受限</strong>的条件下以<strong>最小的代价</strong>来获取<strong>最大的收益</strong>。可以毫不夸张的说，最优化理论是整个机器学习中相对较难且非常重要的一个理论基础，同时也是面试机器学习算法岗或者在该领域继续进修所必不可少的一个门卡。在了解完基本概念的同时，我们也不知不觉的触及到了最优化问题中基本数学描述的三个基本要素，即<strong>决策变量、目标函数以及约束条件</strong>。其次，罗列下这方面所需要掌握的概念及原理：<strong>凸集、凸函数、凸集分离定理、超平面和半空间</strong>。最后，我们需要重点理解的便是梯度下降法，它是目前整个深度学习算法的核心。此外，对于一些诸如<strong>拟牛顿法、阻尼牛顿法、随机梯度下降算法</strong>等可留到后半部分学习。</p><h3 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h3><p>英语，虽然不是我们的母语，但是作为一名新时代的AI从业技术人员或者即将踏入硕博之路的人来说，这是一门必不可少的技能。首先，对于选择就业的同学来说，在日常的工作生活中，都会不可避免的会查阅大量的工具书和英文网站，这就需要我们具备一定的英语基础，才能够在工作中游刃有余，帮助我们快速的定位到关键点。其次，对于想往科研这条路的同学来说，英语更是不可或缺的必备技能。除了平常科研写作要经常用到之外，我们在申请海内外学校的时候还需要要求具有四六级证书（国内）或者雅思托福考试证明（境外），每年往往有许多发表不少科研成果的同学被卡在这里，着实令人惋惜。最后，掌握良好的英语沟通能力，无论对职场发展（去海外工作或者与国外客户合作）还是学术交流（会议）都是具有积极意义的。然而，语言这种东西不能一蹴而就，除了母语环境，我们能做的是每日学习，厚积薄发，后面方可应用自如。</p><h2 id="计算机基础"><a href="#计算机基础" class="headerlink" title="计算机基础"></a>计算机基础</h2><h3 id="Git基础"><a href="#Git基础" class="headerlink" title="Git基础"></a>Git基础</h3><p>git各个分区的转换<br><img src="https://img-blog.csdnimg.cn/20210717163146357.png"><br>Git作为一个版本控制软件，可以帮助我们更好地对我们的项目进行管理，也方便进行多人协同的工作。但是，估计大多数人最常用的还<strong>git clone</strong> （误）。因此这个技能也常常会被大家所忽略但却又是进入工作之后说必须掌握的技能。</p><p>从逻辑上，git所管理的代码可以分为三个区，如上图所示分别为工作区(你正在编写的代码)，本地仓库（保存到本地仓库的代码）以及远程仓库（远程代码库），它们之间的转换所需要用到的命令如上图所示。比如 git commit（提交至本地仓库），git push（把本地代码推到远程库并进行合并），git pull（把远程代码下载下来并合并到工作区），git diff（比较工作区与暂存区的不同）。<strong>虽然平时不用的时候可能会忘掉这些命令，但是需要用的时候看看上图，基本上都能想起每个命令的意义</strong>。</p><h3 id="Linux基础"><a href="#Linux基础" class="headerlink" title="Linux基础"></a>Linux基础</h3><p>大多数情况下，我们的训练环境都是运行在Linux平台上的，因此我们还是有必要掌握一些常用的Linux基础。下面列举一些实际开发工程中经常会用到的指令：</p><ul><li>基本操作：mv(移动)，rm(删除)，cp(复制)，mkdir(创建文件夹), touch(创建文件), scp(用于传送文件)，cat(打印文件到命令行)，grep(查找符合条件的字符串)，ls(查看文件)，chmod(修改权限)，ln(创建软链接)</li><li>压缩/解压命令 ：zip/unzip和tar命令</li><li>系统监控相关：ps(查看进程)，top(类似任务管理器)，df(查看磁盘占用)</li><li> 网络相关：ping(判断网络是否可达)，ifconfig（显示网络设备状态）</li><li>显卡状态：nvidia-smi（需要安装），gpustat（需要安装，这个显示更美观）</li><li>后台运行：nohup（关掉终端也不会停止运行），ctrl+z（切换到后台，关闭终端会结束）</li></ul><blockquote><p>为了安全起见，一般来说不建议用rm来删除文件，而是建立一个垃圾回收文件夹。把平日里不想要的文件通过mv文件统一移动到该文件夹下，然后使用定时清理的脚本清空文件夹里面的内容，以避免“删库跑路”的尴尬。</p></blockquote><h3 id="算法基础"><a href="#算法基础" class="headerlink" title="算法基础"></a>算法基础</h3><p>IT界有一句谚语——<strong>Talk is cheap，show me the code</strong>.虽然平时设计算法、训练模型以及算法部署过程中基本上都不会用到的数据结构相关的知识，奈何大部分互联网公司笔试面试就要撕代码，而且难度也在逐年提升（卷卷卷）。不仅如此，据身边许多人的反应，现在中小公司也学这一招了，所以手撕动态规划算法基本已经成为标配，因此，为了能够在求职的过程中尽可能不让Coding能力成为<strong>减分项</strong>，大家还是需要在这上面多花费点时间。<br>学习数据结构的方法除了看书，弄明白基础数据结构的原理外，最好的学习方法便是实战。关于这点大家可以以Leetcode为主，辅助《剑指offer》等面试宝典进行刷题。对于刚开始刷题的同学，建议按照专题来刷，这样能够比较好得掌握这一类题型的解决方法，更容易加深记忆。比如按照<strong>数组、字符串、链表、栈、队列、哈希表、二叉树、堆、递归、深搜广搜、动态规划</strong>等专题来刷。最后每样都要有所涉及，避免面试出现自己完全没坐做过的类型，几分钟都憋不出一行代码就有点尴尬了，而且给面试官的印象也不好。<br>好玩的事情那么多，谁又喜欢刷题呢？这里给大家一个刷题的思路，让大家更加高效地刷题：</p><ul><li>看懂题目（1-2min）</li><li>设计数据结构+算法，尽量回想一下同类型的题目（1-2min）【没有思路直接去看题解】</li><li>尝试动手将整份代码给敲出来，争取把给定的测试用例都通过（3-5min）</li><li>最后剩下最苦逼的便是调bug了（0-∞min）<blockquote><p>注意：尽量不要在一道题目上花过多的时间，因为有些题目并不是你想就能想出比较好的解决方法。许多题目往往有一套<strong>固定的解题模板</strong>，而我们需要做的是应用好这套模板去解决问题。关于大家都会关心的问题是刷题的时候要用什么语言来刷比较合适？这里推荐大家优先用<strong>Python</strong>吧！相对于其它语言，特别是C++来说，Python的开发效率会显得非常有优势，重点是面试管也能接受。</p></blockquote></li></ul><h3 id="编程基础"><a href="#编程基础" class="headerlink" title="编程基础"></a>编程基础</h3><p>在计算机视觉领域中，前对于前期的模型设计、训练与验证，我们会基于Python语言进行快速的版本迭代，而对于后期模型的部署以及底层op的优化，考虑到实际的生产环境和运行效率则一般会基于C++来实现。</p><ul><li><strong>Why Python？</strong> 作为一门高级语言，Python具备高度的可阅读性，这使得它能够更容易被初学者所接受和掌握，也更易于学习。此外，Python<strong>强大的社区和丰富的第三方库、框架和扩展</strong>也为开发人员带来了极大的便捷，这是它最大的优势！</li><li> <strong>How to learn Python？</strong> 学习任何一门编程语言，包括Python，最好的方法便是实战。因此，第一步我们要了解IDE的概念，不同的<strong>IDE</strong>有不同的适用性，选择合适的开发工具有利于初学者更好的上手。第二步便是找到合适的教程来学习编写Python脚本，这里比较推荐的纸质书籍是《Python从入门到精通》这本书或者直接上在线网站<strong>Python3 教程 <strong>| <a href="https://www.runoob.com/python3/python3-tutorial.html">菜鸟教程</a>。最后一步初学者只需再稍微了解下</strong>解释器</strong>的概念即可，解释器的作用是让计算机能够读懂你的代码脚本应执行相应的操作。</li><li><strong>第三方库：</strong> 语法基础熟悉之后，作为进阶教程，我们可以进一步地学习一些常用的第三方库。比如用于数据分析的Numpy、Pandas；用于可视化的Matplotlib、Seaborn；用于机器学习的Scikit-learn；用于图像处理的Opencv、Scikit-image等。</li><li><strong>环境配置</strong>： 这里笔者强烈推荐大家将Miniconda 3作为我们的虚拟环境包管理。Anaconda是一个用于科学计算的Python发行版，其支持Linux, Mac, Windows系统，提供了包管理与环境管理的功能，可以很方便地解决多版本python并存、切换以及各种第三方包安装问题。而Miniconda则是Anaconda的一个轻量版，足够满足日常的开发需求。</li><li><strong>集成开发环境</strong>：即Integrated Development Environment，IDE，是用于提供程序开发环境的应用程序，一般包括代码编辑器、编译器、调试器和图形用户界面等工具。</li><li><strong>再多唠两句</strong>： Python功能其实远不止上面这些，它对于编写爬虫，搭建个人博客、网站，批量处理文件等都十分方便。对于在这方面有兴趣的同学也可自行探索。</li><li><strong>Why C++？</strong> 尽管Python具有十分强大的功能，然而比较致命的缺点是运行速度慢，相较于C++语言来说是非常慢的。当我们的AI模型训练好之后，下一步便是落地部署。与学术界更关心模型的精度不同，工业界更关心的是模型的部署性能。在实际的生产环境中，由于Python的可移植性和运行速度远不如C++，所以对于后期模型的部署以及底层op的优化都会首选C++。</li><li> <strong>如何部署？</strong> C++部署一般有两种形式。第一种是利用C++从头搭建模型，实现模型训练和推理。第二种是前期先利用Python搭建网络进行训练，后期再将模型载入C++中实现推理。前者开发难度偏大，商用价值较高。而后者开发难度适中，且能满足大多数项目的需求。对于后者，部署C++有两种常用方式：<strong>Pytorch → libtorch和Pytroch→onnx → tensorrt</strong>。</li></ul><h2 id="数据分析与数字图像处理基础"><a href="#数据分析与数字图像处理基础" class="headerlink" title="数据分析与数字图像处理基础"></a>数据分析与数字图像处理基础</h2><h3 id="数据处理与分析"><a href="#数据处理与分析" class="headerlink" title="数据处理与分析"></a>数据处理与分析</h3><p>深度学习项目的成功落地三要素：数据、算法和算力，数据有效地处理与分析是非常关键的一步。简单来说，数据处理与分析即是从大量的、杂乱无章的数据中抽取并分析出有价值的信息。<br>在近十几年的发展上来看，算法本身的创新是非常有限的，大都还是停留在修修补补的阶段。对于一名普通的计算机视觉算法工程师来说，工作中有80%的时间都是在处理数据，因为模型的改动需要考虑到底层算子的适应性，效果不一定好并且工作量会大大增加。因此，我们要学会根据实际应用场景针对性地分析业务需求，通常是基于已开源的大数据集作为pretrain，然后利用业务数据集来finetuning。所以重心还是要学会对业务数据进行<strong>数据清洗</strong>以及选择合适的<strong>数据增强</strong>方式来扩充有限的数据集。而对于一名数据竞赛者来说，更多的应该了解如何开始一个比赛。下面简单的罗列出一个数据分析比赛大体的几个步骤，具体的可以参考后面第3部分&lt;**工具链**&gt;中所罗列出来的竞赛网站自行寻找自己感兴趣的或方向相关的比赛去参加实战一波即可：<br><strong>Exploratory Data Analysis</strong>： 导入数据 → 数据总览 → 变量相关性分析 → 缺失值及异常值处理 → 数据分布变换 → 特征分析（数值型和类别型）；<br><strong>Feature Engineering</strong>： 异常值处理（通过箱形图观察及长尾截断处理等）→ 缺失值处理（分为随机性缺失和非随机性缺失，对应的处理方法分别为RF、SVD、Mean、Median、KNN、NN &amp; Binary、GSimp、QRILC 等）→ 特征离散化 → 数据类型转换（one-hot编码、哈夫曼编码等）→ 特征组合（将具有相关性的特征组合起来形成新的特征，以此来丰富特征的多样性，提高模型的泛化能力）→ 数据降维（PCA）；<br><strong>Modeing</strong>： 选择合适的模型（LightGBM &amp; XGBoost等）→ 交叉验证 → 模型调整（GridSearch &amp; Bayes &amp; 贪心调参等）；<br><strong>Ensemble</strong>： 一般选定3个左右的强模型+多个相关性较小的弱模型进行Voting or Stacking or Boosting。</p><h3 id="数字图像处理"><a href="#数字图像处理" class="headerlink" title="数字图像处理"></a>数字图像处理</h3><blockquote><p>数字图像处理（Digital Image Processing）是通过计算机对图像进行去噪、增强、复原、分割、提取特征等处理的方法和技术。<br>尽管深度学习能实现很高的性能，但目前为止人们仍难以解释其内部工作的机制原理。因此，深度学习本质上还是一个黑盒子。了解数字图像的一些基本概念以及掌握基础的图像处理技能，有助于我们理解更深层次的内容。下面列举一些需要重点了解和掌握的知识点：</p></blockquote><ul><li><strong>图像数字化</strong>： 指的是将模拟（连续）信号的图像转换为数字（离散）信息的过程，主要包含<strong>采样</strong>和<strong>量化</strong>两个步骤。二维图像在计算机中通常是以矩阵的形式表示，这里需要了解图像的一些基本属性，如<strong>图像格式</strong>（BMP &amp; JPEG &amp; GIF &amp; PNG的定义和区别）、<strong>图像分辨率</strong>和<strong>通道数</strong>（8位单通道二值图像 &amp; 24位RGB通道彩色图像 &amp; 32位RGBA通道 &amp; 以及各种通道之间的互相转换）、<strong>图像尺寸</strong>（像素 &amp; 图像宽度和高度）、<strong>图像色彩颜色空间</strong>（RGB &amp; HSV &amp; HSI &amp; CMYK）、<strong>图像插值方法</strong>（最近邻插值、双线性插值、三线性插值）及<strong>图像成像</strong>方式（伽马射线 &amp; X射线等）。</li><li><strong>图像压缩</strong>： 目的是减少图像中的冗余信息，以更高效的格式进行存储和传输数据。一般可分为有损压缩和无损压缩，这里我们只需要简单了解下有哪些经典的压缩算法即可。有兴趣的可以了解下<strong>JPEG压缩算法</strong>的原理和步骤（涉及离散余弦变换 &amp; 量化 &amp; YCbCr色彩空间）</li><li><strong>图像增强</strong>： 指的是利用各种数学方法和变换手段来提高图像对比度与清晰度，使改善后的图像更适应于人的视觉特性或易于机器识别。简单来说，就是要突出感兴趣的特征，抑制不感兴趣的特征，从而改善图像质量。如强化图像中的高频分量，可使图像中物体轮廓清晰，细节更加明显；而强化图像中的低频分量可以减少图像中的噪声影响。这里我们需要重点掌握的是<strong>灰度直方图</strong>的概念，了解什么是<strong>直方图和对比度</strong>，掌握<strong>直方图均衡化</strong>、<strong>限制对比度的自适应直方图均衡化</strong>（CLAHE）以及伽马校正和仿射变换操作。</li><li> <strong>图像复原</strong>： 指的是利用退化过程的先验知识，去恢复已被退化图像的本来面目。这是由于受采集设备和光照等外部环境的影响，图像在形成的过程中不可避免的会失真或者引入背景噪声干扰。因此，我们首先要知道<strong>噪声的来源</strong>（电子元器件发热或传输损失 &amp; 成像系统的调制与缺陷 &amp; 光照等外部环境因素的干扰）以及各种<strong>噪声的来源和特点</strong>（高斯噪声 &amp; 脉冲噪声[椒盐噪声 | 胡椒噪声 | 盐粒噪声] &amp; 泊松噪声 &amp; 斑点噪声）。最后便是如何<strong>去噪</strong>，这里需要重点掌握一些常见的<strong>线性和非线性滤波算法</strong>（均值滤波 &amp; 中值滤波 &amp; 维纳滤波 &amp; 卡尔曼滤波 &amp; 高通滤波 &amp; 低通滤波 &amp; 高斯滤波 &amp; 双边滤波 &amp; 拉普拉斯滤波 &amp; 卷积核 &amp; Gabor滤波器）。需要注意的是，我们在学习的过程中不能停留在定义上，而是应该着重理解各种滤波背后的<strong>工作原理及应用范围</strong>，如低通滤波可用于消除噪声、高通滤波常用语提取边缘，又比如高斯滤波就是用来去除高斯噪声、均值滤波和中值滤波有助于去除胡椒噪声、边滤波则能够在滤波的同时保证一定的边缘信息，但是计算复杂度较高。</li><li><strong>图像基本运算</strong>： 指的是对图像执行一些基本的数学运算。这里涉及到的运算主要可分为<strong>点运算</strong>（线性 &amp; 分段 &amp; 非线性点运算）、<strong>代数运</strong>（加法 &amp; 减法运算）、<strong>逻辑运算</strong>以及最重要的<strong>几何运算</strong>（图像平移 &amp; 旋转 &amp; 翻转 &amp; 镜像 &amp; 缩放）</li><li><strong>图像边缘检测</strong>： 这里仅需了解下有哪些边缘检测算子以及重点掌握一些常见的算子。如<strong>一阶微分算子</strong>（Sobel算子 &amp; Roberts算子 &amp; Prewitt算子）、<strong>二阶微分算子</strong>（Laplacian算子 &amp; LOG算子）及<strong>Canny算子</strong>。</li><li><strong>图像形态学操作</strong>： 指的是一系列处理图像形状特征的图像处理技术。这里需要着重掌握的有<strong>腐蚀和膨胀</strong>、<strong>开运算与闭运算、形态学梯度</strong>（用于保留边缘轮廓）、<strong>白色和黑色顶帽变换</strong>；此外，也可了解下细化、厚化、击中击不中变换、边界/孔洞/联通分量提取。</li><li><strong>图像变换</strong>： 指的是将图像阵列从源域转换到目标域。了解几种常见的变换方式，如<strong>傅里叶变换、离散余弦变换</strong>。此外，可以重点学习下用于特征提取的霍夫变换，实战下如何利用该技术进行直线、圆和弧线等局部特征的提取。最后，再重点梳理下傅里叶变换与小波变换之间的区别和联系。</li><li><strong>图像分割</strong>： 主要是基于灰度值的不连续和相似的性质将图像划分为前景区域和背景区域。对于不连续的灰度值，常用的方法是边缘检测。而对于相似的灰度，我们一般常用<strong>阈值处理</strong>（局部多阈值 &amp; 全局阈值 &amp; Otsu自适应阈值）、<strong>区域生长、分水岭算法</strong>等。</li><li><strong>图像质量评价</strong>： 主要是对图像的某些特性进行分析研究，评估出图像的失真程度。这里需要重点掌握几个评价指标：<strong>SSIM（结构相似度）、PSNR（峰值信噪比）及MSE（均方误差）</strong>。</li></ul><h2 id="机器学习与深度学习基础"><a href="#机器学习与深度学习基础" class="headerlink" title="机器学习与深度学习基础"></a>机器学习与深度学习基础</h2><h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><blockquote><p>机器学习是一门多领域交叉学科，涉及概率论、统计学、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。</p></blockquote><ul><li> 了解并区分什么是监督学习、无监督学习、半监督学习、弱监督学习、多示例学习、迁移学习、元学习、强化学习、对比学习、少样本学习、零样本学习；</li><li>了解参数与超参数、数据拟合（欠拟合、过拟合、Under fit）、偏差与方差、训练集/验证集/测试集、生成模型与判别模型、奥卡姆剃刀/丑小鸭定理/没有免费午餐、样本统计（TP/TN/FP/FN）、交叉验证、参数搜索的概念；理解损失函数、梯度下降、正则化（L1 &amp; L2）、数据降维（PCA &amp; LDA）、数据归一化（Min-Max 标准化 &amp; Z-score标准化）等原理及适用场景；</li><li>掌握机器学习的十大基础算法，即Linear Regression、Logistic Regression、LDA、LVQ、Naive Bayes、KNN、Random Forest、Decision Tree、SVM、Bagging&amp;Boosting&amp;AdaBoost及K-Means算法。梳理各种树模型（GBDT &amp; XGBoost &amp; RF）之间的原理和区别；</li><li>理解掌握常用的评价指标，如Accuracy、Recall（Sensitivity）、Precision、Dice（F1-score）、Jaccard、AUC曲线、P-R曲线、MIoU等。</li><li>学有余力的可以了解下期望最大化、隐马尔科夫模型及条件随机场等原理。</li></ul><h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><blockquote><p>深度学习严格意义上是属于机器学习的一个分支，旨在构建更深层的网络来进行表征学习。本文主要介绍与计算机视觉相关的一些概念及技术。<br>了解相关的一些<strong>高频名词</strong>和计算机视觉有哪些应用方向；</p></blockquote><ul><li><strong>卷积结构</strong>： Plain Conv, DW Conv, Ghost Conv, Deformer Conv, Octave Conv, Gropu Conv, 1×1 Conv, HetConv, Dilated Conv, SCCov, Pyramid Conv, Tined Conv, Dynamic Conv, Decoupled Dynamic Conv,  Involution, etc.</li><li><strong>激活函数</strong>： Sigmoid, Softmax, ReLU, Tanh, PReLU, ELU, GELU, SELU, LeakeReLU, Soft Plus, ACON, etc.</li><li><strong>损失函数</strong>： Binary/Weighted/Balanced Cross-Entropy, Mixed Focal/Focal Loss/GFocal Loss, Dice Loss, IoU/CIoU/GIoU/DIoU/CDIoU/EIoU Loss/Focal-EIOU Loss, Tversky Loss, Triplet loss, etc.</li><li><strong>池化相关</strong>：Max pooing, Average pooling, GAP, Stochastic pooling,  etc.</li><li><strong>优化方法</strong>： Adam、SGD、Adentum、Nesterov、AdaDelta、RMSprop, etc.</li><li><strong>正则化技术</strong>： Dropout, DropBlock, Label Smoothing, SelfNorm &amp; CrossNorm, etc.</li><li><strong>后处理技术</strong>： Watershed algorithm、CRF、TTA、Overlap Prediction、NMS, etc.</li><li><strong>归一化技术</strong>： BN, LN, GN, IN, BGN, SwitchableN, SBN, SSN, FRN, EBN, KalmanN, DualN, etc.</li><li><strong>学习率衰减</strong>： ReduceLROnPlatea, MultiStepLR, ExponentialLR, CosineAnnealingLR, StepLR, etc.</li><li><strong>注意力机制</strong>： SE, SK, Shuffle Attention, Non-local, CBAM, GC, OCR, CBM, CBAM, BA2M, FCANet, Coordinate Attention, etc.</li><li><strong>多尺度机制</strong>： ASPP, SPP, Big-Little, Inception, SFA, ASC, DCFAN, etc.</li><li><strong>特征可视化技术</strong>： CAM, Grad-CAM, Grad-CAM++, Smooth Grad-CAM++, score-CAM, ss-CAM, Ablation CAM, etc.</li><li>数据增强<ul><li>几何增强： Horizontal/Vertical flip, Rotation, Affine transformation, Translation, Cropping, Perspective transformation, Zoom, etc.</li><li>色彩增强： Contrast, Brightness, Saturation, Color space conversion, Color jitter, Channel shuffling, Filling, Superimposed noise, etc.</li><li>其它增强： Mixup, RandAugment, mosaic, dropout, cutout, cutmix, augmix, MoEx, RandErase, ObjectAug, InAugment, KeepAugment, Co-Mixup, ISDA, etc.、</li></ul></li><li><strong>距离度量公式</strong>： Manhattan Distance, Euclidean Distance, Chebyshev Distance, Minkowski Distance, Cosine Distance, Mahalanobis Distance, Hamming Distance, Edit Distance, Earth Mover’s distance，etc.</li><li><strong>Backbone</strong>： LeNet-5, AlexNet, VGGNet, GoogleNet, ResNet, DenseNet, VoVNet, MoblieNet, ShuffleNet, Xception, queezeNet, RexNeXt, Res2Net, SENet, SKNet, DCNet, CSPNet, FBNet, EfficientNet, RegNet, ResNeSt, ReXNet, HaloNets, etc.</li><li><strong>语义分割</strong>： FCN, UNet, ENet, ThunderNet, RefineNet, SegNet, PSPNet, DeepLab, DenseASPP, OCRNet, HRNet,BiSeNet, etc.</li><li><strong>目标检测</strong>：<ul><li><strong>Two-stage</strong>： R-CNN &amp; SPP &amp; FastR-CNN &amp; Faster R-CNN &amp; Cascade-RCNN &amp; Sparse R-CNN, etc.</li><li><strong>One-stage</strong>： YOLO v1-v5 &amp; PPYOLO &amp; SSD &amp; RetinaNet &amp; RefineDet &amp; YOLOR &amp; YOLOF &amp; YOLObite &amp; NanoDet &amp; OneNet, etc.</li><li><strong>Anchor-free</strong>： CornetNet &amp; Objects as Points &amp; CenterNet v1-v2 &amp; FCOS, etc.</li></ul></li><li><strong>实例分割</strong>： MaskRCNN, PolarMask, PolarMask++, PointRend, BlendMask, ISTR, SOLO v1-v2, Sparse RCNN, A2Net, etc.</li><li><strong>自监督学习</strong>： SimCLR, SimSiam, BYOL, SwAV, MoCo v1-v3, OBoW, DINO, etc.</li><li><strong>生成对抗网络</strong>： GAN, DCGAN, Conditional GAN, InfoGAN, BigGAN, WGAN, StyleGAN, CycleGAN, Pix2Pix2, StackGAN, LSGAN, CGGAN, PD-GAN, etc.</li><li><strong>重特征参数化</strong> ：ACNet v1-v2, DBBNet, RepVGG, ResRep, etc.</li><li><strong>Transformer相关</strong> ViT, DETR, METR, SETR, DeiT, TNT, CrossViT, Swin Transformer, LeViT, RVT, PVT, BoTNet, TrTr, MOTR, ISTR, TransGAN, Local-ViT, IPT, DeepViT, CoTr, CaiT, CeiT, PiT, ViViT, CvT, T2T-ViT, TransT, SiT, LV-ViT, MViT, PRTR, CoaT, Segmenter, etc.</li><li><strong>多层感知机相关</strong>： MLP, MLP-Mixer, ExternalAttention, RepMLP, ResMLP, gMLP, etc.<blockquote><p>上面只列举了一小部分方向，对于CV其它领域的总结大盘点和一些训练技巧、常见踩坑点、模型部署等知识点，以及上面所涉及到的每一个知识点，我们均会以图文讲解的形式从原理、算法到具体的应用进行一一讲解和总结。</p></blockquote></li></ul><h2 id="硬基础"><a href="#硬基础" class="headerlink" title="硬基础"></a>硬基础</h2><blockquote><p>硬基础，可以理解为求职申学的加分项，优秀的履历是一张去往金字塔顶端的入场卷。</p></blockquote><h3 id="学校-amp-学历-amp-年龄-amp-性别"><a href="#学校-amp-学历-amp-年龄-amp-性别" class="headerlink" title="学校 &amp; 学历 &amp; 年龄 &amp; 性别"></a>学校 &amp; 学历 &amp; 年龄 &amp; 性别</h3><ul><li><strong>学校</strong>： 实际上，大多数的在校生或多或少都具有名校情结。一个名牌学校的毕业生，除了学校品牌的价值，更多的体现在教学资源、硬件资源以及优质的校友资源等。当然，名校毕业的学生在享受以上资源的同时，也常常会倍感压力，这是由于社会对于此类群体的期许度过高。在我国，名校按大类来分，大致可分为985 | 211 | 双一流；如果想继续分，可分为C9 + 中下流985 + 211 + 其它；再细分还可以是清北+ 华五 + 国防七子 + 两电一邮 + 两外一法 + …。当然，这更多的只是历史弥留的痕迹，相信随着时代的发展，会有越来越多好学校崛起，比如计算机专业较强的双非院校中发展势头最猛的深圳大学、南方科技大学、杭电南邮等以及苏州大学和上海大学等强劲的211高校。对于大陆境外来说，常年排名靠前的有美国常春藤联盟+Stanford+CMU+MIT+UIUC，英国剑桥+牛津，瑞士苏联邦理工，新加波国立大学+南洋理工大学，香港大学+香港中文大学+香港科技大学等。虽然，在我们求职或升学的面试过程中，好的学校通常会更容易获得HR的青睐，但这并不意味着其它学校名气不够好的同学就没有任何机会，对于学校出身不好的人也不用妄自菲薄，更多的应该把时间和精力花在提升自己的软技能上，而对于学校出身好的同学来说也更应该珍惜这份机会，否则会适得其反。</li><li><strong>学历</strong>： 对于互联网这个行业而言，对学历的要求可谓越来越高。特别是针对互联网大厂来说，每年大部分招的应届生有大部分都是研究生学历起步。特别是对于大厂AI LAb部门来说，现在基本都是海内外名校博士起步。当然，对于做开发的同学来说，只要把计算机基础打好以及Leetcode等算法题刷得快准狠，基本不会有太大的问题。而对于想从事CV算法的同学来说，更多的还是建议去修一个研究生学位。而对于想继续进修的同学的来说，一定要在申请之前了解相关院校的要求，比如雅思托福成绩和就读学校门槛，并在截至日期到来之前将相关材料都准备好，一般来说，对于大多数人更多的还是建议国内读研国外读博。</li><li><strong>年龄</strong>： 年龄这块其实是个很敏感的话题。可以发现在我国随着年龄越大，限制越多。最典型的莫过于某菊厂带头的“<strong>35岁优化</strong>”以及某福报厂所提倡的“<strong>为社会输送优质人才</strong>”等。对于高校老师而言，其实也会面临着严峻的考核要求，而且很多国家青年基金项目基本都要求35岁以下申请。对于想考公务员的同学同样也有本科35硕士40的年龄限制。因此，对于想进一步做出抉择的同学来说也需要考虑到未来的一个发展趋势和自身的竞争力，未雨绸缪。</li><li><strong>性别</strong>： 俗话说男女有别，旧社会更有男尊女卑的说法。随着我国改革开放进入到新时代，人们对于这种观念已大大改善。尽管现如今职场上或多或少还存在着少部分的歧视女性，但对于大多数的公司而言，特别是对于互联网算法和开发部分而言，女生在团队里往往是最受照顾的，更多时候福利倾向原则反而是女士优先，所以这点大可放心。</li></ul><h3 id="业务理解-amp-逻辑沟通能力"><a href="#业务理解-amp-逻辑沟通能力" class="headerlink" title="业务理解 &amp; 逻辑沟通能力"></a>业务理解 &amp; 逻辑沟通能力</h3><ul><li><strong>业务理解能力</strong>： 也可以理解为解决问题的能力。这个在工业界其实是比较注重的，特别是社招。对于大厂的大部分算法开发岗位来说，面试过程也经常会遇到这种问题，即给定一个场景，问候选人有什么相应解决方案，这类问题大都是开放题，没有标准答案。然而，这对于候选人来说其实是一个更大的挑战。遇到这种情况，我们首先要理解问题，清楚问题的定义是什么，这其实就是在工作中我们需要明确我们的客户需求是什么？只有明确了任务本身，下一步才是对问题进行分析，根据自身掌握的知识体系结合实际的应用场景给定一个最优的解决方案，最好是要能够落实到每一步应该做什么，尽可能地思考开发过程或应用过程中会出现哪些问题，应该如何解决。最后，才是根据最终所敲定的任务路线，应用已有的技术逐步地攻关解决。</li><li><strong>逻辑沟通能力</strong>： 在我们的日常学习或者工作生活中，沟通是必不可少的。良好的沟通能力有助于团队之间更有效率的协作开发，强大的逻辑能力则更有助于个人解决问题。除了在找工作的过程中我们经常会遇到跟面试管交流或者跟HR谈薪外，在进行学术汇报和同行交流的时候也经常需要我们有良好的逻辑沟通能力。这不仅能够提高一个人的自信，也能为我们的职场生涯增添筹码。</li></ul><h3 id="实习-amp-工作经验"><a href="#实习-amp-工作经验" class="headerlink" title="实习 &amp; 工作经验"></a>实习 &amp; 工作经验</h3><ul><li><strong>实习经验</strong>： 对于许多的在校大学生而言，接触实际的工程项目开发，熟悉公司的项目开发流程，掌握常用的开发工具，可能一个最好的办法就是去大厂实习。现如今大家都知道秋招，特别是春招的时候，竞争大厂CV算法工程师岗位往往是千军万马过独木桥。有一个很重要的原因是因为僧多粥少，这是由于每年大部分正式岗位的指标都留给实习生转正了。所以在这里奉劝大家一句，能去大厂实习的一定要去，不能出去实习的也要创造机实习，比如远程实习。实在不行的只能留在学校自己上github等相关网站上找一些开源项目学习。</li><li><strong>工作经验</strong>： 正所谓学历只是一个敲门砖，它决定的是你能否进入面试。而工作经验，或者说项目经验，则是决定你在整个行业的天花板。一般来说，项目经验所丰富，职业生涯就能走的更远。同时，随着你工作年限的增长，业界有一个不成文的规则，即跳槽的时候一般薪水是会增长x%，有甚至直接翻n倍。除非你本来已经到达天花板，工资也足够高了。当然，如果能加上优质的学历和学校加持，你的升职加薪之旅也会加速。<h3 id="物质资源-amp-人脉资源化"><a href="#物质资源-amp-人脉资源化" class="headerlink" title="物质资源 &amp; 人脉资源化"></a>物质资源 &amp; 人脉资源化</h3></li><li><strong>物质资源</strong>： 这里可以暂且理解为硬件资源。众所周知，深度学习模型成功的三大要素便是数据、算法和算力。其中，算力是从根本上决定了我们是否能进行某个任务或课题的研发或研究。对于在校生来说，首要关键的还是实验室的硬件基础设施，服务器资源是否能满足课题的需求，因为这同时也会关乎到你实验的进展。而对于进入工业界的朋友来说，如果遇到买不起足量服务器的公司千万不要去应聘该公司的算法工程师岗位。说一个身边真实的例子，有个别同学的导师要求该名同学用自己的破笔记本跑3D任务相关的实验以及某某公司为该公司旗下的算法部分分配每人一张卡。可想而知，这种开发和研究周期得有多长。大家也可以观察下，现在头部大厂如谷歌的最新研究基本都是基于多张V100甚至直接上TPU集群上训练。</li><li><strong>人脉资源</strong>： 无论你今后是想从事工业界或者学术界，可以说人脉资源是你必不可少的东西。首先，简单地聊一下学术圈。学术圈这个圈子其实挺小的，包括大家平日里投的期刊，其实绝大多数都是不盲审的，这就意味着可操作性空间大。特别是对于某些期刊来说，很多时候就是一群自己人在圈子内“自嗨”，外人根本进不去（投稿基本是被拒的）。所以，这里更建议大家多去参加一些高级的学术会议，结识多点人脉，建立自己的小圈子，众人拾柴火焰，唯有抱团取暖才是真谛。同样地，对于跟着大牛导师的同学也可以多利用导师手里边的资源为自己争取更好的机会。其次，对于工业界的朋友来说，平常也可以多参加点创投圈，结交多点大佬，不仅以后跳槽挖坑的机会更多，对于有志于创业的伙伴来说未尝不是一种积累。</li></ul><h2 id="工具链"><a href="#工具链" class="headerlink" title="工具链"></a>工具链</h2><blockquote><p>工具链，主要是向大家介绍一下日常工作学习生活中可以帮助自身提升工作效率的一些在线网站、实用工具、资讯媒介以及干货资料分享。</p></blockquote><h3 id="在线网站"><a href="#在线网站" class="headerlink" title="在线网站"></a>在线网站</h3><h4 id="数据竞赛"><a href="#数据竞赛" class="headerlink" title="数据竞赛"></a>数据竞赛</h4><ul><li><a href="https://www.kaggle.com/">Kaggle</a>：全球最大的机器学习/深度学习竞赛平台</li><li><a href="https://js.dclab.run/v2/index.html">DataCastle数据竞赛</a>：全国专业的大数据培训和竞赛平台</li><li><a href="https://tianchi.aliyun.com/">天池</a>：由阿里巴巴举办，面向全球科研工作者的高端算法竞赛平台</li><li><a href="http://www.kdd.org/">KDD CUP</a>：国际知识发现和数据挖掘竞赛</li><li><a href="https://grand-challenge.org/">Grand Challenge</a>：比较全面地收集了医学图像相关的竞赛、数据集</li><li> <a href="https://www.biendata.xyz/">Biendata</a>：国内很大的数据竞赛网站和社区</li></ul><h4 id="算法刷题"><a href="#算法刷题" class="headerlink" title="算法刷题"></a>算法刷题</h4><ul><li><a href="https://leetcode-cn.com/">Leetcode</a>：题型多题目多且经典，在国内绝对是头部的刷题网站了</li><li><a href="https://www.nowcoder.com/">牛客网</a>：求职找工作神站，笔试\面试\实习\求职等各类资源集大成者</li></ul><h4 id="求职就业"><a href="#求职就业" class="headerlink" title="求职就业"></a>求职就业</h4><ul><li><a href="https://www.zhipin.com/">Boss直聘</a>：找工作/实习，打工是不可能打工的，这辈子都不可能打工的</li><li><a href="https://www.nowcoder.com/">牛客网</a>：求职找工作神站，笔试\面试\实习\求职等各类资源集大成者</li><li><a href="https://www.wondercv.com/">超级简历</a>：在线制作属于你的个人简历</li></ul><h4 id="学术相关"><a href="#学术相关" class="headerlink" title="学术相关"></a>学术相关</h4><ul><li><a href="https://scholar.google.com.hk/">Google学术</a>：论文搜索神器，活用高级搜索功能</li><li><a href="https://arxiv.org/">arXiv</a>：新鲜出炉的论文，当然质量也是参差不齐了</li><li><a href="http://ww25.sci-hub.tw/">SCI-Hub</a>：找论文必备</li><li><a href="https://dblp.uni-trier.de/">dblp</a>：是计算机领域内对研究的成果以作者为核心的一个计算机类英文文献的集成数据库系统，往往可以比谷歌学术更快的搜到文献的引用</li><li><a href="https://www.letpub.com.cn/">Letpub</a>：查看期刊的IF，中科院分区等信息</li><li><a href="https://www.connectedpapers.com/">Connectedpapers</a>：根据一篇论文找出其最相关的论文的图谱，帮你快速发掘出论文创新点背后的其他论文！</li><li><a href="https://paperswithcode.com/">Papers With Code</a>：帮助机器学习爱好者跟踪最新发布的论文及源代码，快速了解最前沿的技术进展</li><li><a href="https://www.overleaf.com/">Overleaf</a>：在线的论文latex编辑器，IEEE都推荐的编辑器~</li><li><a href="https://aideadlin.es/">aideadlin.es</a>：AI会议deadline</li></ul><h4 id="新闻资讯"><a href="#新闻资讯" class="headerlink" title="新闻资讯"></a>新闻资讯</h4><ul><li><a href="https://www.zhihu.com/">知乎</a>：蟹邀，人在美国，刚下飞机，CV水很深，利益相关，匿了。</li><li><a href="https://www.quora.com/">Quora</a>：国外版知乎，也有很多圈内大佬在这里谈笑风生</li><li><a href="https://medium.com/">Medium</a>：优质的外文博客网站</li><li><a href="http://csrankings.org/">CSRankings</a>: Computer Science Rankings：计算机各领域的高校/研究所排名</li></ul><h4 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h4><ul><li><a href="http://www.wahart.com.hk/rgb.htm">RGB配色表</a>：在线RGB配色表，可用于快速获取目标颜色的RGB值</li><li><a href="https://www.bilibili.com/">Bilibili</a>：这里面个个都是人才，说话又好听，我敲喜欢这里的</li><li><a href="https://github.com/">Github</a>：全球最大的同性交友网站，世界上资源最丰富的代码仓库</li><li><a href="https://www.graviti.cn/">Graviti</a>：专注于解决AI开发中的数据痛点，从海量公开数据集社区（Open Datasets）到专业数据管理SaaS（TensorBay）</li><li><a href="https://learngitbranching.js.org/">Learn Git Branching</a>：用玩游戏的形式学会Git，带领初学者快速的入门</li><li><a href="https://jsoneditoronline.org/">jsoneditoronline</a>：是一个简单、灵活、可视化在线的JSON编辑器，支持差异化对比，可查看、编辑和格式化JSON数据</li></ul><h3 id="实用工具"><a href="#实用工具" class="headerlink" title="实用工具"></a>实用工具</h3><h4 id="常用开发工具"><a href="#常用开发工具" class="headerlink" title="常用开发工具"></a>常用开发工具</h4><ul><li><strong>Pycharm</strong>： Python项目开发神器，集成调试、语法高亮、Project管理、代码跳转、智能提示、自动完成、单元测试、版本控制等强大功能；</li><li><strong>VSCode</strong>： 便携式代码编辑器，优点是短小精悍，除了可以作为一款轻量级的编辑器，也可作为中小型项目开发的首选工具，除此之外还可以当作Latex编译器；</li><li><strong>MobaXterm</strong>： 是一款可以在Windows系统下远程SSH连接到Linux服务器的神器；</li><li><strong>Jupyter Notebook</strong>： 是一个开源的Web应用程序，允许用户创建和共享包含代码、方程式、可视化和文本的文档。它的用途包括：数据清理和转换、数值模拟、统计建模、数据可视化、机器学习等等。</li></ul><h4 id="论文写作工具"><a href="#论文写作工具" class="headerlink" title="论文写作工具"></a>论文写作工具</h4><ul><li><strong>Mendeley</strong>： 科研文献管理软件，可以给文献加注释和分类，同时也可以把参考文献按照指定格式进行导出；</li><li><strong>EndNote</strong>： 主要是用于Word写期刊论文时可以很方便的管理参考文献的自动引用；</li><li><strong>Mathpix Snipping Tool</strong>： Latex公式离线截屏工具，只需通过软件进行截屏复制Latex代码即可编译运行；</li><li><strong>Typora</strong>： 轻量级的markdown编辑器，同时附带许多有用的插件可供使用；</li></ul><h4 id="日常办公工具"><a href="#日常办公工具" class="headerlink" title="日常办公工具"></a>日常办公工具</h4><ul><li><strong>Snipaste</strong>： 是一款免费，完全没有广告的截图工具，具有强大的桌面贴图功能；</li><li><strong>火柴</strong>： 桌面搜索引擎，可以快速帮你找到需要的文件，同时附带许多实用的小工具；</li><li><strong>V2ray，clashX，ssr</strong>：fq必备软件，领略世界文化；</li><li><strong>向日葵 &amp; Teamviewer</strong>： 远程连接工具；</li><li><strong>Adobe acrobat</strong>： 功能全面的pdf阅读器；</li><li><strong>IrfanView</strong>： 轻量级图像浏览器，可以实现图片编辑、压缩等功能</li><li><strong>石墨文档</strong>： 稳定、免费的在线文档，记笔记、团队协作都很方便；</li><li><strong>OneNote</strong>： Windows官方记事本软件，功能强大，界面清新，非常适合个人。不过由于服务器在国外，所以多终端同步问题目前来说体验不是很好；</li><li><strong>Picasa 3</strong>： 谷歌开发的照片查看器，可用于快速的浏览照片，无广告，然而很早前已停止开发，不过不影响我们的日常使用；</li><li><strong>坚果云/蓝奏云</strong>： 不限速的云盘，免费版一个月的流量用来不同设备之间同步文件足够了</li></ul><h4 id="谷歌浏览器插件"><a href="#谷歌浏览器插件" class="headerlink" title="谷歌浏览器插件"></a>谷歌浏览器插件</h4><ul><li><strong>沙拉查词</strong>： 在线划词实时翻译；</li><li><strong>Grammarly</strong>： 在线语法自动纠正插件；</li><li><strong>Tempermonkey</strong>： 俗称油猴，有丰富的js脚本，让你的浏览器更加强大；</li><li><strong>Octree</strong>： 可以让github网页端的文件以树形结构显示；</li><li><strong>Adblock</strong>： 广告拦截神器，拒绝牛皮癣，还你一个干爽的页面；</li></ul><h4 id="论文资讯"><a href="#论文资讯" class="headerlink" title="论文资讯"></a>论文资讯</h4><p>各大CV相关的顶会顶刊</p><ul><li>CCF A<ul><li>CVPR（CV最高顶会）, ICCV, AAAI, ICML, NIPS, ACMM</li></ul></li><li>CCF B<ul><li>ECCV, WACV, ICME</li></ul></li><li>CCF C<ul><li>BMVC, ACCV, ICPR</li></ul></li><li>JCR Ⅰ区<ul><li>TPAMI（CV顶级期刊）, TIP, IJCV</li></ul></li><li>JCR Ⅱ区<ul><li>Pattern Recognition, IEEE Access（保毕业神器）</li></ul></li><li>JCR Ⅲ区<ul><li>CVIU, IVC, PRL</li></ul></li><li>JCR Ⅳ区<ul><li>IET-CVI, IJRAI, Machine Vision and Applications</li></ul></li></ul><p><strong>AI+医疗交叉领域顶级会议和期刊</strong></p><ul><li>会议：MICCAI, IPMI，ISBI，EMBC</li><li>期刊：TMI, MIA, TBME</li></ul><p><strong>AI自媒体微信公众号平台</strong>：</p><ul><li><strong>机器之心</strong>：专业的人工智能媒体和产业服务平台；</li><li> <strong>新智元</strong>：重点关注人工智能、机器人等前沿领域发展；</li><li><strong>量子位</strong>：追踪人工智能新趋势，报道科技行业新突破；</li><li><strong>CVHub</strong>：专注于发展成为计算机视觉领域的全栈平台，涵盖与CV相关的技术交流分享、学术论文写作指导、求职升学经验分享、实用干货教程分享以及最新的CV资讯速递；</li><li><strong>AI科技大本营</strong>：CSDN旗下的官方公众号，提供人工智能领域热点报道；</li><li><strong>OpenCV团队</strong>：致力于OpenCV开发、维护和推广工作；</li><li><strong>AMiner</strong>：AI赋能科技情报挖掘；</li></ul><h3 id="干货资料"><a href="#干货资料" class="headerlink" title="干货资料"></a>干货资料</h3><h4 id="在线教程"><a href="#在线教程" class="headerlink" title="在线教程"></a>在线教程</h4><ul><li><a href="https://course.fast.ai/">Fast AI</a>：重代码而非数学，不少初学者凭借Fast.ai课程所学技能称霸Kaggle比赛！</li><li><strong>吴恩达</strong><a href="https://study.163.com/course/courseLearn.htm?courseId=1004570029">机器学习</a>、<a href="https://mooc.study.163.com/university/deeplearning_ai">深度学习</a><strong>实战课程</strong>：最受欢迎的入门级课程，吴恩达老师课程最大的特点是通俗易懂；</li><li><strong>李宏毅</strong><a href="https://www.bilibili.com/video/BV1JE411g7XF">机器学习</a>、<a href="https://www.bilibili.com/video/av94519857">深度学习实战</a><strong>课程</strong>：成为像宝可梦训练师那样的AI工程师，李宏毅老师课程最大的特点是诙谐幽默为主；</li><li><a href="https://www.bilibili.com/video/av77752864/">李飞飞CS231</a>计算机视觉公开课：是计算机视觉领域入门的必看经典课程之一；</li><li><a href="http://web.stanford.edu/class/cs224n/index.html">斯坦福CS224n</a>深度学习自然语言处理课程：CV的同学可以稍微了解一下；</li><li><a href="https://pytorch.org/">Pytorch官网</a>：这是学习Pytorch深度学习框架最好的课程资料，包括熟悉Pytorch的各类API的定义和功能以及一些快速入门的教程均可在官网上找到，质量也是杠杠的！</li><li>经典paper解析：<a href="https://www.bilibili.com/video/BV1tU4y147Ah">AI百篇经典论文</a></li><li>一本长达81页的<a href="https://www.pyimagesearch.com/start-here/">CV成长指南</a></li></ul><h3 id="代码库"><a href="#代码库" class="headerlink" title="代码库"></a>代码库</h3><ul><li>图像分类：<a href="https://github.com/rwightman/pytorch-image-models">pytorch-image-models </a>基本上涵盖所有主流网络</li><li>目标检测: <a href="https://github.com/open-mmlab/mmdetection">MMDetection</a>、<a href="https://github.com/facebookresearch/detectron2">Detectron2</a> 这两个都是优秀的代码库，值得学习借鉴查阅各个领域的最新进展，可以查阅这个网站，会记录一些sota的paper和code链接：<a href="https://paperswithcode.com/sota">paper-with-code</a></li></ul><h3 id="参考书籍"><a href="#参考书籍" class="headerlink" title="参考书籍"></a>参考书籍</h3><ul><li>《python从入门到实战》：掌握Python语言的入门级必备书籍；</li><li>《统计机器学习》第2版：李航博士的力作，涵盖机器学习必备入门知识点；</li><li>《西瓜书》：由周志华教授主写，适合本科生看的中文机器学习书籍，关于书中所涉及到的公式推导，建议搭配《南瓜书》进行辅助；</li><li>《动手学深度学习》：这本书是由李沐大神写的，先前之有MXNet版本，后面也逐渐加入了Pytorch和Tensorflow版本；</li><li>《百面机器学习》&amp;《百面深度学习》：由葫芦团队编写， 机器学习、计算机视觉算法工程师等相关岗位的面试宝典；</li><li>《数字图像处理》：作者是日本的学者冈萨雷斯，是传统数字图像处理入门的必看书籍，这部分内容建议根据上面第1部分总结的重点有针对性的去了解即可；</li><li>《OpenCV 轻松入门：面向 Python》：这本书主要是用于辅助你学习opencv的API接口和验证理论实战用的，如果不是刚需也可以去github找一些实战项目亦可；</li><li>《深度学习》：也称为花书，被评为深度学习领域的圣经，可以帮助我们快速构建知识体系。当然，不少读者反映书中内容大都晦涩难懂，建议学有余力的同学可以去看看；</li><li>《剑指offer》：总共有 80 道典型的编程面试题，系统整理基础知识、代码质量、解题思路、优化效率和综合能力这 5 个面试要点，是非常适合新手面试刷的第一本题库；</li><li> 《神经网络与深度学习》：邱锡鹏深度学习经典教材，免费pdf下载可关注微信公众号CVHub，后台发送关键字“0607”获取；</li><li>《计算机视觉：算法与应用第二版》：计算机视觉经典教材；</li><li>《C++ Primer》：C++入门必备教材。</li></ul><blockquote><p>CVHub转载<a href="https://mp.weixin.qq.com/s/DmoGBDstf2Q5clnaQR5hWw?scene=25#wechat_redirect">https://mp.weixin.qq.com/s/DmoGBDstf2Q5clnaQR5hWw?scene=25#wechat_redirect</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
          <category> 机器学习 </category>
          
          <category> 面试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 入门 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GoogLeNet</title>
      <link href="/2021/07/14/googlenet/"/>
      <url>/2021/07/14/googlenet/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉–GoogLeNet"><a href="#带你读论文系列之计算机视觉–GoogLeNet" class="headerlink" title="带你读论文系列之计算机视觉–GoogLeNet"></a>带你读论文系列之计算机视觉–GoogLeNet</h1><p><img src="https://img-blog.csdnimg.cn/20210714184956125.png" alt=" "></p><h2 id="0-闲谈"><a href="#0-闲谈" class="headerlink" title="0 闲谈"></a>0 闲谈</h2><p>玩起手机，看着电视，所有的计划都被抛之脑后，此时的快乐是深夜不舍睡下的愧疚。我总是想着明天怎么，而有时不知珍惜当下；总想着那些离开的朋友，而对现在不满；总想着如果这样，而不是我做了会如何。这两天反思了一下，我太依赖有人给我一个学习路线，往往自己探索学习发现的能力和勇气被打磨掉了。</p><p>小可爱，今天的内容有点多，坚持✊，你是最棒哒！</p><h2 id="1-背景及部分作者"><a href="#1-背景及部分作者" class="headerlink" title="1 背景及部分作者"></a>1 背景及部分作者</h2><p><strong>论文名称来源</strong></p><p><img src="https://img-blog.csdnimg.cn/20210714185106589.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt=" "></p><p>“<strong>We Need To Go Deepe</strong>“是电影《盗梦空间》中的一个表达，它经常出现在使用电影屏幕截图的图像宏和垂直多窗格中，其中角色多姆·科布（莱昂纳多·迪卡普里奥饰）与罗伯特·菲舍尔（西里安·墨菲饰）谈论在某人的脑海中植入一个想法。</p><p>GoogLeNet是2014年Christian Szegedy等人在2014年大规模视觉挑战赛(ILSVRC2014)上使用的一种全新卷积神经网络结构，于2015年在CVPR发表了论文《Going Deeper with Convolutions》。在这之前的AlexNet、VGG等结构都是通过增大网络的深度（层数）来获得更好的训练效果，但层数的增加会带来很多负作用，比如overfitting、梯度消失、梯度爆炸等。Inception的提出则从另一种角度来提升训练结果：能更高效的利用计算资源，在相同的计算量下能提取到更多的特征，从而提升训练结果。</p><p>Inception技术演进：</p><blockquote><p>v1（GoogleNet）–&gt;BN-Inception–&gt;V2–&gt;V3–&gt;V4–&gt;Inception-ResNet–&gt;Xception</p></blockquote><p>下面简单介绍其中两名作者：Christian Szegedy和贾扬清</p><p><img src="https://img-blog.csdnimg.cn/20210714185257213.png" alt=" "></p><p><strong>Christian Szegedy</strong>是GoogLeNet的一作，也是对抗样本由Christian Szegedy提出者。<strong>对抗样本</strong>是指在数据集中通过故意添加细微的干扰所形成的输入样本，导致模型以高置信度给出一个错误的输出。在正则化背景下，通过对抗训练减少原有独立同分布的测试集的错误率——在对抗扰动的训练集样本上训练网络。</p><p><img src="https://img-blog.csdnimg.cn/20210714185320478.png"></p><p><strong>贾扬清</strong>，本科和研究生阶段就读于清华大学自动化专业，后赴加州大学伯克利分校攻读计算机科学博士。他在博士期间创立并开源了如今业内耳熟能详的<strong>深度学习框架Caffe</strong>，被微软、雅虎、英伟达、Adobe等公司采用。</p><p>2019年，阿里巴巴达摩院通过知乎账号宣布，原Facebook（脸书）人工智能科学家贾扬清已正式加入阿里巴巴，担任技术副总裁岗位，领导大数据计算平台的研发工作。</p><p><strong>为什么要提出Inception？</strong></p><p>一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，但一味地增加，会带来诸多问题：</p><p>1）参数太多，如果训练数据集有限，很容易产生过拟合；</p><p>2）网络越大、参数越多，计算复杂度越大，难以应用；</p><p>3）网络越深，容易出现梯度弥散问题（梯度越往后穿越容易消失），难以优化模型。</p><p>我们希望在增加网络深度和宽度的同时减少参数，为了减少参数，自然就想到将全连接变成稀疏连接。但是在实现上，全连接变成稀疏连接后实际计算量并不会有质的提升，因为大部分硬件是针对密集矩阵计算优化的，稀疏矩阵虽然数据量少，但是计算所消耗的时间却很难减少。在这种需求和形势下，Google研究人员提出了Inception的方法。</p><h2 id="2-论文"><a href="#2-论文" class="headerlink" title="2 论文"></a>2 论文</h2><ol><li>提出了一个代号为Inception的深度卷积神经网络架构；</li><li>架构增加网络的深度和宽度，同时保持计算预算不变，主要标志是提高了网络内部计算资源的利用率；</li><li>为了优化质量，架构决策基于Hebbian原则和多尺度处理的直觉。</li><li>为ILSVRC14提交的文件中使用的网络，叫做GoogLeNet，这是一个22 层（如果我们也计算池化，则有27层）的深度网络，其质量是在分类和检测的背景下评估的。</li></ol><p>赫布理论（Hebbian theory）是一个神经科学理论，解释了在学习的过程中脑中的神经元所发生的变化。赫布理论描述了突触可塑性的基本原理，即突触前神经元向突触后神经元的持续重复的刺激，可以导致突触传递效能的增加。</p><p><strong>神经元突触“用进废退”fire together, with together.</strong></p><p>该架构的优势在ILSVRC 2014分类和检测挑战上得到了实验验证，在这方面它优于当前最先进的技术。（2014年）</p><p><strong>从LeNet-5奠定的CNN基础架构</strong>：（卷积+normalization+最大池化）<em>n+全连接层</em>m。</p><p>从LeNet-5开始，卷积神经网络(CNN)通常具有标准结构-堆叠卷积层（可选后跟对比归一化和最大池化）后跟一个或多个全连接层。对于Imagenet等较大的数据集，最近的趋势是增加层数和层大小，同时使用dropout 来解决过拟合问题。</p><p>近年（2014年）加深，加宽，加dropout 解决大数据集中的过拟合。</p><ol><li>尽管池化导致空间信息损失，但CNN在定位、物体检测和人体姿势估计多方面取得应用</li><li>从视觉皮层中借鉴，采用多尺寸滤波器解决</li></ol><p><strong>1×1卷积具有双重目的：</strong></p><ol><li>最关键的是，它们主要用作<strong>降维模块以消除计算瓶颈</strong>，否则会限制我们网络的大小。</li><li>这不仅可以<strong>增加深度</strong>，还可以<strong>增加我们网络的宽度</strong>，而不会显着降低性能。</li></ol><p><strong>Inception模块中1*1卷积作用：</strong></p><ul><li> <strong>降维</strong>；</li><li><strong>减少参数量和运算量</strong>；</li><li><strong>增加模型深度提高非线性表达能力</strong>。</li></ul><p>目标检测以R-CNN为代表的两阶段方法：</p><ol><li><p>找出候选区域（selectivesearch）</p></li><li><p>对每个候选区域运用CNN；</p></li><li><p>检测主要是RCNN</p></li><li><p>RCNN先给出候选，再用CNN定位和分类</p></li><li><p>有点利用了底层特征，也用了高级的CNN模型</p></li><li><p>本文也采用这个方式</p></li></ol><p>改进：multi-box和模型集成</p><p>提高模型性能的<strong>传统方法</strong>：</p><ol><li>增加深度（层数）；</li><li>增加宽度（卷积核个数）</li></ol><p>提高深度神经网络性能最直接的方法是增加它们的大小。这包括增加网络的深度（层数）及其宽度：每层的单元数。这是训练更高质量模型的一种简单而安全的方法，特别是考虑到大量标记训练数据的可用性。然而，这个简单的解决方案有两个主要缺点：1、参数多，过拟合；2、标注困难，类似细粒度图像需要专业知识。</p><p><strong>计算效率问题：</strong></p><p>两个相连卷积层，两层同步增加卷积核个数，计算量将平方增长。如果很多权重训练后接近0，那么这部分计算就被浪费了。我们不能不考虑计算效率，不计成本追求精度。</p><p><strong>解决这些问题的基本方法是最终从全连接到稀疏连接的架构，甚至在卷积内部</strong>。除了模拟生物系统外，还具有更牢固的理论基础的优势，如果数据集的概率分布可以用一个大的、非常稀疏的深度神经网络来表示，那么可以通过分析最后一层激活的相关统计数据并用高度相关的输出。</p><p>不利的一面是，当今（2014年）的计算基础设施在非均匀稀疏数据结构上进行数值计算时效率非常低。即使算术运算次数减少100倍，查找和缓存未命中的开销仍然占主导地位，切换到稀疏矩阵也不会得到回报。通过使用稳定改进、高度调整的数值库，允许极快的密集矩阵乘法，利用底层CPU或GPU 硬件的微小细节，差距进一步扩大。<strong>非均匀稀疏模型需要更复杂的工程和计算基础设施。</strong>ConvNets在特征维度上传统上使用随机和稀疏连接表，以打破对称性并改善学习，为更好地优化并行计算，又变回全连接。结构的一致性和大量过滤器以及更大的bitch size允许利用高效的密集计算。</p><p>能否利用现有硬件进行密集矩阵运算的条件下，改进模型结构，哪怕只在卷积层水平改进，从而能够利用额外的稀疏性呢？</p><p>提出：<strong>一种利用额外稀疏性的架构</strong>，通过利用密集矩阵上的计算来使用当前硬件。</p><p><strong>Inception的背后理论仍要继续研究</strong>。尽管所提出的架构已成为计算机视觉的成功，但其质量是否可以归因于导致其构建的指导原则仍然值得怀疑。确保需要更彻底的分析和验证：例如，如果基于下述原则的自动化工具会为视觉网络找到相似但更好的拓扑。最有说服力的证据是，自动化系统是否会创建网络拓扑，从而使用相同的算法在其他域中产生类似的收益，但具有非常不同的全局架构。至少，Inception架构的初步成功为在这个方向上令人兴奋的未来工作产生了坚定的动力。</p><p>如果自动机器学习工具AutoML能在各种场景下设计出类似的网络，那么证明Inception思路是正确的。</p><p><strong>Inception架构的主要思想是</strong>基于找出卷积视觉网络中的最优局部稀疏结构如何被现成的密集组件逼近和覆盖。请注意，假设平移不变性意味着我们的网络将由卷积构建块构建。我们所需要的只是找到最优的局部构造并在空间上重复它。</p><p><strong>局部信息，由1*1卷积提取越靠前面的层越提取局部信息。大范围空间信息由大卷积核提取越靠后的层提取大范围空间信息。</strong></p><p>人们可以预期，在更大的patch上卷积可以覆盖的集群数量会更少，并且在越来越大的区域上patch的数量会减少。为了避免patch对齐问题，Inception架构的当前版本<strong>仅限于过滤器尺寸1×1,3×3和5×5</strong>。这也意味着建议的架构是所有这些层的组合，它们的输出滤波器组连接成单个输出向量，形成下一阶段的输入。此外，由于池化操作对于卷积网络的成功至关重要，这表明在每个此类阶段添加替代并行池化路径也应该具有额外的有益效果。</p><p>由于这些”初始模块”是相互堆叠的，它们的输出相关统计数字必然会有所不同：随着更高的抽象特征被更高的层所捕获，它们的空间集中度预计会降低，这表明3×3和5×5的比例应该随着我们向更高的层移动而增加。</p><p>将池化层的输出与卷积层的输出合并将导致其输出数量增加。即使这种结构可能涵盖了最佳的稀疏结构，但它的效率非常低，导致计算量在几个阶段就会爆炸。</p><p><img src="https://img-blog.csdnimg.cn/20210714185917615.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/20210714185927259.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><strong>原生Inception模块的问题：通道数越来越多，计算量爆炸。</strong></p><p><img src="https://img-blog.csdnimg.cn/20210714190014225.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/20210714190020808.png"></p><p>在3<em>3卷积之前用1</em>1降维，1<em>1的卷积是用长宽为1通道数为输入的数量。1</em>1卷积核即可升维和降维，也可跨通道信息融合在生成的feature map后面加一个非线性的激活函数层，实际上是增加了模型的深度，提高了模型非线性的表达能力。</p><p>太过密集压缩的嵌入向量，不便于模型处理。</p><p>3<em>3，5</em>5卷积层之前应于1*1卷积降维。</p><p><strong>1*1卷积作用：</strong></p><ul><li>升维/降维 </li><li>减少参数量/计算量 </li><li>增加非线性，增加模型深度</li></ul><p>在计算要求会增加太多的地方应用降维和投影。然而，嵌入以密集、压缩的形式表示信息，压缩信息更难建模。我们希望在大多数地方保持我们的表示稀疏，并且仅在信号必须集体聚合时才压缩信号。也就是说，在3×3和5×5卷积之前，使用1×1卷积来计算缩减。</p><p>一般来说，Inception网络是一个由模块相互堆叠而成的网络，偶尔有跨度为2的最大集合层，以减半网格的分辨率。由于技术上的原因（训练时的内存效率），似乎只在较高的层使用Inception模块，而在较低的层保持传统的卷积方式是有益的。</p><p>这种结构的主要好处之一是，它允许在每个阶段大大增加单元的数量，而不至于在计算复杂性方面出现不可控的暴涨。降维的使用允许将最后一个阶段的大量输入滤波器屏蔽到下一层，首先降低它们的维度，然后用一个大的匹配尺寸对它们进行卷积。这种设计的另一个实际有用的方面是，它符合视觉信息应该在不同尺度上进行处理，然后进行聚合，以便下一个阶段可以同时抽象出不同尺度的特征。</p><p><strong>Inception结构优点</strong></p><ul><li>增加神经元，不增加计算量</li><li>可以提取不同尺度的特征</li></ul><p>视觉信息多尺度并行分开处理，再融合汇总。</p><p>计算资源的改进使用允许增加每个阶段的宽度和数量，而不会陷入计算上的困难。另一种方法是创建稍差的、但计算上更便宜的初始架构。我们发现，包括所有的旋钮和杠杆都可以实现计算资源的可控平衡，从而使网络比非Inception 架构的类似性能的网络快2-3倍，然而这需要进行仔细的设计。</p><p><strong>GoogLeNet名字致敬LeNet。</strong></p><p>用了更深更广的Inception网络，其质量稍差，但将其添加到集成中似乎对结果略有改善。<img src="https://img-blog.csdnimg.cn/20210714190200150.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt=" "></p><p>512=192+208+48+64</p><p>权重和计算量均匀分配给各层</p><p>所有卷积适用ReLU激活函数</p><p>上表中描述了最成功的特定实例（名为GoogLeNet）。在我们组合的7个模型中，有6个使用了完全相同的拓扑结构（用不同的采样方法训练）。</p><p><img src="https://img-blog.csdnimg.cn/20210714190232658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>Global Average Pooling –全局平均池化(GAP)</p><p>一个channel用一个平均值代表取代全连接层，减少参数量</p><p>用GAP代替全连接层：</p><ol><li>便于fine-tune迁移学习</li><li>提升0.6%的TOP-1的准确率</li></ol><p>该网络的设计考虑到了计算效率和实用性，可在个人设备上运行，甚至包括那些计算资源有限的设备，特别是在低内存占用方面。<strong>如果只计算有参数的层，网络有22层深度（如果我们也计算池化，则有27层）。</strong>用于构建网络的总层数（独立构建块）约为100，取决于所使用的机器学习基础设施系统。在分类器之前使用平均池，还用了一个额外的线性层。这使得我们可以很容易地对其他标签集的网络进行调整和微调。从全连接层到平均集合层的转变将top-1的准确性提高了大约0.6 %。即使在去除全连接层后，仍要使用dropout的使用。</p><p>对于网络有相对较大的深度，存在一个问题，即有效方式将梯度传播回所有层。一个有趣的见解是，相对较浅的网络在此任务上的强大性能表明，网络中间的层产生的特征应该具有很强的辨别力。通过添加连接到这些中间层的辅助分类器，我们希望在分类器的较低阶段鼓励区分，增加传播回来的梯度信号，并提供额外的正则化。这些分类器采用较小卷积网络的形式。在训练期间，它们的损失以折扣权重添加到网络的总损失中（辅助分类器的损失权重为0.3）。</p><blockquote><p>注：浅层的辅助分类器后面被证实没太大用处。作者在InceptionV2/V3 的论文里去掉了浅层辅助分类器。</p></blockquote><p>浅层特征对分类已经有足够的区分性</p><p>在4a和4d模块后面加辅助分类层</p><p>训练时的损失函数：</p><p>L=L最后+0.3<em>L辅1+0.3</em>L辅2</p><p>测试阶段：去掉辅助分类器</p><p><img src="https://img-blog.csdnimg.cn/2021071419033425.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/20210714190341441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/20210714190347761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>上图说明如下：</p><ul><li>GoogLeNet采用了模块化的结构（Inception结构），方便增添和修改；</li><li>网络最后采用了average pooling（平均池化）来代替全连接层，该想法来自NIN（Network in Network），事实证明这样可以将准确率提高0.6%。</li><li>虽然移除了全连接，但是网络中依然使用了Dropout ;</li><li>为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度（辅助分类器）</li></ul><p><strong>训练：</strong><br>训练过程复杂，所以没办法告诉我们怎么训练的。调<strong>参玄学！</strong></p><p>结论：训练过程复杂</p><ol><li>会基于训练好的模型，再调整超参，样本大小进行训练；</li><li>最佳的是8%-100%尺⼨，⻓宽⽐是[3/4,4/3]之间；</li><li>光度畸变可减轻过拟合；</li></ol><p>在比赛后被证明效果很好的方法包括对图像的各种大小块进行采样，大小均匀分布在图像区域的8%和100%之间，其纵横比在3/4和4/3之间随机选择。此外，我们发现Andrew Howard的光度失真在一定程度上有助于对抗过度拟合。此外，我们开始使用随机插值方法（双线性，面积，最近邻和三次，等概率）调整大小相对较晚并结合其他超参数变化，因此我们无法确定最终结果是否受到它们的积极影响。</p><p>说不清这些调参和图像增强技巧对最后结果有没有用。</p><h3 id="ILSVRC-2014分类任务"><a href="#ILSVRC-2014分类任务" class="headerlink" title="ILSVRC 2014分类任务"></a>ILSVRC 2014分类任务</h3><ol><li>没有使用额外的数据</li><li>采用七个模型集成，其中六个模型的网络结构、初始化方式、学习率调整策略完全相同，仅仅是采样方式不同</li><li>和VGGNet一样，要解决AlexNet尺度单一的问题：在预测时，将图片resize到四个尺度，短边分别为256、288、320、352，再取三个正方形（上中下或左中右），每个正方形再取四个角落和中心和原图片直接resize到224 x 224，还有这些图片的镜像（水平翻转），这时候的图片就是224 x 224 x 3了，可以直接输入到网络中（总图片数：4 x 3 x 6 x 2）</li><li>在多个裁剪和多个分类器的softmax概率结果求平均得到最终的预测结果（作者尝试了在多个裁剪上最大池化 + 多个分类器求平均发现效果并不如简单的求平均</li></ol><p><img src="https://img-blog.csdnimg.cn/20210714190545764.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="ILSVRC-2014检测任务"><a href="#ILSVRC-2014检测任务" class="headerlink" title="ILSVRC 2014检测任务"></a>ILSVRC 2014检测任务</h3><p>检测任务的目标是bounding box与Ground Truth重叠率要在50%以上，且需要对提取出的bounding box分类正确。作者采用的方法和R-CNN很类似，只是使用上面的Inception堆叠出的网络结构来对bounding box分类，同时，在区域提取那一步将Selective Search和multi-box方法结合起来，增大两倍超像素以此提高假阳率，因为时间紧缺没有使用bounding box regression。作者没有使用定位任务的数据进行预训练。</p><p><img src="https://img-blog.csdnimg.cn/20210714190601701.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/20210714190638525.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VGG</title>
      <link href="/2021/07/06/vgg/"/>
      <url>/2021/07/06/vgg/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉–VGG"><a href="#带你读论文系列之计算机视觉–VGG" class="headerlink" title="带你读论文系列之计算机视觉–VGG"></a>带你读论文系列之计算机视觉–VGG</h1><h1 id="1-卷积和池化"><a href="#1-卷积和池化" class="headerlink" title="1 卷积和池化"></a>1 卷积和池化</h1><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p><strong>卷积只改变图片的深度</strong>（深度与卷积核个数相同），不改变图片的深度和高度（padding方式为SAME，即补零）</p><p><strong>卷积核的作用：</strong><br>input image –&gt; convolution kernel –&gt; Feature map<br>图像处理时。给定输入图像，输入突袭那个中一个小区域中像素加权平均后成为输出图像中的</p><p>每一个对应像素。即最后feature map中的一个像素值<br>经过卷积核后图片大小计算公式：<br><strong>out_size=（in_size-F_size+2P）/S+1</strong><br>其中：F_size为卷积核大小；P为padding的大小；S为stride步长</p><h2 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h2><p><strong>池化只改变图片的深度核高度</strong>，不改变图片深度</p><p><strong>池化作用：</strong><br>图片中的相邻像素倾向具有相似的值，因此通常卷积层相邻的输出像素也具有相似的值，这意味着卷积层输出中包含的大部分信息都是冗余的。</p><p>池化：通过减小输入的大小来降低输出的数量</p><p><strong>常见的池化方式：max pooling 和mean pooling</strong></p><p>传统视觉中，为了保证提取特征具有平移不变性，通常在提取特征前会进行高斯模糊的操作，所以CNN前期的网络中通常会采用mean pooling，后max pooling具有更好的效果（通常我们认为极值才是我们关注的特征，且max pooling增加了非线性，提高的网络的表达能力），且速度更快，所以<strong>后期都采用max pooling，但是会导致CNN网络提取的特征不具有平移不变性，解决方案，增加blur操作</strong></p><blockquote><p>论文参考<a href="https://arxiv.org/abs/1904.11486">https://arxiv.org/abs/1904.11486</a></p></blockquote><h1 id="2-论文背景"><a href="#2-论文背景" class="headerlink" title="2  论文背景"></a>2  论文背景</h1><p>早在1989年，<strong>Yann LeCun</strong> (现纽约大学教授)和他的同事们就发表了卷积神经网络（Convolution NeuralNetworks， 简称CNN）的工作。在很长时间里，CNN虽然在小规模的问题上，如手写数字，取得过当时世界最好结果，但一直没有取得巨大成功。</p><p>2012年，<strong>Alex和Hinton</strong>参加ILSVRC2012比赛并提出AlexNet,首次在CNN中成功应用了ReLU、Dropout和LRN等Trick。同时AlexNet也使用了GPU进行运算加速。AlexNet将LeNet的思想发扬光大，把CNN的基本原理应用到了很深很宽的网络中。AlexNet为ILSVRC2012比赛的冠军，且远超第二名。</p><p>2014年，VGG网络被提出，其在AlexNet的基础上，运用了更小的卷积核，并且加深了网络，达到了更好的效果。</p><p>VGG于2014年由牛津大学科学工程系Visual Geometry Group组提出的。主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能。VGG有两种结构，分别是VGG16和VGG19，两者除了网络深度不一样，其本质并没有什么区别。相对于2012年的AlexNet， VGG的一个高进是采用连续的3x3小卷积核来代替AlexNet中较大的卷积核（AlexNet采用了11x11，7x7与5x5大小的卷积核）。两个3x3步长为1的卷积核的叠加，其感受野相当与一个5x5的卷积核。但是采用堆积的小卷积核是由于大卷积核的，因为层数的增加，增加了网络的非线性，从而能让网络来学习更复杂的模型，并且小卷积核的参数更少。</p><p>VGG网络：是一个Deep CNN，具备CNN所有的功能，常用来提取特征图像。该网络使用3*3卷积对深度增加的网络进行研究，将深度推到6-19层。</p><p>在Localization和Classification  tasks都取得了很大的成就，并且在其他数据集上有很好的通用性。</p><p><strong>文章主要讨论深度。为此，我们固定了架构的其他参数，并通过添加更多的卷积层来稳步增加网络的深度。</strong></p><p>ConvNet架构设计的深度进行研究，<strong>控制单一变量</strong>（深度），固定了其他参数，并通过添加更多的卷积层来稳步增加网络的深度，因为在所有层中使用了非常小的（3×3）卷积滤波器。</p><p>之前Ciresan等人曾使用过小尺寸卷积滤波器。但他们的网络比我们的网络深度要小得多，而且他们没有对大规模的ILSVRC数据集进行评估。Goodfellow等人。将深度ConvNets（11个权重层）应用于街道号码识别任务，并<strong>表明增加的深度导致更好的性能</strong>。除了3×3，它们还使用1×1 和5×5卷积。然而，他们的网络拓扑比VGG网络的更复杂，并且特征图的空间分辨率在第一层中更积极地降低以减少计算量。1×1卷积本质上是在相同维度空间上的线性投影（1*1增加非线性，输入和输出通道的数量相同）。</p><h1 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h1><h2 id="VGG网络亮点"><a href="#VGG网络亮点" class="headerlink" title="VGG网络亮点"></a>VGG网络亮点</h2><p><strong>与AlexNet相比亮点：</strong></p><ol><li>通过堆叠两个3<em>3的卷积核来的代替一个5</em>5的卷积核</li><li>通过堆叠三个3<em>3的卷积核来代替一个7</em>7的卷积核</li></ol><p><strong>好处</strong>：可以减少参数量</p><p>假设输入特征矩阵和输出特征矩阵的深度（channel）为C</p><p>使用一个7<em>7卷积核所需参数：<br>7</em>7<em>C</em>C=49<em>C</em>C</p><p>使用三个3<em>3卷积核所需参数：<br>3</em>3<em>C</em>C+3<em>3</em>C<em>C+3</em>3<em>C</em>C=27<em>C</em>C</p><p>3个3<em>3比1个7</em>7节省(49-27)/27=81%参数。</p><h2 id="感受野的计算"><a href="#感受野的计算" class="headerlink" title="感受野的计算"></a>感受野的计算</h2><p><strong>感受野（receptive fields）</strong>：输出feature map上的一个单元对应的输入层的区域大小。</p><p>计算公式：F(i) =  [F(i+1)-1]*stride+ksize</p><p>其中：F(i)为第i层的感受野；stride为 第i的步距；ksize为卷积核的大小。</p><p>例如：最后一层输出为一个单元：F = 1</p><p>conv3：F = (1-1)*1 + 3 =3</p><p>conv3：F = (3-1)*1 +3 =5</p><p>此时为两个3<em>3的卷积核代替一个5</em>5的卷积核。</p><p>conv3：F = (5-1)*1 +3 =7</p><p>此时为三个3<em>3的卷积核代替一个7</em>7的卷积核。</p><p><img src="https://img-blog.csdnimg.cn/20210706123502806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="网络结构"></p><h2 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h2><ol><li>固定大小224*224RGB输入；</li><li>唯一预处理是从每个像素中减去在训练集上计算的平均RGB值；</li><li>用具有非常小的感受野的过滤器：3×3（这是捕捉左/右、上/下、中心概念的最小尺寸）；</li><li>使用了1×1卷积滤波器，可以将其视为输入通道的线性变换（后跟非线性）；</li><li>卷积步长固定为1像素；conv的空间填充，即卷积后保留空间分辨率，即填充为1像素，3×3卷积；</li><li>空间池化是由五个最大池化层，最大池化在一个2×2像素的窗口上执行，步幅为2；</li><li>后面是三个全连接层（FC层4096-4096-1000）：前两个层每个有4096个通道，第三个执行1000路ILSVRC分类，因此包含1000 个通道（每个通道一个）班级）。最后一层是soft-max层。全连接层的配置在所有网络中都是相同的。</li></ol><p>所有隐藏层都配置了ReLU非线性函数。<strong>该网络没有用局部相应归一化（LRN）</strong>，因为这种规范化不<strong>会提高ILSVRC数据集的性能，但会导致内存消耗和计算时间增加。</strong></p><p><img src="https://img-blog.csdnimg.cn/20210706123615955.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>卷积层参数表示为“*conv(感受野大小)-(通道数)*”。为简洁，未显示ReLU激活函数.</p><p>例如：conv3-64表示64个大小3*3的卷积核</p><p>conv3：卷积核大小3*3；stride=1；padding=1</p><p>maxpool：池化尺寸2*2；stride=2</p><p>只在深度上有所不同：从网络A的11个权重层（8个conv.和3个FC层）到网络E的19个权重层（16个conv.和3个FC层）。</p><p>网络D：conv3+FC=2+2+3+3+3+3=16</p><p><strong>maxpool和softmax不计入层数</strong></p><p>max pool和全连接层之间有一个flatten函数，把多维像素展平成一维像素，便于全连接层进行处理。</p><p>前两个全连接层：ReLU和Dropout</p><p>该网络可以看层两部分：最后一次全连接层（不包括）之前看为提取特征网络结构，三个全连接和softmax可看为分类结构。</p><h2 id="网络的训练"><a href="#网络的训练" class="headerlink" title="网络的训练"></a>网络的训练</h2><p>ConvNet的训练过程一般遵循Krizhevsky等人（2012）的方法（除了从多尺度训练图像中对输入作物进行抽样）。训练是通过使用<strong>min-batch梯度下降法</strong>（基于反向传播）优化多叉逻辑回归目标来进行的，并带有动量。<strong>batch size为256，momentum为0.9</strong>。训练通过权重衰减（L2惩罚乘数设置为5·10e-4）和前两个全连接层的dropout正则化（<strong>dropout比率为0.5</strong>）进行正则化，Learning rate为0.01。然后在验证集准确性不再提高时，<strong>学习率下降了3次，37万次迭代（74次）后停止。</strong></p><p>我们推测，尽管与Alex Net网络相比，我们的网络有更多的参数和更大的深度，但<strong>网络需要更多的收敛时间</strong>，这是因为（a）更大的深度和更小的conv.filter尺寸带来的隐性正则化；（b）某些层的预先初始化。</p><p>网络权重的初始化很重要，因为不好的初始化会因为深层网络中梯度的不稳定性而使学习停滞。</p><p><strong>网络A</strong>足够浅，可以用<strong>随机初始化</strong>进行训练。然后，在训练更深的架构时，我们用网络A的层初始化前四个卷积层和最后三个全连接层（中间层随机初始化）。</p><h2 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h2><p>为了获得固定尺寸的<strong>224×224ConvNet 输入图像</strong>，它们被随机地从重新缩放的训练图像中裁剪出来（每个SGD迭代的图像裁剪一次）。为了进一步增加训练集，<strong>将图像随机水平翻转和随机RGB颜色移动。</strong></p><p>S为resize后最小边，并且裁剪大小224*224。</p><p>虽然裁剪尺寸固定为224×224，但原则上S可以取不低于224的任何值：对于S=224，裁剪将捕获整个图像的统计数据，完全覆盖训练图像的最小一面；对于S远大于224，裁剪将对应于图像的一小部分，包含一个小物体或一个物体部分。</p><p><strong>两种方法来设置训练尺度S。</strong></p><p><strong>第一种是固定S</strong>，对应于单尺度训练。两个固定尺寸：S=256和S=384；首先用S =256来训练网络。为了加快S=384 网络的训练，我们用S=256的权重进行初始化，并使用较小的初始学习率10的-3次方。</p><p><strong>第二种设置S</strong>多尺度训练的方法其中每个训练图像通过从一定<strong>范围[256，512]中随机采样</strong>S来单独重新缩放。因为图像中的对象可能具有不同的大小。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p><strong>1. 等比例缩放至Q，Q可以≠S<br>2. 稠密测试法：FC变卷积<br>3. 类分数图平均池化<br>4. 水平镜像</strong></p><p>在测试时，给定一个训练好的ConvNet和一个输入图像，按以下方式分类。首先，被重新<strong>缩放到一个预先定义的最小图像边</strong>，用Q表示（我们也把它称为测试尺度）。我们注意到<strong>Q不一定等于训练规模S</strong>。然后，网络以密集地应用于重新缩放的测试图像。即全连接层首先转换为卷积层（第一个FC层转换为7×7卷积层，最后两个FC层转换为1×1卷积层）。然后将所得的全卷积网络应用于整个（未裁剪的）图像。结果是一个类分数图，其通道数等于类数，空间分辨率可变，取决于输入图像的大小。最后，为了获得图像的类分数的固定大小向量，<strong>对类分数图进行平均池化</strong>。还通过图像的水平翻转来扩充测试集。对<strong>原始图像和翻转图像</strong>的soft-max类后验求平均以获得图像的最终分数。</p><p><img src="https://img-blog.csdnimg.cn/20210706124016329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>首先，我们注意到使用局部响应归一化（A-LRN网络）并没有改进没有任何归一化层的模型A 。因此，我们不在更深层次的架构（B-E）中使用归一化。</p><p>其次，我们观察到<strong>分类误差随着ConvNet深度的增加而降低</strong>：从A中的11层到E中的19层。</p><p>值得注意的是，尽管深度相同，配置C（包含三个1×1卷积层）的性能比配置D在整个网络中使用3×3conv layers差<strong>（D优于C）</strong>。上图也表明<strong>非线性确实有帮助（C比B 好）</strong>，但使用conv捕获空间上下文也很重要。<strong>当深度达到19层时，我们架构的错误率会饱和，但更深的模型可能对更大的数据集有益。证实了具有小过滤器的深网优于具有较大过滤器的浅网。</strong></p><p><img src="https://img-blog.csdnimg.cn/20210706124109863.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>测试时的尺度抖动导致更好的性能。最深的配置（D和E）表现最好，并且尺度抖动比固定最小边S的训练更好。在验证集上的最佳单网络性能是24.8%/7.5%top-1/top-5错误（在上表中以粗体突出显示）。在测试集上，配置E 实现了7.3%的top-5错误。</p><p><img src="https://img-blog.csdnimg.cn/20210706124128761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/20210706124132575.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>上表可以看出，使用<strong>multi-crop比dense评估略好</strong>，但它们的组合优于单一方式（multi-crop与dense互为补充）。multi-crop：150张（5<em>5</em>2*3=150）。</p><p><img src="https://img-blog.csdnimg.cn/20210706124159826.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>表明深的ConvNets显着优于前一代模型。</p><h2 id="发展分析"><a href="#发展分析" class="headerlink" title="发展分析"></a>发展分析</h2><p><strong>瓶颈</strong></p><p>VGG耗费更多计算资源，并且使用了更多的参数，导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。并且单纯的增加神经网络的深度，会给训练带来困难，会出现梯度消失、不收敛等问题。</p><p><strong>未来发展方向</strong></p><p>VGG的提出让研究员们看到网络的深度对结果的影响，并启发了他们去研究更深的网络。并且VGG网络的中间层能有效提取出输入图的feature，所以训练好的VGG模型通常会被运用到损失函数中间去，来弥补L2损失函数所造成的过于光滑的缺点。</p><p><img src="https://img-blog.csdnimg.cn/20210706124315337.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信息系统项目管理师备考经验</title>
      <link href="/2021/06/29/xin-xi-xi-tong-xiang-mu-guan-li-shi-bei-kao-jing-yan/"/>
      <url>/2021/06/29/xin-xi-xi-tong-xiang-mu-guan-li-shi-bei-kao-jing-yan/</url>
      
        <content type="html"><![CDATA[<h1 id="信息系统项目管理师备考经验"><a href="#信息系统项目管理师备考经验" class="headerlink" title="信息系统项目管理师备考经验"></a>信息系统项目管理师备考经验</h1><h2 id="絮叨："><a href="#絮叨：" class="headerlink" title="絮叨："></a>絮叨：</h2><p>之前闲来无事，想着大学期间考取了系统集成项目管理工程师（中级）。要不，在考个信息系统项目管理师（高级）。</p><h3 id="高级和中级备考有点区别："><a href="#高级和中级备考有点区别：" class="headerlink" title="高级和中级备考有点区别："></a>高级和中级备考有点区别：</h3><ol><li>中级需要考两科（选择和案例分析），高级考三科（选择、案例分析和论文）；</li><li>高级考试的内容比中级细很多；</li></ol><p>这两点是我最深的感受。最初，我就感觉应该和中级的考试内容差不多，备考时间就和之前安排的一样，结果考前几天发现来不及，导致我的论文只准备了一篇，还没有压中，最后硬生生写了2300多字的论文。血的教训啊，大家一定要早早准备！</p><p>废话不多说，直接上干货。</p><h3 id="【软考证书的作用】"><a href="#【软考证书的作用】" class="headerlink" title="【软考证书的作用】"></a>【软考证书的作用】</h3><ul><li>以考代评，评定职称（拿下软考高级证书即具有高级职称）</li><li>能力提升，助力职场发展+转型升级+升职加薪</li><li>积分落户加分</li><li>领取政府补贴</li><li>企业招投标加分</li><li>抵扣个税，提高养老金</li></ul><p><strong>ps: 各地实际政策不同，以当地为准。今年上半年软考已经考试完毕了，参加下一期备考的同学可以开始准备了！由于疫情原因，广东的部分地区推辞了考试时间，没考的小伙伴也要好好准备。</strong></p><p>下面就以我考的信息系统项目管理师为例。</p><p>先说一下考试形式和时间安排：<br>信息系统管理师考试有3场，分上午考试、下午考试I和下午考试II，3场考试在同一天的考试中都过关才能算这个级别的考试过关。</p><p>上午考试的内容是信息系统管理综合基础，考试时间为150分钟（9:00～11:30），笔试，选择题，而且全部是单项选择题，其中含5分的英文题。上午考试总共75道题，按60%计，45分算过关。</p><p>下午考试的内容包含两部分。下午考试I是“信息系统项目管理案例分析”，考试时间为90分钟（13:30～15：00），笔试，问答题。一般为3道大题，每道大题又分3～5个小问。大多数情况，每道题25分，总计75分，按60%45分算过关。下午考试II是论文考试（15:20～17:20），论文题目二选一，论文总分75分，45分算过关。</p><p>上午的选择题知识点多，专业术语多，考试范围似乎很广。最初，我准备看教材，看了几章，发现效率极其低下。我就改变策略，直接做历年真题，把教材当作补充和字典，最后在通过历年真题总结知识点。这样，考试前看只需看自己写的知识点。近三年的卷子尤为重要，大概率有相同的考题。<br>历年真题和解析均可以在以下网址下载（可自行打印，也可在线考试）</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">https://www.cnitpm.com/zhenti/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>【重点】最好的模拟试题是历年真题，您不妨在业余时间做一做历年真题。</strong></p><p>下午考试I的范围相对比较窄，局限在项目管理的范畴之内。<br>案例分析题：<br>1、基础知识题；<br>2、找出原因题；（尽量多写一些要点，写多不扣分）<br>3、解决方案题；<br>4、经验教训题；<br>5、计算题；</p><p>我最喜欢的就是计算题了，答案唯一。</p><p>计算题基本集中在<strong>网络图计算，挣值分析计算、投资分析计算</strong>这3个主要的领域。</p><p>下午考试II论文，对于我来说比较难，一是因为自己很少写；二是因为平时总介绍少；三是因为项目经验还有所欠缺。好在论文的范围并不宽，基本集中在项目管理领域，而且要求也不并不高，题目也多是比较宽泛的题目。</p><p>以下是总结的部分过程，仅供参考。</p><p><strong>项目整体管理</strong></p><blockquote><p>1、项目启动过程；<br>2、项目规划过程；<br>3、项目执行和监管过程；<br>4、项目收尾过程</p></blockquote><p><strong>范围管理</strong><br>1、编制范围管理计划，开发详细的项目范围说明书；<br>2、根据项目范围说明书进一步创建工作分解结构；<br>3、开展范围确认及范围控制工作；</p><p><strong>时间/进度管理</strong></p><blockquote><p>1、注意范围和进度的关系；<br>2、合理估算项目工作量，制定项目进度计划；<br>3、落实各项活动的责任人和组织，建立沟通汇报机制；<br>4、采用挣值管理技术进行项目进度和成本的绩效测量，及时调整与控制项目的进度；</p></blockquote><p><strong>成本管理</strong></p><blockquote><p>1、成本规划阶段<br>2、成本估算和预算阶段<br>3、成本控制阶段</p></blockquote><p><strong>人力资源管理</strong></p><blockquote><p>1、识别项目角色、职责，制定人力资源计划并组建项目团队；<br>2、建立沟通汇报机制，关注团队成员需求，打造高效团队；<br>3、采用项目绩效评估跟踪个人和团队绩效；</p></blockquote><p><strong>沟通管理</strong></p><blockquote><p>1、充分了解所有项目干系人，分析各自的沟通需求，编制有效的额沟通管理计划；<br>2、遵循沟通的原则，建立沟通汇报机制，进行高效的信息分发；<br>3、收集并发有关项目绩效信息，建立绩效报告制度；<br>4、不断跟踪满足项目干系人对项目的需求，进行项目干系人管理；</p></blockquote><p><strong>质量管理</strong></p><blockquote><p>1、质量规划；<br>2、利用质量审计和过程分许来保证质量。质量保证阶段；<br>3、通过评审、测试、趋势分析来控制质量。质量控制阶段；</p></blockquote><p><strong>风险管理</strong></p><blockquote><p>1、根据项目特点，编制风险管理计划；<br>2、合同风险分析专家，进行项目风险识别；<br>3、定性、定量风险缝隙；<br>4、根据风险分析，制定风险应对计划；<br>5、持续进行项目的风险监控，不断识别新的风险闭关记录过程；</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 经验 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PV</title>
      <link href="/2021/06/29/pv/"/>
      <url>/2021/06/29/pv/</url>
      
        <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>(由Dijkstra首先提出并解决)5个哲学家围绕一张圆桌而坐，桌子上放着5支筷子， 每两个哲学家之间放一支；哲学家的动作包括思考和进餐，进餐时需要同时拿起他左 边和右边的两支筷子，思考时则同时将两支筷子放回原处。如何保证哲学家们的动作 有序进行？如：不出现相邻者同时要求进餐；不出现有人永远拿不到筷子。</p><ol><li>关系分析。系统中有5个哲学家进程，5位哲学家与左右邻居对其中间筷子的访问是互斥关系。</li><li> 整理思路。这个问题中只有互斥关系，但与之前 遇到的问题不同的事，每个哲学家进程需要同时 持有两个临界资源才能开始吃饭。如何避免临界 资源分配不当造成的死锁现象，是哲学家问题的精髓。</li></ol><p>解决⽅法有两个，⼀个是让他们同时拿两个筷⼦:⼆是对每个哲学家的动作制定规则，避免饥饿或者死锁 。</p><p><strong>⽅法⼀： ⾄多只允许四位哲学家同时去拿左筷⼦，最终能保证⾄少有⼀位哲学家能进餐，并在⽤完后释放两只筷⼦供他⼈使⽤。</strong></p><p>设置⼀个初值为 4 的信号量 r，只允许 4 个哲学家同时去拿左筷⼦，这样就能保证⾄少有⼀个哲学家可以就餐，不会出现饿死和死锁的现象。</p><p><strong>原理</strong>：⾄多只允许四个哲学家同时进餐，以保证⾄少有⼀个哲学家能够进餐，最终总会释放出他所使⽤过的两⽀筷⼦，从⽽可使更多的哲学家进餐。</p><p>代码如下：</p><pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript">semaphore chopstick<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">;</span>semaphore r <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span><span class="token function">Pi</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>     <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token constant">P</span><span class="token punctuation">(</span>r<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//请求进餐</span>        <span class="token constant">P</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//请求左⼿边的筷⼦</span>        <span class="token constant">P</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//请求右⼿边的筷⼦</span>        eat<span class="token punctuation">;</span>        <span class="token constant">V</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//放回左边筷⼦</span>        <span class="token constant">V</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//放回右边筷⼦</span>        <span class="token constant">V</span><span class="token punctuation">(</span>r<span class="token punctuation">)</span><span class="token punctuation">;</span>        think<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>⽅法⼆： 仅当哲学家的左右⼿筷⼦都拿起时才允许进餐。 原理：多个临界资源，要么全部分配，要么⼀个都不分配，因此不会出现死锁的情形。</strong></p><p>代码片段：</p><pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript">semaphore chopstick<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">;</span>semaphore mutex <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">//互斥地取筷子</span><span class="token function">Pi</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>              <span class="token comment">//i号哲学家的进程 </span>    <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token constant">P</span><span class="token punctuation">(</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token constant">P</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//拿左 </span>    <span class="token constant">P</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">%</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//拿右 </span>    <span class="token constant">V</span><span class="token punctuation">(</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span>     吃饭…     <span class="token constant">V</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//放左 </span>    <span class="token constant">V</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">%</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//放右 </span>    思考…    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>⽅法三： 规定奇数号哲学家先拿左筷⼦再拿右筷⼦，⽽偶数号哲学家相反。</strong></p><p><strong>原理</strong>：按照下图，将是 2,3 号哲学家竞争 3 号筷⼦，4,5 号哲学家竞争 5 号筷⼦。1 号哲学家不需要竞争。最后总会有⼀个哲学家能获得两⽀筷⼦⽽进餐。</p><p><img src="https://img-blog.csdnimg.cn/20200101172654699.jpg#pic_center" alt="在这里插入图片描述"></p><p>代码如下：</p><pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript">semaphore chopstick<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token function">Pi</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">//偶数号哲学家</span>    <span class="token constant">P</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//请求右⼿边的筷⼦ </span>    <span class="token constant">P</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//请求左⼿边的筷⼦</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span> <span class="token comment">//奇数号哲学家</span>    <span class="token constant">P</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//请求左⼿边的筷⼦</span>    <span class="token constant">P</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//请求右⼿边的筷⼦</span>    <span class="token punctuation">}</span>    eat<span class="token punctuation">;</span>    <span class="token constant">V</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//放回右边筷⼦</span>    <span class="token constant">V</span><span class="token punctuation">(</span>chopstick<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//放回左边筷⼦</span>    think<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>总之，哲学家进餐问题的关键在于解决进程死锁。 这些进程之间只存在互斥关系，但是与之前接触到的互斥关系不同的是，每个进程都需要同时持有 两个临界资源，因此就有“死锁”问题的隐患。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PV操作 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA WEB环境搭建教程</title>
      <link href="/2021/06/29/javaweb/"/>
      <url>/2021/06/29/javaweb/</url>
      
        <content type="html"><![CDATA[<h1 id="JAVA-WEB环境搭建教程"><a href="#JAVA-WEB环境搭建教程" class="headerlink" title="JAVA WEB环境搭建教程"></a>JAVA WEB环境搭建教程</h1><p>需要的软件安装包下载地址：链接：<a href="https://pan.baidu.com/s/1po2YlEXLHYMTYU_-mK21aw">https://pan.baidu.com/s/1po2YlEXLHYMTYU_-mK21aw</a>         提取码：t4ep </p><p><strong>一、安装JDK（若已经安装配置好环境变量的的可以忽略此步）</strong></p><p>（1）    双击运行jdk安装文件<br><img src="https://img-blog.csdnimg.cn/2018111120011559.png" alt="在这里插入图片描述"><br>（2）直接下一步，等待安装完成后关闭</p><p><img src="https://img-blog.csdnimg.cn/20181111200331260.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（3）配置环境变量<br>       （a）此电脑–&gt;右击–&gt;属性–&gt;高级系统设置<br>       <img src="https://img-blog.csdnimg.cn/20181111200457999.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>  （b）设置JAVA_HOME<br>        找到系统变量，点击新建，设置变量名为JAVA_HOME（JDK的安装路径），这里路径为你的jdk安装的绝对路径。<br>        <img src="https://img-blog.csdnimg.cn/20181111200536740.png" alt="在这里插入图片描述"><br>（c）设置CLASSPATH<br>继续在系统变量中新建CLASSPATH变量(这个值都是一样的，直接复制过去就可以)，值为：.;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar;<br><img src="https://img-blog.csdnimg.cn/20181111200739495.png" alt="在这里插入图片描述"></p><p>d)    设置Path变量<br>在系统变量中找到Path变量：<br>过程为：选中Path变量-》编辑，显示以下内容<br><img src="https://img-blog.csdnimg.cn/20181111200800534.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">选择浏览,找到你安装的jdk的bin文件夹，并确定<br><img src="https://img-blog.csdnimg.cn/20181111200823622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>然后path中就会出现<br><img src="https://img-blog.csdnimg.cn/20181111200841444.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>最后确定，确定<br>4)    右击 <img src="https://img-blog.csdnimg.cn/20181111200901105.png" alt="在这里插入图片描述">打开命令提示符管理员<br><img src="https://img-blog.csdnimg.cn/20181111200924384.png" alt="在这里插入图片描述"><br>如果没有需要右击下面的任务栏<br><img src="https://img-blog.csdnimg.cn/20181111201014828.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20181111201019786.png" alt="在这里插入图片描述"><br>关闭此选项<br><img src="https://img-blog.csdnimg.cn/20181111201042557.png" alt="在这里插入图片描述"><br>（5）输入java -version回车，查看使得否安装成功<br><img src="https://img-blog.csdnimg.cn/20181111201120951.png" alt="在这里插入图片描述"><br><strong>二、安装eclipse Java EE（如果已经安装了eclipse可以在网上搜索eclipse java ee插件安装教程，这里我提供photon的版本的插件安装教程链接：<a href="https://blog.csdn.net/qq_42006661/article/details/82250554%EF%BC%8C%E5%85%B6%E4%BB%96%E7%89%88%E6%9C%AC%E7%9A%84%E5%A4%A7%E8%87%B4%E5%92%8C%E8%BF%99%E4%B8%AA%E6%AD%A5%E9%AA%A4%E5%B7%AE%E4%B8%8D%E5%A4%9A%EF%BC%8C%E5%8F%AA%E4%B8%8D%E8%BF%87%E8%A6%81%E6%B3%A8%E6%84%8F%E7%89%88%E6%9C%AC%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%89">https://blog.csdn.net/qq_42006661/article/details/82250554，其他版本的大致和这个步骤差不多，只不过要注意版本的问题）</a></strong><br>（1）双击运行eclipse的安装包，选择java ee安装<br><img src="https://img-blog.csdnimg.cn/20181111201234410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（2）选择好安装位置，然后点击安装<br><img src="https://img-blog.csdnimg.cn/20181111201256147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>选择同意<br><img src="https://img-blog.csdnimg.cn/20181111201327965.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>安装过程中出现其他弹出框选择同意即可，等待安装完成，最后选择启动<br><img src="https://img-blog.csdnimg.cn/20181111201434147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>三、安装Tomcat</strong><br>（1）双击tomcat安装包，点击next<br><img src="https://img-blog.csdnimg.cn/20181111201522180.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt=" "><br>（2）同意使用协议，开始安装Tomcat<br><img src="https://img-blog.csdnimg.cn/20181111201638545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（3）一直next，直到这个页面选择你的jdk安装目录<br><img src="https://img-blog.csdnimg.cn/20181111201712455.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（4）选择安装路径<br><img src="https://img-blog.csdnimg.cn/20181111201740945.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>最后点击安装，等待安装完成即可<br>（5）此图标表明tomcat服务<img src="https://img-blog.csdnimg.cn/20181111201853865.png" alt="在这里插入图片描述">正在运行 ，右击该图标可以选择停止Tomcat服务<br>（6）在Tomcat服务运行的情况下，打开浏览器在地址栏输入localhost:8080,出现以下界面代表安装配置成功<br><img src="https://img-blog.csdnimg.cn/20181111201922250.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>四、安装MySQL</strong><br>（1）在电脑任意目录下新建一个MySQL文件夹我这里建在了c盘<br><img src="https://img-blog.csdnimg.cn/20181111202006388.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（2）    将mysql压缩包解压到我们新建的MySQL文件夹下<br><img src="https://img-blog.csdnimg.cn/20181111202031906.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（3）从解压的文档结构中，我们可以看到里面没有my.ini配置文件，这里需要自己创建my.ini配置文件。填写以下内容：注意以下箭头标识的地方一定要改成自己的安装目录</p><p><img src="https://img-blog.csdnimg.cn/20181111202054713.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（4）配置环境变量：<br>同样在系统环境变量中配置path环境变量，参照jdk的环境变量配置选择的是mysql的bin目录<br><img src="https://img-blog.csdnimg.cn/20181111202135499.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（5）在CMD下执行mysqld –initialize-insecure<br><img src="https://img-blog.csdnimg.cn/2018111120215628.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>自动创建了data文件<br><img src="https://img-blog.csdnimg.cn/20181111202210518.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（6）执行mysqld -install命令<br><img src="https://img-blog.csdnimg.cn/2018111120223163.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（7）执行mysql服务启动net start mysql命令<br><img src="https://img-blog.csdnimg.cn/20181111202253824.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>并在任务管理器——&gt;服务界面可以看到mysql服务<br><img src="https://img-blog.csdnimg.cn/20181111202316956.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>如果遇到MySQL服务启动不了，或则，前面没有出现安装成功的提示需要在cmd下输入mysqld -remove MySQL命令再重复以上步骤。或者以管理员身份运行命令提示符。<br>（8）新安装的mySQL的root账户是没有密码的，我们需要给MySQL的root账户设置密码。先输入mysql -u root -p登录root账户，不用输入密码直接回车即可<br><img src="https://img-blog.csdnimg.cn/20181111202459522.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>再输入ALTER USER ‘root‘@’localhost’ IDENTIFIED WITH mysql_native_password BY’新密码’;<br><img src="https://img-blog.csdnimg.cn/20181111202520204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>以下两个脚本开启和关闭MySQL服务，右击以管理员身份运行就可以关闭开启MySQL服务<br><img src="https://img-blog.csdnimg.cn/20181111202742125.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>五、把Tomcat集成到eclipse中</strong><br>（1）启动eclipse，选择file——&gt;new——&gt;project<br><img src="https://img-blog.csdnimg.cn/20181111203034527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>选择web——&gt;Dynamic web project<br><img src="https://img-blog.csdnimg.cn/20181111203104823.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>选择Tomcat<br><img src="https://img-blog.csdnimg.cn/20181111203123587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>选择Tomcat9.0<br><img src="https://img-blog.csdnimg.cn/20181111203139105.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>然后next，然后选择Tomcat安装位置<br><img src="https://img-blog.csdnimg.cn/20181111203156368.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20181111203206842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20181111203216394.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在project_name填上项目名称，然后选择finish<br>（2）新建server<br><img src="https://img-blog.csdnimg.cn/20181111203238477.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20181111203245821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>Finish即可</p>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA WEB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AlexNet</title>
      <link href="/2021/06/28/alexnet/"/>
      <url>/2021/06/28/alexnet/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉–AlexNet"><a href="#带你读论文系列之计算机视觉–AlexNet" class="headerlink" title="带你读论文系列之计算机视觉–AlexNet"></a>带你读论文系列之计算机视觉–AlexNet</h1><p><strong>少一些功利主义，多一些不为什么的坚持，你将变得异常美丽</strong>！加油，小可爱们！<br><img src="https://img-blog.csdnimg.cn/20210622225925769.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h2 id="背景及作者"><a href="#背景及作者" class="headerlink" title="背景及作者"></a>背景及作者</h2><p><strong>AlexNet</strong>被认为是计算机视觉领域最有影响力的论文之一，它刺激了更多使用卷积神经网络和GPU来加速深度学习的论文的出现。截至2020年，AlexNet论文已被引用超过54,000次。</p><p>AlexNet参加了2012年9月30日举行的ImageNet大规模视觉识别挑战赛，达到最低的15.3%的Top-5错误率，比第二名低10.8个百分点。</p><p><strong>TOP5错误率</strong>:即对一个图片，如果概率前五中包含正确答案，即认为正确。</p><p><strong>Hinton</strong>是对比散度算法的发明人之一，也是反向传播算法和深度学习的积极推动者，被誉为“深度学习之父”。Hinton因在深度学习方面的贡献与Yoshua Bengio和Yann LeCun一同被授予了2018年的图灵奖。</p><p><img src="https://img-blog.csdnimg.cn/20210622230043357.png"></p><p><strong>深度学习三驾马车：</strong></p><ul><li>大规模数据；</li><li>硬件算法；</li><li>模型算法及调参；</li></ul><p><strong>论文在如下背景下展开研究：</strong></p><ul><li>当前图像分类任务主要是通过传统机器学习的方法进行的，模型容量小，且不易于实际使用，容易过拟合；</li><li>实际目标多样性丰富，标记好的数据集的样本数越来越大，需要更高容量的模型进行学习。而卷积神经网络可以通过调节深度和宽度来控制模型的容量，且充分利用了自然图像的局部空间相关性的特性；</li><li>GPUs等硬件以及高度优化的2-D卷积运算的实现发展成熟，以足够强大，可用于训练较大的CNNs，结合如今的大数据集，不用过分担心过拟合；</li></ul><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><p>论文的模型，即AlexNet，其由多伦多大学，Geoff Hinton实验室设计，夺得了2012年ImageNet ILSVRC比赛的冠军，且其top-5错误率远低于第二名，分别为15.3%和26.2%。</p><p>AlexNet在<strong>深度学习发展史上的历史意义远大于其模型的影响。</strong>在此之前，深度学习已经沉寂了很久。在此之后，深度学习重新迎来春天，卷积神经网络也成为计算机视觉的核心算法模型。</p><p><strong>卷积过程中，卷积核的权重不变，局部连接，权值共享。</strong></p><p><strong>池化在卷积神经网络中的作用：</strong>一方面可以减少feature map（或kennel）的尺寸，减小计算量；另一方面可以防止过拟合，把一些噪音过滤掉，同时为卷积神经网络引入了平移不<strong>加粗样式</strong>变性。</p><h3 id="本文的主要内容有："><a href="#本文的主要内容有：" class="headerlink" title="本文的主要内容有："></a>本文的主要内容有：</h3><ul><li>使用 ReLU 激活函数加速收敛 </li><li>使用 GPU 并行，加速训练。也为之后的分组卷积（group convolution）理论奠定基础。</li><li> 提出局部响应归一化（Local Response Normalization, LRN）增加泛化特性 (虽然被后人证明无效 )</li><li>使用交叠池化 (Overlapping Pooling) 防止过拟合 </li><li>提出Dropout，数据增强等手段防止过拟合</li></ul><h3 id="一、数据集："><a href="#一、数据集：" class="headerlink" title="一、数据集："></a>一、数据集：</h3><p>数据来源于ImageNet，训练集包含120万张图片，验证集包含5万张图片，测试集包含15万张图片，这些图片分为了1000个类别，并且有多种不同的分辨率，但是AlexNet的输入要求是固定的分辨率，为了解决这个问题，Alex的团队采用低采样率把每张图片的分辨率降为256×256，具体方法就是给定一张矩形图像，首先重新缩放图像，使得较短边的长度为256，然后从结果图像的中心裁剪出256×256大小的图片。</p><p><strong>采用2块GPU对训练进行加速，仍需5-6天</strong>。</p><p>网络包含许多新的和不寻常的特征，可以提高其性能并减少其训练时间。</p><p>网络的大小主要受当前GPU上可用内存量和我们愿意容忍的训练时间量的限制。</p><p>1000个类别中的每个类别中包含大约1000张图像总共有大约120万张训练图像、50,000张验证图像和150,000张测试图。</p><p><strong>举一个</strong>🌰：训练集是平时作业题，验证集是模拟考试题，测试集是高考题，高考考砸说明过拟合了。</p><h3 id="二、图像预处理："><a href="#二、图像预处理：" class="headerlink" title="二、图像预处理："></a>二、图像预处理：</h3><p>每个图片变成256*256的图片，计算出每一个像素的均值，把每一个像素都减去对应的均值（相当于中心化的预处理）。</p><p><strong>预处理可以减少噪声的敏感性。</strong></p><h3 id="三、激活函数"><a href="#三、激活函数" class="headerlink" title="三、激活函数"></a>三、激活函数</h3><p><strong>为什么使用ReLu激活函数？</strong></p><p><strong>Sigmoid函数</strong>：把（-∞,+∞）的任意数挤压在（0，1）小区间里；<br><strong>tanh函数</strong>：把（-∞,+∞）的任意数挤压在（-1，1）小区间里；</p><p>sigmoid和tanh函数都是饱和激活函数，即当输入x过小或过大时，会被局限在一个很小的区域内，不能在进行变化。这种饱和的激活函数会造成梯度消失的问题，影响学习的效率和速度。</p><p><strong>ReLu函数为不饱和激活函数，可解决梯度消失问题。</strong></p><p>以ReLu函数代替Tanh或sigmoid函数（logistic回归使用的激活函数），这样能使网络训练，以更快的速度收敛。</p><p>在此之前，有人提出f(x)=|tanh(x)|，此方法在Caltech-101数据集上正则化和局部平均池化特别好。但是，在Caltech-101数据集上，<strong>主要问题是防止过度拟合。</strong>而对在<strong>大型数据集上，更快的学习、训练对性能有很大影响</strong>，此方法不满足。</p><p><img src="https://img-blog.csdnimg.cn/20210622230545680.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>如图ReLU函数比tanh函数收敛快6倍。虽然不同网络结构效果可能不同，但ReLU普遍收敛很快。</p><h3 id="四、GPU"><a href="#四、GPU" class="headerlink" title="四、GPU"></a>四、GPU</h3><p><strong>为什么要使用多GPU？</strong></p><p>单GPU无法训练太大的额数据集，因此使用两个并行GPU（当前GPU 能直接读取和写入彼此的内存）。</p><p>并行化本质上是将一半的内核（或神经元）放在一个GPU上，另一个GPU尽在某层中进行通信。</p><p>单GPU网络实际上与双GPU网络有相同数量的内核。这是因为网络的大部分参数都在第一个全连接层中，该层将最后的卷积层作为输入。</p><p>单GPU(半参数)模型中最后一个卷积和券链接层参数数量与双GPU(全参数)模型相同。<strong>因此“半参数”并非真的只有一半的参数。</strong></p><p><strong>双GPU(全参数)的训练时间比但GPU(半参数)更短。</strong></p><h3 id="五、局部响应归一化（LRN）"><a href="#五、局部响应归一化（LRN）" class="headerlink" title="五、局部响应归一化（LRN）"></a>五、局部响应归一化（LRN）</h3><p>ReLU函数不像tanh和sigmoid一样有一个有限的值域区间，所以在ReLU之后需要进行归一化处理，LRN的思想来源于神经生物学中一个叫做“侧抑制”的概念，指的是被激活的神经元抑制周围的神经元。</p><p>Alex认为LRN可以防止过拟合，并与生物上的神经元类似；但是此方法在后续已不再采用了，如VGG指出有LRN和没有LRN没有区别，<strong>LRN没有什么作用，只会徒劳的增加计算量。</strong></p><h3 id="六、有重叠的池化"><a href="#六、有重叠的池化" class="headerlink" title="六、有重叠的池化"></a>六、有重叠的池化</h3><p>即池化步长小于池化窗口。</p><p><strong>Alex认为可以防止过拟合，但后续也不会采用这个技巧，为以后的模型进行了探索。</strong></p><h3 id="七、整体结构"><a href="#七、整体结构" class="headerlink" title="七、整体结构"></a>七、整体结构</h3><p><img src="https://img-blog.csdnimg.cn/20210622230737565.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>224*224算出来第一层的feature map是一个小数，不符合整数的要求。则[(227-11)/4]+1=55，此处为作者的笔误。</p><p>第一个卷积层：96个11<em>11</em>3的卷积核步长为4；</p><p>第二个卷积层：256个5<em>5</em>48的卷积核；</p><p>第三个卷积层：384个3<em>3</em>256的卷积核；</p><p>第四个卷积层：384个3<em>3</em>192的卷积核；</p><p>第五个卷积层：256个3<em>3</em>192的卷积核；</p><p>全连接层：每层4096个神经元；</p><p>1000个神经元，它是线性分类，并没有非线性的激活函数，每一个神经元输出对应的分数，对1000个分数进行softmax，归一化，把它变成1000个概率，其和为1。</p><h3 id="八、防止过拟合"><a href="#八、防止过拟合" class="headerlink" title="八、防止过拟合"></a>八、防止过拟合</h3><p>存储1000个类别只需10bit，2的10次方=1024</p><p>但把图片映射成标签需要很多参数参数过多，可能会过出现严重的过拟合。</p><h4 id="1、增加训练样本"><a href="#1、增加训练样本" class="headerlink" title="1、增加训练样本"></a>1、增加训练样本</h4><p>图像平移和水平翻转。将256<em>256的图像随机选取224</em>224的片段作为输入对象。一张图可以变成32<em>32</em>2=2048张图。虽然图像高度相似，但是可以有效的防止过拟合，扩充数据集。</p><p>先对图像做镜像反射，就像下图这样：</p><p><img src="https://img-blog.csdnimg.cn/20210622230835216.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>摘自<a href="https://www.learnopencv.com/understanding-alexnet/">https://www.learnopencv.com/understanding-alexnet/</a></p><p>然后在原图和镜像反射的图（256×256）中随机抽取227×227的块，像这样：</p><p><img src="https://img-blog.csdnimg.cn/20210622230857825.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>摘自<a href="https://www.learnopencv.com/understanding-alexnet/">https://www.learnopencv.com/understanding-alexnet/</a></p><h4 id="2、Dropout随机丢弃一定比例的神经元，被丢弃的神经元不参加训练过程。"><a href="#2、Dropout随机丢弃一定比例的神经元，被丢弃的神经元不参加训练过程。" class="headerlink" title="2、Dropout随机丢弃一定比例的神经元，被丢弃的神经元不参加训练过程。"></a>2、Dropout随机丢弃一定比例的神经元，被丢弃的神经元不参加训练过程。</h4><p>Dropout做法是，对每一层、每次训练以概率P丢弃一些神经元，这样每次训练的网络都不一样。</p><p><strong>CNN的连接和参数要少得多，因此它们更容易训练。</strong></p><p>前两个全连接层中使用了dropout。在没有dropout 的情况下，网络严重的过拟合。dropout使收敛所需的迭代次数大约增加了一倍。</p><p><strong>训练结束后的测试流程，要用完成的网络结构，同时对该层的所有的参数（w,b）都乘以（1-P）。</strong></p><h3 id="九、-细节、结果与讨论"><a href="#九、-细节、结果与讨论" class="headerlink" title="九、 细节、结果与讨论"></a>九、 细节、结果与讨论</h3><p><img src="https://img-blog.csdnimg.cn/20210622231015379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>GPU1上的内核在很大程度上是不分颜色的，而GPU2上的内核在很大程度上是特定颜色的。这种特殊化发生在每次运行期间，并且与任何特定的随机权重初始化无关（除了GPU的重新编号之外）。</p><p>第一卷积层对224×224×3的输入图像学习了96个大小为11×11×3的卷积核。上面的48个核是在GPU1上学习的，下面的48个核是在GPU2上学习的。</p><p>初始化第二，第四和第五卷积层的神经元偏差，以及完全连接的隐藏层，恒定1。其余各层为数0。</p><p>所有层使用相同的的学习率。训练过程中，手动调整学习率，当验证错误率不再随当前的学习率提高时，将学习率除以10。初始值为0.01，在终止前减少了三次。</p><p>传统的无监督自动编码器没有使用性能，只提取原始像素空间特征，不提取语义特征。</p><p>另一种探测网络视觉知识的方法是考虑最后一个4096维隐藏层的图像所引起的特征激活。如果两幅图像产生的特征激活向量具有较小的欧氏分离度，我们可以说，神经网络的高层认为它们是相似的。</p><p>使用4096维实值向量之间的欧几里得距离来计算相似性是低效的，但是可以通过训练一个自动编码器将这些向量压缩成短的二进制代码来使其高效。</p><p><strong>如果去掉一个卷积层，网络的性能就会下降</strong>。例如，去掉任何一个中间层，都会使网络的最高性能损失2%左右。（<strong>ZFNet论文</strong>中有更详细的去掉中间层性能的比较实验）</p><p><strong>没有使用无监督与训练。</strong></p><p><strong>此方法可用于视频序列中。</strong></p><blockquote><p>愿你的每次流泪都是喜极而泣<br>愿你精疲力竭有树可倚</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ZFNet</title>
      <link href="/2021/06/28/zfnet/"/>
      <url>/2021/06/28/zfnet/</url>
      
        <content type="html"><![CDATA[<h1 id="带你读论文系列之计算机视觉–ZFNet"><a href="#带你读论文系列之计算机视觉–ZFNet" class="headerlink" title="带你读论文系列之计算机视觉–ZFNet"></a>带你读论文系列之计算机视觉–ZFNet</h1><h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p><a href="https://wuliwuxin.github.io/2021/06/28/alexnet/">《带你读论文系列之计算机视觉–AlexNet》</a></p><p>Convolutional Network表现好：</p><ul><li>更大的训练集的可用性，有数百万的标记样本；</li><li>强大的GPU实现，使训练非常大的模型成为现实；</li><li>更好的模型正则化策略，如Dropout</li></ul><p>复杂模型的内部运作和行为，或它们如何取得如此好的性能，仍然没有什么深入了解。你如此优秀，我还不知道你为什么这么优秀。嗯，我必须要了解你一下。「🤔」</p><h2 id="背景与作者"><a href="#背景与作者" class="headerlink" title="背景与作者"></a>背景与作者</h2><p><strong>ZFNet</strong>是<strong>Matthew D.Zeiler与Rob Fergus</strong>于2013年提出，并获得了<strong>2013年ImageNet的冠军</strong>。2012年AlexNet问世，并在ImageNet竞赛中取得了优异的成绩，也证明了大的卷积网路的性能优异，但是我们并不知道为什么CNN性能好。</p><p>因此，该论文是在AlexNet基础上进行了一些细节的改动,通过使用可视化技术揭示了神经网络各层到底在干什么，起到了什么作用。也是基于这个技术，作者对AlexNet进行了优化，<strong>调整之后的网络的性能在很多问题上性能都好于AlexNet。</strong></p><p><img src="https://img-blog.csdnimg.cn/20210625220749108.png"></p><p><strong>Matthew D.Zeiler</strong>创始人兼 CEO Matthew Zeiler 是机器学习博士。应用人工智能 (AI) 领域的先驱和思想领袖。Matt 与著名机器学习专家 Geoff Hinton 和 Yann LeCun 在计算机视觉方面的开创性研究推动了图像识别行业从理论到实际应用。自 2013 年创立 Clarifai 以来，Matt 已将他屡获殊荣的研究发展为开发人员友好的产品，使企业能够快速无缝地将 AI 集成到他们的工作流程和客户体验中。今天，Clarifai 是领先的独立 AI 公司，被广泛视为机器学习领域最有前途的 初创公司之一。</p><p><img src="https://img-blog.csdnimg.cn/20210625220815254.png"></p><p><strong>Rob Fergus</strong>的研究领域是计算机视觉、机器学习和计算机图形。他对建立图像的统计模型感兴趣，这些模型既包括高层次的物体和场景，也包括低层次的像素和边缘。这些模型可以在各种问题中部署。他特别感兴趣的问题包括：物体识别、图像搜索等。</p><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><p><strong>论文的主要贡献：</strong><br>1、特征可视化<br>2、对于CNN结构的改进<br>3、对于遮挡的敏感性<br>4、关联分析<br>5、特征提取的通用性<br>6、特征分析</p><h3 id="技术："><a href="#技术：" class="headerlink" title="技术："></a>技术：</h3><ol><li><strong>反池化过程</strong>：池化是不可逆的过程，然而我们可以通过记录池化过程中，最大激活值得坐标位置。然后在反池化的时候，只把池化过程中最大激活值所在的位置坐标的值激活，其它的值置为0。这个过程只是一种近似，因为我们在池化的过程中，除了最大值所在的位置，其它的值也是不为0的。</li><li><strong>反激活</strong>：在AlexNet中，relu函数是用于保证每层输出的激活值都是正数，因此对于反向过程，我们同样需要保证每层的特征图为正值，也就是说这个反激活过程和激活过程没有什么差别，都是直接采用relu函数。</li><li><strong>反卷积</strong>：利用相同卷积核的转置作为核，于输入做卷积运算</li></ol><h3 id="特征可视化"><a href="#特征可视化" class="headerlink" title="特征可视化"></a>特征可视化</h3><p><strong>什么是平移不变性？</strong></p><p>不变性即使目标的外观发生了某种变化，但是你依然可以把它识别出来。这对图像分类来说是一种很好的特性，因为我们希望图像中目标无论是被平移，被旋转，还是被缩放，甚至是不同的光照条件、视角，都可以被成功地识别出来。</p><p>所以上面的描述就对应着各种不变性：</p><ul><li>平移不变性：Translation Invariance</li><li>旋转/视角不变性：</li><li>Ratation/Viewpoint Invariance</li><li>尺度不变性：Size Invariance</li><li>光照不变性：Illumination Invariance</li></ul><p><strong>特征可视化局限在第一层</strong>，可以投射到像素空间，但是更<strong>高层的解释方法有限</strong>。因为对于较高的层，不变性是非常复杂的，所以很难被简单的二次逼近法所捕获。</p><p><strong>作者的方法</strong>提供了一个非参数化的不变性观点，显示了训练集的哪些patch激活了特征图。</p><p>在2013年Donahue等人展示了在数据集中识别patch的可视化，这些patch负责模型中更高层次的强激活。我们的可视化不同的是，不只是输入图像的作物，而是自上而下的投影，揭示了每个patch内刺激特定特征图的结构。</p><p>带标签的图像来训练模型，交叉熵损失函数用来比较预测值与实际值。（卷积层中的过滤器、全连接层中的权重矩阵和偏置）通过反向传播损失对整个网络参数的导数进行训练，并通过随机梯度下降更新参数。</p><p>我们提出了一种将这些活动映射回输入像素空间的新方法，显示什么输入模式最初导致了特征图中的给定激活。</p><h3 id="用反卷积法进行可视化"><a href="#用反卷积法进行可视化" class="headerlink" title="用反卷积法进行可视化"></a>用反卷积法进行可视化</h3><p>反卷积网络，相反的convolution network过程，而不是将像素映射到特征。convnet使用学习的过滤器来卷积来自前一层的特征图。deconvnet使用相同过滤器的转置版本（即垂直和水平翻转每个过滤器），但应用于校正后的map，而不是下层的输出。</p><p><strong>最大池化不可逆</strong>，但我们可以在变量中记录每个池化区域内最大值的位置来近似逆转。反池化：在卷积神经网络时，记录每个最大池化局部最大的位置。反池化时，将最大位置值还原，其余位置设为0。</p><p>为了确保特征图始终是正的，我们通过ReLu非线性函数重建信号。单个激活获得的重建类似于原始输入图像的一小部分。</p><p><img src="https://img-blog.csdnimg.cn/20210625221457777.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h3><p>一个区别是在CNN的第3 、4、5层中使用的稀疏连接（由于模型被拆分为2个GPU）在我们的模型中被密集连接替换。</p><p>每个RGB图像都通过将最小尺寸调整为256、裁剪中心256x256区域、减去每像素平均值（跨所有图像）然后使用10个不同的大小为224x224 的子裁剪（角+中心和（外）水平翻转）进行预处理。为每个训练示例生成多种不同的裁剪和翻转，以提高训练集的大小。使用小批量大小为128的随机梯度下降来更新参数。</p><p>在模型的第一层，输入图像大致在[-128,128]范围内。</p><p><strong>参数设置：</strong></p><ul><li>初始学习率：0.01</li><li>初始动量：0.9</li><li>dropout概率：0.5</li><li>所有初始权重:0.01</li><li>偏置项：0</li></ul><p>将RMS值超过固定半径0.1的卷积层中的每个滤波器重新归一化为这个固定半径。</p><blockquote><p>均方根误差（RMSE，root-mean-square error）：</p></blockquote><p>均方根误差为了说明样本的离散程度。</p><p>做非线性拟合时,RMSE越小越好。</p><p><strong>该模型在70个epoch后停止训练，这在单个GTX580 GPU上花费了大约12天。</strong><br><img src="https://img-blog.csdnimg.cn/20210625221537984.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><img src="https://img-blog.csdnimg.cn/20210625221551891.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/20210625221545124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt=""></p><p><strong>第2层</strong>响应角和其他边缘/颜色连接；</p><p><strong>第3层</strong>具有更复杂的不变性，捕获相似的纹理；</p><p><strong>第4层</strong>显示出显着的变化，但更具有特定类别：</p><p><strong>第5层</strong>显示了具有显着姿势变化的整个对象；</p><p><strong>注意：</strong></p><ul><li>每个特征图内的强分组；</li><li>较高层次的不变性；</li><li>图像中歧视性部分的夸大，例如狗的眼睛和鼻子</li></ul><h3 id="训练时特征演变"><a href="#训练时特征演变" class="headerlink" title="训练时特征演变"></a>训练时特征演变</h3><p>在一个给定的特征图中投射回像素空间的强激活（跨越所有训练实例）的进展。外观上的突然跳动是由于最强激活的图像发生了变化。</p><p><img src="https://img-blog.csdnimg.cn/20210625221733179.png"></p><p>上图表示通过训练随机选择的模型特征子集的演化。每个图层的特征显示在不同的块中。在每个块中，我们在 epoch [1,2,5,10,20,30,40,64] 中显示了随机选择的特征子集。可视化显示了给定特征图的最强激活（在所有训练示例中），使用我们的 deconvnet 方法投影到像素空间。人为增强色彩对比度。</p><p><strong>上层只有在相当多的 epochs(40-50)之后才发展，需要让模型训练直到完全收敛。</strong></p><h3 id="特征不变性"><a href="#特征不变性" class="headerlink" title="特征不变性"></a>特征不变性</h3><p>样本图像，在观察模型顶层和底层的特征向量相对于未变换特征的变化时，它们被不同程度地平移、旋转和缩放。小的变换在模型的第一层有很大的影响，但在顶部特征层的影响较小。该网络的输出对平移和缩放是稳定的。一般来说，除了具有旋转对称性的物体，输出对旋转是不变的。</p><p><img src="https://img-blog.csdnimg.cn/20210625221819624.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>上图表示：模型内垂直平移、缩放和旋转不变性的分析（分别为 a-c 行）。第 1 列：5 个经过转换的示例图像。列2和3：分别来自第1层和第7层的原始图像和变换图像的特征向量之间的欧几里德距离。第4列：每个图像的真实标签的概率，因为图像被变换。</p><h3 id="结构的选择"><a href="#结构的选择" class="headerlink" title="结构的选择"></a>结构的选择</h3><p>可视化 Krizhevsky 等人的架构<strong>存在的问题</strong>：</p><p>第一层滤波器是极高频和低频信息的混合，几乎没有覆盖中频。</p><p>第二层可视化显示了由第一层卷积中使用的大步幅 4 引起的混叠伪影。</p><p><strong>解决方案：</strong><br>将第 1 层过滤器的大小从 11x11 减小到 7x7 并且使卷积的步幅4变为 2。这样在第 1 层和第 2 层特征中保留了更多信息，它还提高了分类性能。</p><h3 id="遮挡敏感度"><a href="#遮挡敏感度" class="headerlink" title="遮挡敏感度"></a>遮挡敏感度</h3><p>对于<strong>图像分类</strong>方法，<strong>存在的问题</strong>是模型是真正识别图像中对象的位置，还是仅使用周围的上下文。</p><p>通过系统地用灰色方块遮挡输入图像的不同部分，并监测分类器的输出。因为当对象被遮挡时，正确类别的概率显着下降。</p><p><img src="https://img-blog.csdnimg.cn/20210625221941959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>如图所示三个测试示例，我们系统地用灰色方块（第 1 列）覆盖场景的不同部分，并查看顶部（第 5 层）特征映射（第二列和第三列）和分类器输出（第四列和第五列) 变化。第二列：对于灰度的每个位置，我们在第 5 层特征图（未遮挡图像中响应最强的那个）中记录总激活。第三列：投影到输入图像（黑色方块）中的该特征图的可视化，以及来自其他图像的该地图的可视化。第一行的例子显示了最强的特征是狗的脸。当这被掩盖时，特征图中的活动减少（第二列中的蓝色区域）。第四列：作为灰色方块位置的函数的正确类别概率图。例如。当狗的脸被遮挡时，“博美犬”的概率显着下降。第五列：最可能的标签作为遮挡器位置的函数。例如。在第一行，对于大多数位置，它是“博美犬”，但如果狗的脸被遮挡而不是球，那么它预测“网球”。在第二个示例中，汽车上的文本是第 5 层中最强的特征，但分类器对车轮最敏感。第三个示例包含多个对象。第 5 层中最强的特征挑出人脸，但分类器对狗敏感（第四列中的蓝色区域），因为它使用了多个特征图。</p><p>当遮挡物覆盖出现在可视化中的图像区域时，我们看到特征图中的活动急剧下降。<strong>这表明可视化真正对应于对象的位置和该特征图的图像结构。</strong></p><p><img src="https://img-blog.csdnimg.cn/20210625222041365.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/20210625222047265.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70" alt=""></p><p>如图所示：不同狗图像中不同对象部分的对应性度量。眼睛和鼻子的较低分数（与随机对象部分相比）表明该模型在模型的第 5 层隐式建立了某种形式的部分对应关系。在第 7 层，分数更相似，可能是由于上层试图区分不同品种的狗。</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p><strong>ImageNet数据集</strong>：训练集1.3M；验证集50K;测试集100K；1000个分类.</p><h4 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h4><p><img src="https://img-blog.csdnimg.cn/20210625222128677.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>224 x 224（具有 3 个颜色平面）图像作为输入呈现。第一层96 个过滤器（红色）卷积的，每个过滤器的大小为 7 x 7，在 x 和 y 中使用 2 的步长。然后得到的特征图是：（i）通过一个修正的线性函数；(ii) 池化（最大在 3x3 区域内，使用步幅 2）；（iii）跨特征映射归一化的对比度，以提供 96 个不同的 55 x 55 元素特征映射。</p><p>在第 2、3、4、5 层重复类似的操作。最后两层是全连接的，将顶部卷积层的特征作为向量形式（6·6·256 = 9216 维）的输入。最后一层是一个C-way softmax function，C是类的数量。所有过滤器和特征图都是方形的。</p><p>架构变化（第1层的7×7过滤器和第1、2层的stride 2卷积），比他们的单一模型结果Top-5 error 降低了1.7%，证明了这样改进的正向效果。</p><p>结合多个模型时，我们得到14.8%的测试误差。</p><h3 id="模型探索"><a href="#模型探索" class="headerlink" title="模型探索"></a>模型探索</h3><ul><li>删除模型的两个卷积层或者两个全连接层，对分类结果影响不大。</li><li>去除中间卷积层和全连接层后，只有4个层的模型的性能明显下降，说明了模型的整体深度很重要。</li><li>单独改变全连接层的尺寸，对分类结果影响不大，但增大中间卷积层的尺寸对分类结果。</li></ul><p><img src="https://img-blog.csdnimg.cn/20210625222219818.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>使用ImageNet预训练的模型用到其他数据集上也取得了很好的效果，说明了fine-tuning的价值。</p><p>特征分析部分在原始模型某一中间层后加SoftMax或者SVM分类器，说明了最后面层特征的分类效果最好，再次佐证了不同层之间学习到的特征具有层次结构，层数越大，学习到的特征表达能力越强。</p><p><strong>其他数据集上的表现</strong></p><p>对于 Caltech-101 和 Caltech-256，数据集非常相似，以至于我们模型得到结果做好。</p><p><img src="https://img-blog.csdnimg.cn/20210625222515559.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/20210625222523409.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><p>但我们的 convnet 模型对 PASCAL 数据的泛化不太好，可能存在数据集偏差。</p><p><img src="https://img-blog.csdnimg.cn/20210625222600421.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGlfeGlu,size_16,color_FFFFFF,t_70"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>提出了一种可视化方法，展示了如何使用这些可视化来调试模型的问题以获得更好的结果。</li><li>发现学习到的特征远不是无法解释的，而是特征间存在层次性，层数越深，特征不变性越强，类别的判别能力越强；</li><li>通过可视化模型中间层，在AlexNet基础上进一步提升了分类效果；</li><li>通过一系列遮挡实验证明，该模型在进行分类训练时，对图像中的局部结构高度敏感，而不仅仅是使用广泛的场景上下文。对该模型的消融研究表明，网络的最小深度，而不是任何单个部分，对模型的性能至关重要。遮挡实验表明分类时模型和局部块的特征高度相关；</li><li>模型的深度很关键；</li><li>预训练模型可以在其他数据集上fine-tuning得到很好的结果。</li></ul><blockquote><p>愿你的身后总有力量<br>愿你成为自己的太阳</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
